{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6a9b8b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "%run excute_nonZS_MaxMin.ipynb\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc74e9c9",
   "metadata": {},
   "source": [
    "## 1. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fec69e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if I use this, then the result will not be correct - just logics outside of the function\n",
    "\n",
    "def network_data(s, G, n):\n",
    "    (v1, v2, max_opinion, min_opinion, max_pol) = MaxMin_play(s, n, G)\n",
    "    (scaled_deg_cent, scaled_clo_cent, scaled_eigen_cent, scaled_MinPaths_sort, scaled_op_extre, scaled_cc) = metrics(G, v1)\n",
    "    # print(v1, max_opinion)\n",
    "    #print(\"actual_ranks INPUT:\",s, n, v1, max_opinion )\n",
    "    (actual_Y_dict, actual_ranks, innate_por_dict) = actual_rank(s, n, v1, max_opinion)\n",
    "    keys = converted_dict2.keys()\n",
    "    df = pd.DataFrame({'keys': list(keys),\n",
    "                   'x1_d': [sorted_gap[x] for x in keys],\n",
    "                   'x2_deg':[converted_dict[x] for x in keys],\n",
    "                   'x3_clo':[converted_dict1[x] for x in keys],\n",
    "                   'x4_eigen': [converted_dict2[x] for x in keys],\n",
    "                   'x5_path': [scaled_MinPaths_sort[x] for x in keys],\n",
    "                   'x6_cc': [scaled_cc[x] for x in keys],\n",
    "                   'y_value': [actual_Y_dict[x] for x in keys],\n",
    "                    'ranks_y':[actual_ranks[x] for x in keys]})\n",
    "\n",
    "    print(\"_________________\")\n",
    "    a = sorted(actual_Y_dict.items(), key=lambda x:x[1])\n",
    "#     print(a)\n",
    "    if a[0][0]!= v1:\n",
    "        print(a[0][0]==v2)\n",
    "    else:\n",
    "        print(a[1][0]==v2)\n",
    "    \n",
    "    return (df, actual_Y_dict, innate_por_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1d20531f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "{19: 0}\n",
      "[18]\n",
      "[18, 9]\n",
      "[18, 11]\n",
      "[18, 9, 0]\n",
      "[18, 9, 2]\n",
      "[18, 9, 3]\n",
      "[18, 9, 6]\n",
      "[18, 9, 7]\n",
      "[18, 9, 8]\n",
      "[18, 9, 12]\n",
      "[18, 9, 13]\n",
      "[18, 9, 14]\n",
      "[18, 9, 15]\n",
      "[18, 9, 17]\n",
      "[18, 11, 1]\n",
      "[18, 11, 10]\n",
      "[18, 11, 19]\n",
      "[18, 9, 0, 4]\n",
      "[18, 9, 0, 5]\n",
      "[18, 9, 2, 16]\n",
      "{18: 0, 9: 2, 11: 2, 0: 3, 2: 3, 3: 3, 6: 3, 7: 3, 8: 3, 12: 3, 13: 3, 14: 3, 15: 3, 17: 3, 1: 3, 10: 3, 19: 3, 4: 4, 5: 4, 16: 4}\n",
      "{0: 3, 1: 3, 2: 3, 3: 3, 4: 4, 5: 4, 6: 3, 7: 3, 8: 3, 9: 2, 10: 3, 11: 2, 12: 3, 13: 3, 14: 3, 15: 3, 16: 4, 17: 3, 18: 0, 19: 3}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "{0: 3, 1: 3, 2: 3, 3: 3, 4: 4, 5: 4, 6: 3, 7: 3, 8: 3, 9: 2, 10: 3, 11: 2, 12: 3, 13: 3, 14: 3, 15: 3, 16: 4, 17: 3, 18: 0, 19: 3}\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "0\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "nxG = nx.from_numpy_matrix(G)  \n",
    "print(v1)\n",
    "paths = nx.single_source_shortest_path(nxG,v1) \n",
    "\n",
    "#\n",
    "print(PathLen)\n",
    "\n",
    "\n",
    "# the length of shortest path from v2 to v1\n",
    "lenths =[]\n",
    "for v in paths.items():\n",
    "    lenth = len(v[1])\n",
    "    print(v[1])\n",
    "    lenths.append(lenth)\n",
    "# print(paths.keys())\n",
    "PathLen = dict(zip(paths.keys(),lenths))\n",
    "# print(PathLen)\n",
    "PathLen.update({v1:0})\n",
    "# print(paths)\n",
    "print(PathLen)\n",
    "scaled_MinPaths_sort = dict(sorted(PathLen.items(), key=lambda x:x[0]))\n",
    "print(scaled_MinPaths_sort)\n",
    "keys = list(range(n))\n",
    "print(keys)\n",
    "print(scaled_MinPaths_sort)\n",
    "for x in keys:\n",
    "    print(scaled_MinPaths_sort[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7f12e259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_values Normalizaion \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def rescale(dic): # input x is a dictionary - sorted node index: value\n",
    "    minmax_scale = MinMaxScaler(feature_range=(0, 1))\n",
    "    x = list(dic.values())\n",
    "    x = np.array(x)\n",
    "    x = x.reshape(-1, 1)\n",
    "    x_scale = minmax_scale.fit_transform(x).flatten()\n",
    "    dic_scale = dict(zip(dic.keys(),x_scale))\n",
    "    return dic_scale  # output\n",
    "\n",
    "# Creat Metrics for Regression\n",
    "\n",
    "################### create shortest path from all nodes to max selected node v1 ############\n",
    "def shortest_pth(G, v1):\n",
    "    nxG = nx.from_numpy_matrix(G)  \n",
    "    paths = nx.single_source_shortest_path(nxG,v1) \n",
    "    # the length of shortest path from v2 to v1\n",
    "    lenths =[]\n",
    "    for v in paths.items():\n",
    "        lenth = len(v[1])\n",
    "        lenths.append(lenth)\n",
    "    # print(paths.keys())\n",
    "    PathLen = dict(zip(paths.keys(),lenths))\n",
    "    # print(PathLen)\n",
    "    PathLen.update({v1:0})\n",
    "\n",
    "    #print(\"path_lenth\",PathLen)\n",
    "    return PathLen\n",
    "\n",
    "def local_clustering_coefficient(G):\n",
    "    clus_coef = []\n",
    "    for node in range(len(G)):\n",
    "        neighbors = np.nonzero(G[node])[1]\n",
    "        num_neighbors = len(neighbors)\n",
    "        if num_neighbors < 2:\n",
    "            clustering_coefficient = 0.0  # No triangles possible\n",
    "        else:\n",
    "            num_triangles = 0\n",
    "            for i in range(num_neighbors - 1):\n",
    "                for j in range(i + 1, num_neighbors):\n",
    "                    #print(neighbors[i], neighbors[i])\n",
    "                    if G[neighbors[i], neighbors[j]] == 1:\n",
    "                        num_triangles = num_triangles + 1\n",
    "                        #print(num_triangles)\n",
    "#             print(\"num_triangles:\",num_triangles)\n",
    "            clustering_coefficient = (2.0 * num_triangles) / (num_neighbors * (num_neighbors - 1))\n",
    "        clus_coef.append((node, clustering_coefficient))\n",
    "    cc = dict(clus_coef)\n",
    "    \n",
    "    return cc\n",
    "\n",
    "\n",
    "def metrics(G, v1):\n",
    "\n",
    "    nxG = nx.from_numpy_matrix(G) \n",
    "    # G = nx.karate_club_graph()\n",
    "   # print(\"_______________Degree Centrality_____________________________\")  \n",
    "    deg_centrality = nx.degree_centrality(nxG)\n",
    "    sortedDict = sorted(deg_centrality.items(), key=lambda x:x[1])\n",
    "    converted_dict = dict(sortedDict)\n",
    "    # print(converted_dict)\n",
    "    #print(\"                           \")\n",
    "   # print(\"_______________Closeness Rank_____________________________\")\n",
    "    close_centrality = nx.closeness_centrality(nxG)\n",
    "    sortedDict1 = sorted(close_centrality.items(), key=lambda x:x[1])\n",
    "    converted_dict1 = dict(sortedDict1)\n",
    "    # print(converted_dict1)\n",
    "    #print(\"                           \")\n",
    "   # print(\"_______________Page Rank_____________________________\")\n",
    "    pr = nx.eigenvector_centrality(nxG)\n",
    "    sortedDict2 = sorted(pr.items(), key=lambda x:x[1])\n",
    "    converted_dict2 = dict(sortedDict2)\n",
    "    # print(converted_dict2)\n",
    "    #print(\"                           \")\n",
    "   # print(\"_______________Opinion Extremity_____________________________\")\n",
    "    def gap(op, n):\n",
    "        ones = np.ones((n, 1))\n",
    "        x = op - (np.dot(np.transpose(op),ones)/n) * ones\n",
    "        return abs(x)\n",
    "    gap = gap(s,n)\n",
    "    my_gap = {index: value for index, value in enumerate(gap)}\n",
    "    sorting_gap = sorted(my_gap.items(), key=lambda x:x[1], reverse=True)\n",
    "    sorted_gap = dict(sorting_gap)\n",
    "    # print(\"opinion - mean\")\n",
    "    # print(sorted_gap)\n",
    "    \n",
    "   # print(\"________________Shortest Path_____________________________\")\n",
    "    PathLen = shortest_pth(G, v1)\n",
    "    # creat a dict node:shortest length to v1(max selected node)\n",
    "    \n",
    "   #print(\"________________cluster coefficient____________________________\") \n",
    "    cc = local_clustering_coefficient(G)\n",
    "    \n",
    "    PathLen = rescale(PathLen) # rescale the shortest path to the range (0,1) for regression\n",
    "#     converted_dict= rescale(converted_dict)\n",
    "#     converted_dict1 = rescale(converted_dict1)\n",
    "#     converted_dict2 = rescale(converted_dict2)\n",
    "#     sorted_gap = rescale(sorted_gap)\n",
    "#     cc = rescale(cc)\n",
    "    \n",
    "    # sorting all varibles based on the node index\n",
    "    scaled_MinPaths_sort = dict(sorted(PathLen.items(), key=lambda x:x[0]))\n",
    "    #print(\"scaled_paths_sort\",scaled_MinPaths_sort)\n",
    "    \n",
    "    scaled_deg_cent = dict(sorted(converted_dict.items(), key=lambda x:x[0]))\n",
    "    scaled_clo_cent = dict(sorted(converted_dict1.items(), key=lambda x:x[0]))\n",
    "    scaled_eigen_cent = dict(sorted(converted_dict2.items(), key=lambda x:x[0]))\n",
    "    scaled_op_extre = dict(sorted(sorted_gap.items(), key=lambda x:x[0]))\n",
    "    scaled_cc = dict(sorted(cc.items(), key=lambda x:x[0]))\n",
    "    \n",
    "    return (scaled_deg_cent, scaled_clo_cent, scaled_eigen_cent, scaled_MinPaths_sort, scaled_op_extre, scaled_cc)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f3390af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the ground truth of Min's action - knowing Max chooses v1, what Min's action will be?\n",
    "def actual_rank(s, n, v1, max_opinion):\n",
    "\n",
    "    L = scipy.sparse.csgraph.laplacian(G, normed=False)  # Return the Laplacian matrix\n",
    "    A = np.linalg.inv(np.identity(n) + L)  # A = (I + L)^(-1)\\n  Stanford paper theory\n",
    "    op = copy.copy(s)\n",
    "    op[v1] = max_opinion\n",
    "    \n",
    "    all_1 = list(range(n))    # for all agent \n",
    "    C1 = [x for x in all_1 if x != v1]  # for the vertice that Maximizer has not touched\n",
    "    innat_por = obj_polarization(A, s, n) # Calculate the polarization after maximzer' action - not innate polarization\n",
    "    max_por = obj_polarization(A, op, n)\n",
    "    results = []\n",
    "    real_por1 = []\n",
    "    for v2 in C1:   \n",
    "        (changed_opinion, por) = derivate_s(op,n,v2,A)   # find the best new_op option  \n",
    "        por_1 = por - max_por     # append the change of the polarization\n",
    "        results.append((v2, por_1))\n",
    "        real_por1.append((v2,innat_por))\n",
    "#         print(\"innate_por \",real_por1)\n",
    "    results.append((v1,0)) # minimizer cannot choose v1, but we need all nodes for the dataframe\n",
    "    real_por1.append((v1,innat_por))\n",
    "\n",
    "    innate_por_dict = dict(real_por1)\n",
    "#     actual_por_dict = dict(sorted(actual_por.items(), key=lambda x:x[0]))  \n",
    "    \n",
    "    actual_Y = dict(results) # now we have - node:polarization\n",
    "    # most of v are in sequential order, but v1 might not be in order, so we need to sort it\n",
    "    actual_Y_dict = dict(sorted(actual_Y.items(), key=lambda x:x[0]))   #sort - list nodes in sequential of the node index\n",
    "\n",
    "    actual_Y_dict_scale = rescale(actual_Y_dict)\n",
    "\n",
    "\n",
    "    # create the rank of the Y values based on minimizer's choice \n",
    "    actual_Y_order = dict(sorted(actual_Y.items(), key=lambda x:x[1]))  #sort - list nodes in sequential of the polariz.\n",
    "    node_ranks= dict(zip(actual_Y_order.keys(), all_1)) # dictionary -  node:polarization rank(replace polarz. with rank)\n",
    "    actual_ranks = dict(sorted(node_ranks.items(), key=lambda x:x[0])) # sort - list node in sequential node index\n",
    "    \n",
    "    return (actual_Y_dict, actual_ranks, innate_por_dict)  # return two dictionary, 1. sequential node: polarization, \n",
    "                                                                # 2. seq. node: pol rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e326fade",
   "metadata": {},
   "source": [
    "# Creat Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e9e6c4c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent18 's opinion 0.1801356806087211 changed to 1\n",
      "Min Action:    Agent12 's opinion 0.04059978984611734 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.036744546181292706\n",
      "MinPaths_sort: {0: 0.75, 1: 1.0, 2: 0.75, 3: 1.0, 4: 1.0, 5: 0.75, 6: 0.75, 7: 0.75, 8: 1.0, 9: 0.75, 10: 1.0, 11: 1.0, 12: 1.0, 13: 0.5, 14: 1.0, 15: 0.75, 16: 0.75, 17: 0.5, 18: 0.0, 19: 1.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent18 's opinion 0.7302572985610319 changed to 1\n",
      "Min Action:    Agent0 's opinion 0.06724962727808181 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.05219091391913133\n",
      "MinPaths_sort: {0: 1.0, 1: 0.75, 2: 0.75, 3: 0.75, 4: 0.75, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.75, 9: 0.75, 10: 0.5, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.75, 15: 0.75, 16: 0.5, 17: 0.75, 18: 0.0, 19: 1.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.630683624464088 changed to 0\n",
      "Min Action:    Agent18 's opinion 0.0690154475079332 changed to 0.8655106774543213\n",
      "Network reaches equilibrium Polarization: 0.031345020814130264\n",
      "MinPaths_sort: {0: 0.5, 1: 0.75, 2: 0.75, 3: 1.0, 4: 0.75, 5: 0.75, 6: 0.75, 7: 1.0, 8: 0.75, 9: 1.0, 10: 0.75, 11: 0.75, 12: 0.75, 13: 1.0, 14: 1.0, 15: 0.75, 16: 0.5, 17: 0.5, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.09237664032106985 changed to 1\n",
      "Min Action:    Agent7 's opinion 0.0477421634809454 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.08328201915890862\n",
      "MinPaths_sort: {0: 0.75, 1: 0.75, 2: 0.75, 3: 1.0, 4: 0.75, 5: 0.75, 6: 0.5, 7: 0.75, 8: 0.75, 9: 1.0, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.75, 14: 1.0, 15: 0.75, 16: 0.75, 17: 1.0, 18: 1.0, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.24849589506009617 changed to 0\n",
      "Min Action:    Agent17 's opinion 0.8459300613445022 changed to 0.3488656692096414\n",
      "Network reaches equilibrium Polarization: 0.07210532002721197\n",
      "MinPaths_sort: {0: 0.8, 1: 0.8, 2: 0.8, 3: 0.8, 4: 0.6000000000000001, 5: 0.8, 6: 0.6000000000000001, 7: 0.8, 8: 0.8, 9: 0.6000000000000001, 10: 0.8, 11: 0.8, 12: 0.6000000000000001, 13: 1.0, 14: 0.8, 15: 0.6000000000000001, 16: 0.8, 17: 0.8, 18: 0.4, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.5810633452354207 changed to 1\n",
      "Min Action:    Agent17 's opinion 0.04901325209700158 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.11835910221684484\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 1.0, 5: 1.0, 6: 1.0, 7: 1.0, 8: 1.0, 9: 0.75, 10: 0.75, 11: 0.75, 12: 1.0, 13: 0.75, 14: 1.0, 15: 0.75, 16: 0.5, 17: 1.0, 18: 0.75, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.27388942453480014 changed to 0\n",
      "Min Action:    Agent6 's opinion 0.875525249512481 changed to 0.15583108107815588\n",
      "Network reaches equilibrium Polarization: 0.04305394595468203\n",
      "MinPaths_sort: {0: 0.75, 1: 1.0, 2: 0.75, 3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 7: 0.75, 8: 1.0, 9: 0.75, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.75, 15: 0.75, 16: 0.5, 17: 0.75, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent18 's opinion 0.841522290079038 changed to 0\n",
      "Min Action:    Agent19 's opinion 0.22758704496244986 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.035024547212103505\n",
      "MinPaths_sort: {0: 0.75, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.75, 15: 0.75, 16: 0.75, 17: 0.5, 18: 0.0, 19: 0.5}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.38346385717422526 changed to 1\n",
      "Min Action:    Agent18 's opinion 0.08765185014746324 changed to 0.779366339666869\n",
      "Network reaches equilibrium Polarization: 0.06905869045305046\n",
      "MinPaths_sort: {0: 0.75, 1: 0.75, 2: 0.75, 3: 1.0, 4: 1.0, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 0.5, 10: 0.75, 11: 1.0, 12: 1.0, 13: 0.75, 14: 1.0, 15: 1.0, 16: 1.0, 17: 0.75, 18: 1.0, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.4415461051839734 changed to 0\n",
      "Min Action:    Agent3 's opinion 0.9081841307604551 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.03561370232189777\n",
      "MinPaths_sort: {0: 1.0, 1: 0.75, 2: 1.0, 3: 1.0, 4: 0.75, 5: 1.0, 6: 0.75, 7: 1.0, 8: 1.0, 9: 1.0, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.75, 14: 1.0, 15: 0.75, 16: 0.75, 17: 0.5, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.8536353345919081 changed to 1\n",
      "Min Action:    Agent12 's opinion 0.020466604187458715 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.029081832951980018\n",
      "MinPaths_sort: {0: 0.75, 1: 1.0, 2: 0.75, 3: 0.5, 4: 0.75, 5: 1.0, 6: 0.75, 7: 0.75, 8: 1.0, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.75, 15: 0.75, 16: 0.5, 17: 0.75, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent17 's opinion 0.4411225216917184 changed to 1\n",
      "Min Action:    Agent14 's opinion 0.9924785346133403 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.028136619258777328\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 0.6666666666666666, 5: 1.0, 6: 1.0, 7: 1.0, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.6666666666666666, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.0, 18: 1.0, 19: 1.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.7943941562025961 changed to 1\n",
      "Min Action:    Agent18 's opinion 0.8478012297387597 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.07334499221055787\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 0.75, 3: 1.0, 4: 1.0, 5: 0.75, 6: 1.0, 7: 1.0, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 1.0, 14: 1.0, 15: 1.0, 16: 0.75, 17: 0.75, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent18 's opinion 0.6077802766396644 changed to 1\n",
      "Min Action:    Agent19 's opinion 0.8750282651717496 changed to 0.22467733490445868\n",
      "Network reaches equilibrium Polarization: 0.03657266767702294\n",
      "MinPaths_sort: {0: 0.75, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.75, 5: 0.75, 6: 1.0, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 1.0, 12: 1.0, 13: 0.75, 14: 0.75, 15: 0.75, 16: 0.75, 17: 1.0, 18: 0.0, 19: 0.5}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent17 's opinion 0.14898565060420077 changed to 1\n",
      "Min Action:    Agent18 's opinion 0.8437488184820028 changed to 0.20357810131830892\n",
      "Network reaches equilibrium Polarization: 0.03875185100475831\n",
      "MinPaths_sort: {0: 0.75, 1: 0.75, 2: 1.0, 3: 0.75, 4: 0.75, 5: 0.75, 6: 1.0, 7: 0.75, 8: 0.75, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.5, 14: 0.75, 15: 0.5, 16: 0.5, 17: 0.0, 18: 0.5, 19: 0.5}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.6351596331636137 changed to 1\n",
      "Min Action:    Agent17 's opinion 0.9114935143982377 changed to 0.4034403471908411\n",
      "Network reaches equilibrium Polarization: 0.040630499929721176\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.75, 4: 1.0, 5: 1.0, 6: 0.75, 7: 1.0, 8: 1.0, 9: 1.0, 10: 1.0, 11: 0.75, 12: 1.0, 13: 1.0, 14: 0.75, 15: 1.0, 16: 0.75, 17: 0.5, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.40458978416929336 changed to 0\n",
      "Min Action:    Agent18 's opinion 0.16375263434235376 changed to 0.6007146667198604\n",
      "Network reaches equilibrium Polarization: 0.02486671792641195\n",
      "MinPaths_sort: {0: 1.0, 1: 0.75, 2: 1.0, 3: 0.75, 4: 0.75, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.75, 15: 0.75, 16: 0.75, 17: 0.5, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.31502624282824354 changed to 0\n",
      "Min Action:    Agent17 's opinion 0.04502986788003538 changed to 0.7438473777103563\n",
      "Network reaches equilibrium Polarization: 0.025856969854688935\n",
      "MinPaths_sort: {0: 0.75, 1: 0.75, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 1.0, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.75, 15: 0.5, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.8629272637368336 changed to 1\n",
      "Min Action:    Agent2 's opinion 0.06774113006480964 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.07404452327466046\n",
      "MinPaths_sort: {0: 1.0, 1: 0.75, 2: 0.75, 3: 1.0, 4: 0.75, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.75, 9: 1.0, 10: 0.75, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.5, 15: 0.75, 16: 0.75, 17: 1.0, 18: 1.0, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.8124917186201838 changed to 1\n",
      "Min Action:    Agent18 's opinion 0.004915534306718539 changed to 0.7713167797527674\n",
      "Network reaches equilibrium Polarization: 0.07780470402563758\n",
      "MinPaths_sort: {0: 1.0, 1: 0.75, 2: 0.5, 3: 0.75, 4: 0.75, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 1.0, 10: 0.75, 11: 1.0, 12: 0.75, 13: 0.75, 14: 1.0, 15: 1.0, 16: 0.75, 17: 1.0, 18: 1.0, 19: 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent18 's opinion 0.6647966199213851 changed to 0\n",
      "Min Action:    Agent19 's opinion 0.09655575589334375 changed to 0.5344622551326101\n",
      "Network reaches equilibrium Polarization: 0.03839593305035313\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 7: 1.0, 8: 1.0, 9: 1.0, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 1.0, 14: 0.6666666666666666, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 1.0, 18: 0.0, 19: 1.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.3091679891400314 changed to 0\n",
      "Min Action:    Agent0 's opinion 0.9365106213335936 changed to 0.1420855004262946\n",
      "Network reaches equilibrium Polarization: 0.028540003520913428\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 0.6666666666666666, 3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 7: 1.0, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.6666666666666666, 13: 1.0, 14: 1.0, 15: 0.6666666666666666, 16: 1.0, 17: 0.6666666666666666, 18: 1.0, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent18 's opinion 0.800926619458462 changed to 0\n",
      "Min Action:    Agent16 's opinion 0.16891061219483372 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.027630891938828617\n",
      "MinPaths_sort: {0: 0.75, 1: 0.75, 2: 0.75, 3: 1.0, 4: 1.0, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 1.0, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.5, 15: 0.75, 16: 0.5, 17: 0.75, 18: 0.0, 19: 0.5}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.6046784112306995 changed to 0\n",
      "Min Action:    Agent3 's opinion 0.9734360533705 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.04267030252507231\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 0.6666666666666666, 5: 1.0, 6: 1.0, 7: 1.0, 8: 0.6666666666666666, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 0.6666666666666666, 17: 1.0, 18: 1.0, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.7326664786780992 changed to 0\n",
      "Min Action:    Agent18 's opinion 0.8859722153711175 changed to 0.5255021423222561\n",
      "Network reaches equilibrium Polarization: 0.04619550556864519\n",
      "MinPaths_sort: {0: 0.5, 1: 0.75, 2: 0.75, 3: 0.75, 4: 0.75, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.75, 9: 1.0, 10: 0.75, 11: 0.75, 12: 1.0, 13: 0.75, 14: 0.75, 15: 1.0, 16: 0.75, 17: 1.0, 18: 1.0, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.6547105655046355 changed to 0\n",
      "Min Action:    Agent18 's opinion 0.8877493709314288 changed to 0.040688920764647356\n",
      "Network reaches equilibrium Polarization: 0.07664167271543172\n",
      "MinPaths_sort: {0: 0.75, 1: 0.5, 2: 0.75, 3: 0.75, 4: 0.75, 5: 1.0, 6: 1.0, 7: 0.75, 8: 0.75, 9: 0.75, 10: 1.0, 11: 1.0, 12: 0.75, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.44381194995453044 changed to 0\n",
      "Min Action:    Agent18 's opinion 0.14710443736486356 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.07483165132198781\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 0.75, 6: 1.0, 7: 1.0, 8: 0.75, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.75, 15: 1.0, 16: 1.0, 17: 0.75, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent18 's opinion 0.6977556925644126 changed to 0\n",
      "Min Action:    Agent3 's opinion 0.9899534657917828 changed to 0.26039505675165536\n",
      "Network reaches equilibrium Polarization: 0.0253665632451368\n",
      "MinPaths_sort: {0: 0.75, 1: 0.75, 2: 0.75, 3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 7: 0.75, 8: 0.75, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.5, 14: 0.75, 15: 0.5, 16: 0.75, 17: 0.75, 18: 0.0, 19: 0.5}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent18 's opinion 0.4554034362206817 changed to 0\n",
      "Min Action:    Agent17 's opinion 0.011330155688753396 changed to 0.9018730707169964\n",
      "Network reaches equilibrium Polarization: 0.04740411983319699\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 1.0, 5: 1.0, 6: 1.0, 7: 1.0, 8: 1.0, 9: 1.0, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.5, 15: 0.75, 16: 0.75, 17: 0.5, 18: 0.0, 19: 1.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.8092033861474842 changed to 1\n",
      "Min Action:    Agent17 's opinion 0.1068362169263335 changed to 0.5011040046981159\n",
      "Network reaches equilibrium Polarization: 0.018796690127767208\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 0.6666666666666666, 16: 1.0, 17: 1.0, 18: 0.6666666666666666, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.7701065024451106 changed to 0\n",
      "Min Action:    Agent7 's opinion 0.8783462872446145 changed to 0.183623522872448\n",
      "Network reaches equilibrium Polarization: 0.03663588134625536\n",
      "MinPaths_sort: {0: 0.75, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.75, 5: 0.75, 6: 1.0, 7: 1.0, 8: 0.75, 9: 1.0, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.5, 15: 0.75, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.15438216658910353 changed to 1\n",
      "Min Action:    Agent18 's opinion 0.19664600577999547 changed to 0.6798571408075903\n",
      "Network reaches equilibrium Polarization: 0.07731176532023948\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 0.75, 3: 1.0, 4: 1.0, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.75, 9: 0.75, 10: 0.75, 11: 0.75, 12: 1.0, 13: 0.75, 14: 0.5, 15: 0.75, 16: 0.75, 17: 0.75, 18: 1.0, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.5229377318053833 changed to 0\n",
      "Min Action:    Agent2 's opinion 0.9972296869587256 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.07842946712673196\n",
      "MinPaths_sort: {0: 0.75, 1: 1.0, 2: 1.0, 3: 0.75, 4: 0.75, 5: 0.75, 6: 1.0, 7: 0.75, 8: 1.0, 9: 1.0, 10: 0.5, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.75, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.1758202594855114 changed to 1\n",
      "Min Action:    Agent11 's opinion 0.13997605029193805 changed to 0.8563826392583735\n",
      "Network reaches equilibrium Polarization: 0.02668281333671827\n",
      "MinPaths_sort: {0: 0.75, 1: 0.75, 2: 1.0, 3: 0.75, 4: 0.75, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.75, 9: 0.75, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.75, 15: 0.5, 16: 0.5, 17: 0.75, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.5932293880695779 changed to 0\n",
      "Min Action:    Agent17 's opinion 0.21796392046120172 changed to 0.8903899801051333\n",
      "Network reaches equilibrium Polarization: 0.025805435956233105\n",
      "MinPaths_sort: {0: 0.75, 1: 0.75, 2: 0.75, 3: 0.75, 4: 1.0, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.75, 9: 0.5, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.75, 14: 1.0, 15: 0.75, 16: 0.75, 17: 0.5, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.5287482474997219 changed to 0\n",
      "Min Action:    Agent17 's opinion 0.9384155189344032 changed to 0.2686373249821213\n",
      "Network reaches equilibrium Polarization: 0.03417841349465936\n",
      "MinPaths_sort: {0: 0.5, 1: 0.75, 2: 0.75, 3: 0.75, 4: 0.75, 5: 0.5, 6: 0.75, 7: 0.75, 8: 1.0, 9: 0.75, 10: 0.75, 11: 1.0, 12: 1.0, 13: 0.75, 14: 0.75, 15: 0.75, 16: 1.0, 17: 0.75, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.3474202140912759 changed to 0\n",
      "Min Action:    Agent1 's opinion 0.9496219874424411 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.04632200103340062\n",
      "MinPaths_sort: {0: 0.75, 1: 0.75, 2: 0.75, 3: 0.75, 4: 0.75, 5: 0.75, 6: 0.5, 7: 0.75, 8: 0.75, 9: 0.75, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.75, 14: 1.0, 15: 0.5, 16: 0.75, 17: 1.0, 18: 0.75, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.7210590135955901 changed to 1\n",
      "Min Action:    Agent17 's opinion 0.7523876571662935 changed to 0.11766091298890936\n",
      "Network reaches equilibrium Polarization: 0.04253596350370904\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.75, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.75, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.75, 14: 1.0, 15: 1.0, 16: 1.0, 17: 0.5, 18: 0.75, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.2950442687797169 changed to 0\n",
      "Min Action:    Agent17 's opinion 0.22679761232376128 changed to 0.8494202157769254\n",
      "Network reaches equilibrium Polarization: 0.035604013518380474\n",
      "MinPaths_sort: {0: 0.75, 1: 0.75, 2: 0.75, 3: 0.75, 4: 0.75, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.75, 9: 0.75, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.75, 15: 0.5, 16: 0.75, 17: 0.5, 18: 1.0, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.4025184916663216 changed to 1\n",
      "Min Action:    Agent9 's opinion 0.0701599513605915 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.03958119519540033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinPaths_sort: {0: 0.75, 1: 0.75, 2: 0.75, 3: 0.5, 4: 0.75, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 1.0, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.5, 14: 0.75, 15: 0.75, 16: 0.75, 17: 1.0, 18: 1.0, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent18 's opinion 0.37997728776585993 changed to 0\n",
      "Min Action:    Agent19 's opinion 0.9549173152300214 changed to 0.43840232563787707\n",
      "Network reaches equilibrium Polarization: 0.02270549399017212\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0, 6: 0.6666666666666666, 7: 1.0, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.6666666666666666, 13: 0.6666666666666666, 14: 1.0, 15: 1.0, 16: 0.6666666666666666, 17: 0.6666666666666666, 18: 0.0, 19: 1.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.4690700349162209 changed to 0\n",
      "Min Action:    Agent18 's opinion 0.9264221883378011 changed to 0.514477452956045\n",
      "Network reaches equilibrium Polarization: 0.03912355474285053\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 7: 1.0, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.75, 15: 1.0, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.5200313510614751 changed to 0\n",
      "Min Action:    Agent9 's opinion 0.8865109181277561 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.06855055558554937\n",
      "MinPaths_sort: {0: 1.0, 1: 0.75, 2: 1.0, 3: 0.75, 4: 1.0, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.75, 13: 1.0, 14: 0.75, 15: 0.75, 16: 1.0, 17: 1.0, 18: 0.75, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.5963954246327744 changed to 0\n",
      "Min Action:    Agent17 's opinion 0.9353068846000857 changed to 0.6765173717822414\n",
      "Network reaches equilibrium Polarization: 0.05939765628581531\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 0.75, 3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 7: 1.0, 8: 1.0, 9: 1.0, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.75, 14: 1.0, 15: 0.75, 16: 0.5, 17: 0.75, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.18190458341033755 changed to 0\n",
      "Min Action:    Agent17 's opinion 0.7926619504434897 changed to 0.3246177757828134\n",
      "Network reaches equilibrium Polarization: 0.028201748596184913\n",
      "MinPaths_sort: {0: 0.75, 1: 0.5, 2: 0.75, 3: 0.75, 4: 0.75, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 0.75, 10: 0.5, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.5, 15: 0.75, 16: 0.75, 17: 1.0, 18: 1.0, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.8791123558284645 changed to 1\n",
      "Min Action:    Agent1 's opinion 0.0404946642095696 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.07923266224944298\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 0.75, 3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 7: 1.0, 8: 1.0, 9: 0.75, 10: 0.75, 11: 1.0, 12: 1.0, 13: 0.75, 14: 0.75, 15: 1.0, 16: 1.0, 17: 1.0, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent15 's opinion 0.6880718867916142 changed to 1\n",
      "Min Action:    Agent16 's opinion 0.8899811687943648 changed to 0.3875608290307531\n",
      "Network reaches equilibrium Polarization: 0.025371040368712818\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 1.0, 8: 1.0, 9: 0.6666666666666666, 10: 0.6666666666666666, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.6666666666666666, 15: 0.0, 16: 0.6666666666666666, 17: 0.6666666666666666, 18: 1.0, 19: 1.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.26291498632623744 changed to 1\n",
      "Min Action:    Agent3 's opinion 0.08409371124134635 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.06226108423897552\n",
      "MinPaths_sort: {0: 1.0, 1: 0.75, 2: 0.75, 3: 0.75, 4: 0.75, 5: 0.75, 6: 1.0, 7: 0.75, 8: 1.0, 9: 0.75, 10: 1.0, 11: 0.75, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.5, 16: 0.75, 17: 0.75, 18: 1.0, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent13 's opinion 0.20564906180723874 changed to 1\n",
      "Min Action:    Agent18 's opinion 0.10170939330934226 changed to 0.6536850639867521\n",
      "Network reaches equilibrium Polarization: 0.018935162404206726\n",
      "MinPaths_sort: {0: 0.6666666666666666, 1: 1.0, 2: 0.6666666666666666, 3: 1.0, 4: 0.6666666666666666, 5: 1.0, 6: 1.0, 7: 1.0, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 0.6666666666666666, 13: 0.0, 14: 0.6666666666666666, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent17 's opinion 0.2592633690064451 changed to 1\n",
      "Min Action:    Agent16 's opinion 0.6235301224166258 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.027665928306960554\n",
      "MinPaths_sort: {0: 0.75, 1: 0.75, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.75, 8: 1.0, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.75, 14: 0.75, 15: 0.5, 16: 0.5, 17: 0.0, 18: 0.75, 19: 0.75}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.6814039875406346 changed to 1\n",
      "Min Action:    Agent1 's opinion 0.04290513743854829 changed to 0.9865714362955516\n",
      "Network reaches equilibrium Polarization: 0.04601774590808334\n",
      "MinPaths_sort: {0: 0.75, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.75, 5: 0.75, 6: 0.5, 7: 0.75, 8: 0.75, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.75, 15: 0.75, 16: 0.75, 17: 1.0, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.20284151127328098 changed to 1\n",
      "Min Action:    Agent13 's opinion 0.037962859324426 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.08834899410059788\n",
      "MinPaths_sort: {0: 1.0, 1: 0.75, 2: 0.75, 3: 0.75, 4: 1.0, 5: 1.0, 6: 1.0, 7: 0.75, 8: 0.75, 9: 0.75, 10: 1.0, 11: 0.75, 12: 1.0, 13: 0.75, 14: 1.0, 15: 0.5, 16: 0.75, 17: 1.0, 18: 1.0, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.5100168585886327 changed to 0\n",
      "Min Action:    Agent3 's opinion 0.9258587794710896 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.050244300255593934\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 0.75, 6: 0.75, 7: 1.0, 8: 1.0, 9: 1.0, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.5, 15: 0.75, 16: 0.75, 17: 0.75, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent18 's opinion 0.21682864328650664 changed to 0\n",
      "Min Action:    Agent19 's opinion 0.11087750527226337 changed to 0.49079173286497746\n",
      "Network reaches equilibrium Polarization: 0.03937895020704477\n",
      "MinPaths_sort: {0: 0.75, 1: 0.75, 2: 0.5, 3: 0.75, 4: 0.75, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.75, 15: 1.0, 16: 0.75, 17: 0.5, 18: 0.0, 19: 1.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.577236154808555 changed to 0\n",
      "Min Action:    Agent1 's opinion 0.9281129809969537 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.0781620111199916\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 7: 1.0, 8: 1.0, 9: 0.75, 10: 0.75, 11: 1.0, 12: 1.0, 13: 0.75, 14: 0.75, 15: 0.5, 16: 0.75, 17: 1.0, 18: 0.75, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.7768229449227879 changed to 0\n",
      "Min Action:    Agent18 's opinion 0.05556405768719075 changed to 0.9503342573011148\n",
      "Network reaches equilibrium Polarization: 0.038778747784597695\n",
      "MinPaths_sort: {0: 1.0, 1: 0.75, 2: 1.0, 3: 1.0, 4: 1.0, 5: 0.75, 6: 1.0, 7: 1.0, 8: 0.75, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.75, 13: 0.75, 14: 1.0, 15: 0.75, 16: 0.75, 17: 0.75, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.3309240462696249 changed to 0\n",
      "Min Action:    Agent18 's opinion 0.8565041858516087 changed to 0.31373569750008384\n",
      "Network reaches equilibrium Polarization: 0.04655438507690624\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 0.75, 6: 1.0, 7: 1.0, 8: 0.75, 9: 0.75, 10: 0.75, 11: 1.0, 12: 0.75, 13: 1.0, 14: 0.75, 15: 0.75, 16: 0.5, 17: 0.5, 18: 1.0, 19: 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.5969829436566241 changed to 0\n",
      "Min Action:    Agent17 's opinion 0.983908266448721 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.08123107719499663\n",
      "MinPaths_sort: {0: 0.75, 1: 0.75, 2: 0.75, 3: 1.0, 4: 0.75, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.75, 13: 1.0, 14: 1.0, 15: 0.75, 16: 0.75, 17: 1.0, 18: 1.0, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent17 's opinion 0.4470237067304689 changed to 0\n",
      "Min Action:    Agent8 's opinion 0.9070680207570609 changed to 0.224452899527764\n",
      "Network reaches equilibrium Polarization: 0.03171132338095313\n",
      "MinPaths_sort: {0: 0.6666666666666666, 1: 1.0, 2: 1.0, 3: 0.6666666666666666, 4: 1.0, 5: 1.0, 6: 1.0, 7: 1.0, 8: 0.6666666666666666, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.0, 18: 0.6666666666666666, 19: 1.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent18 's opinion 0.4758152346008784 changed to 1\n",
      "Min Action:    Agent10 's opinion 0.022150267019747094 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.03463084267393542\n",
      "MinPaths_sort: {0: 0.5, 1: 0.75, 2: 0.75, 3: 0.75, 4: 1.0, 5: 0.75, 6: 1.0, 7: 0.75, 8: 0.75, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.75, 15: 0.75, 16: 0.75, 17: 0.5, 18: 0.0, 19: 0.5}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.8369387324379003 changed to 0\n",
      "Min Action:    Agent16 's opinion 0.009764660516284551 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.04323750668487012\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 0.75, 5: 0.75, 6: 1.0, 7: 1.0, 8: 0.75, 9: 0.75, 10: 1.0, 11: 0.75, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.75, 16: 0.5, 17: 1.0, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.8728974469951133 changed to 1\n",
      "Min Action:    Agent18 's opinion 0.8301297432017636 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.066296910250174\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.75, 4: 0.75, 5: 1.0, 6: 0.75, 7: 1.0, 8: 1.0, 9: 0.75, 10: 1.0, 11: 1.0, 12: 1.0, 13: 0.75, 14: 1.0, 15: 1.0, 16: 0.75, 17: 0.75, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.4962313479685877 changed to 1\n",
      "Min Action:    Agent17 's opinion 0.1287135537247741 changed to 0.6802793602422021\n",
      "Network reaches equilibrium Polarization: 0.015974772561063805\n",
      "MinPaths_sort: {0: 0.75, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.75, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 0.5, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.75, 14: 0.75, 15: 0.75, 16: 0.5, 17: 0.75, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.3360668092865017 changed to 0\n",
      "Min Action:    Agent13 's opinion 0.9374882111184374 changed to 0.20656490889243917\n",
      "Network reaches equilibrium Polarization: 0.038235612977968646\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.75, 5: 0.75, 6: 0.75, 7: 0.75, 8: 1.0, 9: 0.75, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.5, 15: 0.75, 16: 0.5, 17: 0.75, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.03240389731953286 changed to 1\n",
      "Min Action:    Agent11 's opinion 0.07861046643012015 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.02484936701193025\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 1.0, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.6666666666666666, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 0.6666666666666666, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.38462043758837827 changed to 0\n",
      "Min Action:    Agent7 's opinion 0.9226398621176309 changed to 0.09091612459486294\n",
      "Network reaches equilibrium Polarization: 0.025086077398349737\n",
      "MinPaths_sort: {0: 0.75, 1: 0.75, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.5, 11: 0.75, 12: 0.75, 13: 0.75, 14: 1.0, 15: 0.75, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent18 's opinion 0.45095483961458727 changed to 0\n",
      "Min Action:    Agent8 's opinion 0.9886704034330563 changed to 0.20560286331103264\n",
      "Network reaches equilibrium Polarization: 0.028578905670074845\n",
      "MinPaths_sort: {0: 1.0, 1: 0.75, 2: 0.75, 3: 0.75, 4: 0.75, 5: 0.75, 6: 0.75, 7: 0.75, 8: 1.0, 9: 1.0, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.5, 15: 0.5, 16: 0.75, 17: 0.75, 18: 0.0, 19: 0.5}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.6831689566520235 changed to 1\n",
      "Min Action:    Agent8 's opinion 0.02790637444664079 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.03175884451343321\n",
      "MinPaths_sort: {0: 0.75, 1: 0.75, 2: 0.5, 3: 0.75, 4: 0.75, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 1.0, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.5, 14: 0.75, 15: 0.75, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.676322607454205 changed to 1\n",
      "Min Action:    Agent12 's opinion 0.14833108370845205 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.06782222983134327\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.75, 4: 1.0, 5: 0.75, 6: 1.0, 7: 0.75, 8: 0.75, 9: 0.75, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.75, 15: 0.75, 16: 0.5, 17: 0.75, 18: 1.0, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.23683429235149 changed to 1\n",
      "Min Action:    Agent1 's opinion 0.15114640047467454 changed to 0.9492424846186974\n",
      "Network reaches equilibrium Polarization: 0.021580434170367764\n",
      "MinPaths_sort: {0: 0.75, 1: 0.75, 2: 0.75, 3: 0.75, 4: 0.75, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 0.5, 10: 0.5, 11: 0.5, 12: 0.75, 13: 0.75, 14: 0.75, 15: 1.0, 16: 0.75, 17: 1.0, 18: 1.0, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent18 's opinion 0.5261070919417458 changed to 0\n",
      "Min Action:    Agent14 's opinion 0.9681728873155536 changed to 0.5148973742256732\n",
      "Network reaches equilibrium Polarization: 0.019339252996102646\n",
      "MinPaths_sort: {0: 0.75, 1: 0.75, 2: 1.0, 3: 0.75, 4: 0.75, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.75, 13: 0.5, 14: 0.75, 15: 0.5, 16: 0.75, 17: 0.75, 18: 0.0, 19: 0.5}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.32564094755958006 changed to 0\n",
      "Min Action:    Agent16 's opinion 0.8733835621561984 changed to 0.2875743277814848\n",
      "Network reaches equilibrium Polarization: 0.0488378450670611\n",
      "MinPaths_sort: {0: 0.75, 1: 0.75, 2: 0.75, 3: 0.75, 4: 1.0, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 0.5, 10: 0.5, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.75, 15: 0.75, 16: 0.75, 17: 0.75, 18: 1.0, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.7945787966907194 changed to 1\n",
      "Min Action:    Agent8 's opinion 0.06300566275152375 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.0779674142039877\n",
      "MinPaths_sort: {0: 1.0, 1: 0.8, 2: 0.8, 3: 0.8, 4: 0.8, 5: 0.6000000000000001, 6: 0.6000000000000001, 7: 0.6000000000000001, 8: 0.8, 9: 0.8, 10: 0.6000000000000001, 11: 0.6000000000000001, 12: 0.8, 13: 0.8, 14: 0.4, 15: 0.6000000000000001, 16: 0.6000000000000001, 17: 0.6000000000000001, 18: 0.8, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.5549597537545131 changed to 1\n",
      "Min Action:    Agent17 's opinion 0.016424622393980792 changed to 0.5538708716886713\n",
      "Network reaches equilibrium Polarization: 0.06435534651773843\n",
      "MinPaths_sort: {0: 0.5, 1: 0.75, 2: 0.75, 3: 1.0, 4: 0.75, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 1.0, 10: 0.75, 11: 0.75, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.75, 16: 0.5, 17: 1.0, 18: 1.0, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.6516884700838445 changed to 1\n",
      "Min Action:    Agent18 's opinion 0.951001065096271 changed to 0.0032088896860115127\n",
      "Network reaches equilibrium Polarization: 0.06467971763777904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinPaths_sort: {0: 0.8, 1: 0.6000000000000001, 2: 1.0, 3: 0.8, 4: 0.8, 5: 1.0, 6: 0.8, 7: 0.8, 8: 1.0, 9: 1.0, 10: 0.8, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.8, 15: 1.0, 16: 1.0, 17: 1.0, 18: 0.4, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.2177807800124203 changed to 0\n",
      "Min Action:    Agent0 's opinion 0.8858186495586262 changed to 0.019273406888511164\n",
      "Network reaches equilibrium Polarization: 0.028068548695030986\n",
      "MinPaths_sort: {0: 1.0, 1: 0.75, 2: 1.0, 3: 0.75, 4: 1.0, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 0.75, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.75, 15: 0.5, 16: 0.5, 17: 0.75, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent17 's opinion 0.4504579472458815 changed to 0\n",
      "Min Action:    Agent16 's opinion 0.3056113323664439 changed to 0.8173619963226848\n",
      "Network reaches equilibrium Polarization: 0.024345219435290187\n",
      "MinPaths_sort: {0: 1.0, 1: 0.75, 2: 1.0, 3: 0.75, 4: 0.75, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 0.75, 10: 0.75, 11: 0.75, 12: 1.0, 13: 0.5, 14: 0.75, 15: 1.0, 16: 0.5, 17: 0.0, 18: 0.75, 19: 0.5}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.9697539569674918 changed to 1\n",
      "Min Action:    Agent17 's opinion 0.02141675426816292 changed to 0.8942974350101055\n",
      "Network reaches equilibrium Polarization: 0.08006865652123703\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.75, 4: 1.0, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 1.0, 10: 0.75, 11: 0.5, 12: 0.75, 13: 0.75, 14: 1.0, 15: 1.0, 16: 1.0, 17: 0.75, 18: 1.0, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.12008763892420216 changed to 1\n",
      "Min Action:    Agent18 's opinion 0.9522023388024706 changed to 0.43967928174509574\n",
      "Network reaches equilibrium Polarization: 0.031750897989403296\n",
      "MinPaths_sort: {0: 0.75, 1: 0.75, 2: 0.75, 3: 0.5, 4: 0.75, 5: 0.75, 6: 0.75, 7: 0.75, 8: 1.0, 9: 0.75, 10: 0.75, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.75, 15: 0.75, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent18 's opinion 0.7452719242216586 changed to 0\n",
      "Min Action:    Agent9 's opinion 0.9369060948068357 changed to 0.39831048182608925\n",
      "Network reaches equilibrium Polarization: 0.03389004638069158\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 0.75, 5: 0.75, 6: 1.0, 7: 1.0, 8: 0.75, 9: 1.0, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.5, 15: 0.75, 16: 0.75, 17: 0.5, 18: 0.0, 19: 0.5}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.8844605244571491 changed to 0\n",
      "Min Action:    Agent16 's opinion 0.9886088501783632 changed to 0.21335539611388685\n",
      "Network reaches equilibrium Polarization: 0.025978055687192976\n",
      "MinPaths_sort: {0: 0.75, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.75, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.75, 14: 0.5, 15: 0.75, 16: 0.75, 17: 0.75, 18: 1.0, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent18 's opinion 0.3491959379330515 changed to 1\n",
      "Min Action:    Agent1 's opinion 0.06444860845805955 changed to 0.594888999167454\n",
      "Network reaches equilibrium Polarization: 0.02028004246224556\n",
      "MinPaths_sort: {0: 1.0, 1: 0.75, 2: 0.75, 3: 0.75, 4: 0.75, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.75, 9: 0.5, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.75, 14: 0.75, 15: 0.5, 16: 0.75, 17: 0.5, 18: 0.0, 19: 0.75}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.28728445325379715 changed to 0\n",
      "Min Action:    Agent18 's opinion 0.9635047537860835 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.06995497260885239\n",
      "MinPaths_sort: {0: 0.75, 1: 0.75, 2: 0.5, 3: 0.75, 4: 0.75, 5: 0.75, 6: 1.0, 7: 0.75, 8: 0.75, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.75, 15: 1.0, 16: 0.75, 17: 0.75, 18: 1.0, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.6122445572189513 changed to 0\n",
      "Min Action:    Agent18 's opinion 0.849797582314687 changed to 0.40107493406912714\n",
      "Network reaches equilibrium Polarization: 0.025120641203533092\n",
      "MinPaths_sort: {0: 0.75, 1: 0.75, 2: 0.75, 3: 0.75, 4: 0.75, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.5, 15: 0.75, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.1314466200628862 changed to 0\n",
      "Min Action:    Agent1 's opinion 0.954613254814558 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.07351693795275482\n",
      "MinPaths_sort: {0: 0.8, 1: 0.8, 2: 0.8, 3: 0.8, 4: 0.8, 5: 0.8, 6: 0.8, 7: 0.8, 8: 0.8, 9: 0.6000000000000001, 10: 0.8, 11: 0.8, 12: 0.8, 13: 0.8, 14: 1.0, 15: 0.8, 16: 0.6000000000000001, 17: 0.6000000000000001, 18: 0.4, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.5722962084035464 changed to 0\n",
      "Min Action:    Agent15 's opinion 0.2223746487913124 changed to 0.7647431577677178\n",
      "Network reaches equilibrium Polarization: 0.025501853963334625\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.75, 5: 1.0, 6: 1.0, 7: 0.75, 8: 0.75, 9: 0.75, 10: 0.75, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.5, 15: 0.5, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.6180452178411445 changed to 0\n",
      "Min Action:    Agent4 's opinion 0.9284730690793087 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.039295523522889945\n",
      "MinPaths_sort: {0: 0.75, 1: 1.0, 2: 0.75, 3: 0.75, 4: 1.0, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.75, 13: 0.75, 14: 0.75, 15: 0.75, 16: 0.75, 17: 0.75, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.7691106262117381 changed to 0\n",
      "Min Action:    Agent17 's opinion 0.07867298592818073 changed to 0.8787630648655954\n",
      "Network reaches equilibrium Polarization: 0.029288777504350307\n",
      "MinPaths_sort: {0: 0.75, 1: 0.75, 2: 1.0, 3: 1.0, 4: 1.0, 5: 0.75, 6: 1.0, 7: 0.75, 8: 0.75, 9: 0.75, 10: 0.5, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.75, 15: 0.75, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.10628767250007365 changed to 0\n",
      "Min Action:    Agent16 's opinion 0.2677993807954133 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.06574147234319225\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.75, 4: 1.0, 5: 1.0, 6: 1.0, 7: 1.0, 8: 0.75, 9: 1.0, 10: 1.0, 11: 0.75, 12: 1.0, 13: 1.0, 14: 1.0, 15: 0.75, 16: 0.5, 17: 0.75, 18: 1.0, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.2478269352947099 changed to 0\n",
      "Min Action:    Agent18 's opinion 0.1626732365150998 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.04991556047035149\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.75, 4: 0.75, 5: 0.75, 6: 1.0, 7: 1.0, 8: 0.75, 9: 1.0, 10: 0.75, 11: 0.75, 12: 0.75, 13: 1.0, 14: 1.0, 15: 0.5, 16: 0.75, 17: 1.0, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.8836631659301435 changed to 1\n",
      "Min Action:    Agent7 's opinion 0.9070416283475393 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.044687633994770805\n",
      "MinPaths_sort: {0: 0.75, 1: 0.75, 2: 0.75, 3: 0.75, 4: 0.75, 5: 0.75, 6: 0.5, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.75, 15: 0.75, 16: 0.75, 17: 1.0, 18: 0.75, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.952163696572086 changed to 0\n",
      "Min Action:    Agent3 's opinion 0.9917649201453683 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.09261311058414672\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 0.75, 6: 1.0, 7: 1.0, 8: 0.75, 9: 0.75, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.75, 15: 1.0, 16: 1.0, 17: 0.75, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.07833204635810975 changed to 0\n",
      "Min Action:    Agent16 's opinion 0.08328032953095377 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.049825091675932624\n",
      "MinPaths_sort: {0: 0.75, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.75, 5: 0.75, 6: 0.5, 7: 0.75, 8: 0.75, 9: 1.0, 10: 0.75, 11: 0.75, 12: 0.75, 13: 1.0, 14: 0.75, 15: 0.75, 16: 0.5, 17: 0.75, 18: 0.5, 19: 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.9577759895334507 changed to 1\n",
      "Min Action:    Agent4 's opinion 0.06668902858997972 changed to 0.8924052415854019\n",
      "Network reaches equilibrium Polarization: 0.034947074043319294\n",
      "MinPaths_sort: {0: 0.75, 1: 0.5, 2: 0.75, 3: 0.75, 4: 1.0, 5: 1.0, 6: 1.0, 7: 0.75, 8: 0.75, 9: 0.75, 10: 0.75, 11: 1.0, 12: 0.75, 13: 0.5, 14: 0.75, 15: 0.75, 16: 1.0, 17: 1.0, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.4128289412997498 changed to 1\n",
      "Min Action:    Agent14 's opinion 0.11983117045044755 changed to 0.9243937839458481\n",
      "Network reaches equilibrium Polarization: 0.0466572379980322\n",
      "MinPaths_sort: {0: 1.0, 1: 0.75, 2: 1.0, 3: 0.75, 4: 1.0, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.75, 13: 1.0, 14: 0.75, 15: 0.5, 16: 0.5, 17: 0.75, 18: 1.0, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent18 's opinion 0.08918923586047289 changed to 1\n",
      "Min Action:    Agent17 's opinion 0.12560228280265828 changed to 0.6384907315863005\n",
      "Network reaches equilibrium Polarization: 0.02410681750499524\n",
      "MinPaths_sort: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 1.0, 8: 1.0, 9: 1.0, 10: 0.6666666666666666, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 0.6666666666666666, 16: 1.0, 17: 1.0, 18: 0.0, 19: 0.6666666666666666}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.8479342096134121 changed to 0\n",
      "Min Action:    Agent17 's opinion 0.9792674519772626 changed to 0.44718369512653444\n",
      "Network reaches equilibrium Polarization: 0.025026944681472405\n",
      "MinPaths_sort: {0: 0.75, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.75, 5: 0.75, 6: 0.5, 7: 0.75, 8: 0.75, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.5, 14: 0.75, 15: 1.0, 16: 0.75, 17: 0.75, 18: 0.5, 19: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent10 's opinion 0.4352221124879696 changed to 1\n",
      "Min Action:    Agent19 's opinion 0.06754895433553332 changed to 0.5150497975510039\n",
      "Network reaches equilibrium Polarization: 0.03265931088325799\n",
      "MinPaths_sort: {0: 0.6666666666666666, 1: 1.0, 2: 1.0, 3: 0.6666666666666666, 4: 1.0, 5: 1.0, 6: 1.0, 7: 1.0, 8: 0.6666666666666666, 9: 0.6666666666666666, 10: 0.0, 11: 0.6666666666666666, 12: 1.0, 13: 1.0, 14: 1.0, 15: 0.6666666666666666, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent17 's opinion 0.9848052488195601 changed to 1\n",
      "Min Action:    Agent14 's opinion 0.19748852276713091 changed to 0.9238371124301671\n",
      "Network reaches equilibrium Polarization: 0.027932895656174683\n",
      "MinPaths_sort: {0: 0.75, 1: 0.5, 2: 0.75, 3: 0.75, 4: 0.75, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 0.75, 10: 0.75, 11: 1.0, 12: 0.75, 13: 0.5, 14: 0.75, 15: 0.75, 16: 0.5, 17: 0.0, 18: 0.75, 19: 0.75}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent19 's opinion 0.9874367585924186 changed to 1\n",
      "Min Action:    Agent17 's opinion 0.7966888883652796 changed to 0.10668031927032817\n",
      "Network reaches equilibrium Polarization: 0.0255321479949328\n",
      "MinPaths_sort: {0: 0.75, 1: 0.75, 2: 1.0, 3: 0.75, 4: 0.75, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.75, 13: 0.75, 14: 0.75, 15: 0.75, 16: 0.75, 17: 0.5, 18: 0.5, 19: 0.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize an empty DataFrame to store your data\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Initialize empty lists to store data for training and testing\n",
    "train_data1 = []\n",
    "valid_data1 =[]\n",
    "test_data1 = []\n",
    "Game_result = []\n",
    "sets = 101\n",
    "for i in range(1, sets):  # Change the range if you want more iterations\n",
    "    # Your existing code here to generate data for each iteration\n",
    "    s = make_innat_opinions(n)\n",
    "    G = make_random_network(n)\n",
    "    (v1, v2, max_opinion, min_opinion, max_pol) = MaxMin_play(s, n, G)\n",
    "    Game_result.append((v2,max_pol))\n",
    "    (deg_cent, clo_cent, eigen_cent, MinPaths_sort,op_extre, cc) = metrics(G, v1)\n",
    "   # (converted_dict, converted_dict1, converted_dict2, sorted_gap, scaled_MinPaths_sort) = metrics(G, v1)\n",
    "    \n",
    "    # Calculate actual ranks and rescale polarization change\n",
    "    (actual_Y_dict, actual_ranks, innate_por_dict) = actual_rank(s, n, v1, max_opinion)\n",
    "    # rescale\n",
    "    scaled_actual_Y_dict = rescale(actual_Y_dict)\n",
    "    \n",
    "    keys = list(eigen_cent.keys())\n",
    "#     print(\"MinPaths_sort:\",MinPaths_sort)\n",
    "    # Assuming you have generated 'temp_df' as you did in your original code\n",
    "    temp_df = pd.DataFrame(({'keys': list(keys),\n",
    "                       'x1_d': [op_extre[x][0] for x in keys],\n",
    "                       'x2_deg':[deg_cent[x] for x in keys],\n",
    "                       'x3_clo':[clo_cent[x] for x in keys],\n",
    "                       'x4_eigen': [eigen_cent[x] for x in keys],\n",
    "                       'x5_path': [MinPaths_sort[x] for x in keys],\n",
    "                       'x6_cc': [cc[x] for x in keys],\n",
    "                       'x7_po':[innate_por_dict[x] for x in keys],\n",
    "                       'y_value': [scaled_actual_Y_dict[x] for x in keys],\n",
    "                        'ranks_y':[actual_ranks[x] for x in keys]}))\n",
    "\n",
    "    # Append the temporary DataFrame to the main DataFrame\n",
    "    df = pd.concat([df, temp_df], ignore_index=True)\n",
    "    \n",
    "    # Append the data to either the training or testing list\n",
    "    if i <= 0.8*sets:  # Use first 80% for trainning, adjust as needed\n",
    "        train_data1.append(temp_df)\n",
    "    elif i> 0.8*sets and i <= 0.9*sets:\n",
    "        valid_data1.append(temp_df)\n",
    "    else:\n",
    "        test_data1.append(temp_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "ec561084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(r'C:\\Users\\xzhan\\OneDrive\\Misinfo Paper\\One Node - Final\\NE Prediction\\trainning.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "81bcbd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix:\n",
      "                  keys      x1_d    x2_deg    x3_clo  x4_eigen   x5_path  \\\n",
      "keys      1.000000e+00 -0.013317 -0.597280 -0.553135 -0.685592 -0.304622   \n",
      "x1_d     -1.331696e-02  1.000000  0.015546  0.017540  0.014220 -0.029230   \n",
      "x2_deg   -5.972795e-01  0.015546  1.000000  0.987496  0.974212  0.271526   \n",
      "x3_clo   -5.531347e-01  0.017540  0.987496  1.000000  0.950147  0.215886   \n",
      "x4_eigen -6.855919e-01  0.014220  0.974212  0.950147  1.000000  0.312464   \n",
      "x5_path  -3.046219e-01 -0.029230  0.271526  0.215886  0.312464  1.000000   \n",
      "x6_cc    -5.828462e-01 -0.032999  0.486868  0.450623  0.557983  0.394565   \n",
      "x7_po     1.026901e-17  0.034135  0.002542 -0.024622 -0.007856  0.171561   \n",
      "y_value   3.350733e-02 -0.184856 -0.001048  0.002210 -0.012092 -0.185174   \n",
      "ranks_y   1.240067e-01 -0.110534 -0.125172 -0.125015 -0.133244 -0.219290   \n",
      "\n",
      "             x6_cc         x7_po   y_value       ranks_y  \n",
      "keys     -0.582846  1.026901e-17  0.033507  1.240067e-01  \n",
      "x1_d     -0.032999  3.413533e-02 -0.184856 -1.105341e-01  \n",
      "x2_deg    0.486868  2.542462e-03 -0.001048 -1.251715e-01  \n",
      "x3_clo    0.450623 -2.462238e-02  0.002210 -1.250150e-01  \n",
      "x4_eigen  0.557983 -7.855738e-03 -0.012092 -1.332440e-01  \n",
      "x5_path   0.394565  1.715613e-01 -0.185174 -2.192897e-01  \n",
      "x6_cc     1.000000 -3.127280e-02 -0.046182 -1.411969e-01  \n",
      "x7_po    -0.031273  1.000000e+00 -0.099088 -1.959393e-16  \n",
      "y_value  -0.046182 -9.908761e-02  1.000000  8.509315e-01  \n",
      "ranks_y  -0.141197 -1.959393e-16  0.850932  1.000000e+00  \n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation matrix\n",
    "\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Print the correlation matrix\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "87b5ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_excel(r'C:/Users/xzhan/OneDrive/Misinfo Paper/One Node - Final/NE Prediction/Network_datasets.xlsx', index=False)\n",
    "# Concatenate the training and testing dataframes\n",
    "train_df = pd.concat(train_data1, ignore_index=True)\n",
    "# test_df = pd.concat(test_data1, ignore_index=True)\n",
    "# valid_df = pd.concat(valid_data1, ignore_index=True)\n",
    "#Split the data into features (X) and target (Y)\n",
    "X_train = train_df[['x1_d', 'x2_deg', 'x3_clo', 'x4_eigen','x5_path','x6_cc','x7_po','y_value']].values\n",
    "Y_train = train_df['y_value'].values\n",
    "Y_ranks = train_df['ranks_y'].values\n",
    "\n",
    "# X_test = test_df[['x1_d', 'x2_deg', 'x3_clo', 'x4_eigen','x5_path','x6_cc','x7_po','y_value']].values\n",
    "# Y_test = test_df['y_value'].values\n",
    "# Y_test_ranks = test_df['ranks_y'].values\n",
    "\n",
    "# X_valid = valid_df[['x1_d', 'x2_deg', 'x3_clo', 'x4_eigen','x5_path','x6_cc','x7_po','y_value']].values\n",
    "# Y_valid = valid_df['y_value'].values\n",
    "# Y_vaid_ranks = valid_df['ranks_y'].values\n",
    "\n",
    "\n",
    "# # # # #########################################################\n",
    "# X_train = train_df[['x1_d', 'x4_eigen','x5_path','x6_cc','y_value']].values\n",
    "# Y_train = train_df['y_value'].values\n",
    "# Y_ranks = train_df['ranks_y'].values\n",
    "\n",
    "# X_test = test_df[['x11', 'x22', 'x33']].values\n",
    "# Y_test = test_df['y_value'].values\n",
    "# X_valid = valid_df[['x11', 'x22', 'x33']].values\n",
    "# Y_valid = valid_df['y_value'].values\n",
    "\n",
    "\n",
    "# ######################################################\n",
    "# X_train = train_df[['x1_d','x6_cc','y_value']].values\n",
    "# Y_train = train_df['y_value'].values\n",
    "# X_test = test_df[['x11', 'x22']].values\n",
    "# Y_test = test_df['y_value'].values\n",
    "# X_valid = valid_df[['x11', 'x22']].values\n",
    "# Y_valid = valid_df['y_value'].values\n",
    "\n",
    "########################################################\n",
    "# X_train = train_df[['x22']].values\n",
    "# Y_train = train_df['y_value'].values\n",
    "# X_test = test_df[['x22']].values\n",
    "# Y_test = test_df['y_value'].values\n",
    "# X_valid = valid_df[['x22']].values\n",
    "# Y_valid = valid_df['y_value'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4569f26",
   "metadata": {},
   "source": [
    "# A. Linear Regression Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "6fcb02bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 1.119e+31\n",
      "Date:                Fri, 10 Nov 2023   Prob (F-statistic):               0.00\n",
      "Time:                        22:18:49   Log-Likelihood:                 38742.\n",
      "No. Observations:                1170   AIC:                        -7.747e+04\n",
      "Df Residuals:                    1161   BIC:                        -7.742e+04\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       1.665e-15   1.38e-15      1.211      0.226   -1.03e-15    4.36e-15\n",
      "x1         -3.053e-16   2.08e-16     -1.465      0.143   -7.14e-16    1.03e-16\n",
      "x2           1.11e-16   1.91e-15      0.058      0.954   -3.64e-15    3.86e-15\n",
      "x3         -2.331e-15   3.04e-15     -0.766      0.444   -8.31e-15    3.64e-15\n",
      "x4          1.998e-15   2.64e-15      0.756      0.450   -3.19e-15    7.18e-15\n",
      "x5         -3.886e-16   1.55e-16     -2.504      0.012   -6.93e-16   -8.42e-17\n",
      "x6         -3.608e-16   3.05e-16     -1.185      0.236   -9.58e-16    2.37e-16\n",
      "x7          8.327e-17   1.86e-15      0.045      0.964   -3.56e-15    3.72e-15\n",
      "x8             1.0000    1.1e-16   9.07e+15      0.000       1.000       1.000\n",
      "==============================================================================\n",
      "Omnibus:                       66.445   Durbin-Watson:                   0.307\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               76.510\n",
      "Skew:                           0.617   Prob(JB):                     2.43e-17\n",
      "Kurtosis:                       3.215   Cond. No.                         239.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "coefficients: [ 1.665e-15 -3.053e-16  1.110e-16 -2.331e-15  1.998e-15 -3.886e-16\n",
      " -3.608e-16  8.327e-17  1.000e+00]\n",
      "standard_errors: [1.375e-15 2.084e-16 1.910e-15 3.045e-15 2.642e-15 1.552e-16 3.046e-16\n",
      " 1.855e-15 1.103e-16]\n",
      "Mean Squared Error: 1.0147737221750287e-30\n",
      "P value:[0.226 0.143 0.954 0.444 0.45  0.012 0.236 0.964 0.   ]\n",
      "F-test:1.1187643667574407e+31\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# add a constant term to the dataframe\n",
    "X_train_OLS = sm.add_constant(X_train)\n",
    "# fit the linear regression model\n",
    "model_OLS = sm.OLS(Y_train,X_train_OLS).fit()\n",
    "#model = sm.OLS(df['y_rank'], df[['const', 'x1','x2','x3']]).fit()\n",
    "# print the model summary\n",
    "print(model_OLS.summary())\n",
    "\n",
    "############## Model Evaluation#################\n",
    "coefficients = model_OLS.params\n",
    "standard_errors = model_OLS.bse\n",
    "print(\"coefficients:\",coefficients)\n",
    "print(\"standard_errors:\",standard_errors)\n",
    "r_squared = model_OLS.rsquared\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "predictions_ols = model_OLS.predict(X_train_OLS)\n",
    "mse_ols = mean_squared_error(Y_train, predictions_ols)\n",
    "print(f\"Mean Squared Error: {mse_ols}\")\n",
    "residuals_ols = model_OLS.resid\n",
    "p_values_ols = model_OLS.pvalues\n",
    "print(f\"P value:{p_values_ols}\")\n",
    "f_statistic = model_OLS.fvalue\n",
    "print(f\"F-test:{f_statistic}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "2f81e7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.467 0.182 0.667 0.703 0.986]\n",
      " [0.003 0.2   0.667 0.65  0.72 ]\n",
      " [0.227 0.234 0.667 0.649 0.562]\n",
      " ...\n",
      " [0.348 0.041 1.    0.533 0.067]\n",
      " [0.064 0.08  1.    0.619 0.92 ]\n",
      " [0.188 0.044 0.    0.4   1.   ]]\n",
      "Correlation Matrix:\n",
      "          0         1         2         3         4\n",
      "0  1.000000  0.031860  0.018037  0.023765 -0.214577\n",
      "1  0.031860  1.000000  0.406854  0.490900  0.070153\n",
      "2  0.018037  0.406854  1.000000  0.414370 -0.092615\n",
      "3  0.023765  0.490900  0.414370  1.000000  0.036143\n",
      "4 -0.214577  0.070153 -0.092615  0.036143  1.000000\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "3adbe01d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-185-eabaceed7deb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#### pred_Y = model.predict(df[['const', 'x11','x22','x33']])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# add a constant term to the dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_test_OLS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpredictions_test_ols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_OLS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_OLS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#print(predictions_test_ols)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "#### pred_Y = model.predict(df[['const', 'x11','x22','x33']])\n",
    "# add a constant term to the dataframe\n",
    "X_test_OLS = sm.add_constant(X_test)\n",
    "predictions_test_ols = model_OLS.predict(X_test_OLS)\n",
    "#print(predictions_test_ols)\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "mse = mean_squared_error(Y_test, predictions_test_ols)\n",
    "mae = mean_absolute_error(Y_test, predictions_test_ols)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "residuals_ols = model_OLS.resid\n",
    "p_values_ols = model_OLS.pvalues\n",
    "print(f\"P value:{p_values_ols}\")\n",
    "f_statistic = model_OLS.fvalue\n",
    "print(f\"F-test:{f_statistic}\")\n",
    "\n",
    "\n",
    "# pred_index = np.argmin(pred_Y)\n",
    "# Find k nodes index with smallest polarization - use to predict minimizer's choice\n",
    "k = 3\n",
    "print(predictions_ols.argsort()[:k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258061b2",
   "metadata": {},
   "source": [
    "# B. Neural Network Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fe5ecfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "75/75 - 0s - loss: 42.5968 - mae: 5.9613\n",
      "Epoch 2/50\n",
      "75/75 - 0s - loss: 12.0865 - mae: 2.8943\n",
      "Epoch 3/50\n",
      "75/75 - 0s - loss: 9.3134 - mae: 2.4982\n",
      "Epoch 4/50\n",
      "75/75 - 0s - loss: 8.7329 - mae: 2.4159\n",
      "Epoch 5/50\n",
      "75/75 - 0s - loss: 8.3596 - mae: 2.3544\n",
      "Epoch 6/50\n",
      "75/75 - 0s - loss: 8.0048 - mae: 2.2871\n",
      "Epoch 7/50\n",
      "75/75 - 0s - loss: 7.7561 - mae: 2.2638\n",
      "Epoch 8/50\n",
      "75/75 - 0s - loss: 7.5553 - mae: 2.2283\n",
      "Epoch 9/50\n",
      "75/75 - 0s - loss: 7.3919 - mae: 2.1965\n",
      "Epoch 10/50\n",
      "75/75 - 0s - loss: 7.2790 - mae: 2.1854\n",
      "Epoch 11/50\n",
      "75/75 - 0s - loss: 7.1517 - mae: 2.1687\n",
      "Epoch 12/50\n",
      "75/75 - 0s - loss: 7.0626 - mae: 2.1476\n",
      "Epoch 13/50\n",
      "75/75 - 0s - loss: 6.9957 - mae: 2.1354\n",
      "Epoch 14/50\n",
      "75/75 - 0s - loss: 6.9360 - mae: 2.1223\n",
      "Epoch 15/50\n",
      "75/75 - 0s - loss: 6.9007 - mae: 2.1206\n",
      "Epoch 16/50\n",
      "75/75 - 0s - loss: 6.8565 - mae: 2.1112\n",
      "Epoch 17/50\n",
      "75/75 - 0s - loss: 6.8305 - mae: 2.1077\n",
      "Epoch 18/50\n",
      "75/75 - 0s - loss: 6.7885 - mae: 2.0966\n",
      "Epoch 19/50\n",
      "75/75 - 0s - loss: 6.7497 - mae: 2.0889\n",
      "Epoch 20/50\n",
      "75/75 - 0s - loss: 6.7505 - mae: 2.0969\n",
      "Epoch 21/50\n",
      "75/75 - 0s - loss: 6.7655 - mae: 2.0946\n",
      "Epoch 22/50\n",
      "75/75 - 0s - loss: 6.7371 - mae: 2.0843\n",
      "Epoch 23/50\n",
      "75/75 - 0s - loss: 6.6597 - mae: 2.0781\n",
      "Epoch 24/50\n",
      "75/75 - 0s - loss: 6.6832 - mae: 2.0782\n",
      "Epoch 25/50\n",
      "75/75 - 0s - loss: 6.6448 - mae: 2.0697\n",
      "Epoch 26/50\n",
      "75/75 - 0s - loss: 6.6193 - mae: 2.0606\n",
      "Epoch 27/50\n",
      "75/75 - 0s - loss: 6.5816 - mae: 2.0538\n",
      "Epoch 28/50\n",
      "75/75 - 0s - loss: 6.5967 - mae: 2.0724\n",
      "Epoch 29/50\n",
      "75/75 - 0s - loss: 6.5792 - mae: 2.0506\n",
      "Epoch 30/50\n",
      "75/75 - 0s - loss: 6.5956 - mae: 2.0604\n",
      "Epoch 31/50\n",
      "75/75 - 0s - loss: 6.5224 - mae: 2.0473\n",
      "Epoch 32/50\n",
      "75/75 - 0s - loss: 6.5033 - mae: 2.0435\n",
      "Epoch 33/50\n",
      "75/75 - 0s - loss: 6.5252 - mae: 2.0486\n",
      "Epoch 34/50\n",
      "75/75 - 0s - loss: 6.4864 - mae: 2.0434\n",
      "Epoch 35/50\n",
      "75/75 - 0s - loss: 6.5227 - mae: 2.0496\n",
      "Epoch 36/50\n",
      "75/75 - 0s - loss: 6.4829 - mae: 2.0411\n",
      "Epoch 37/50\n",
      "75/75 - 0s - loss: 6.4831 - mae: 2.0371\n",
      "Epoch 38/50\n",
      "75/75 - 0s - loss: 6.4475 - mae: 2.0375\n",
      "Epoch 39/50\n",
      "75/75 - 0s - loss: 6.4402 - mae: 2.0327\n",
      "Epoch 40/50\n",
      "75/75 - 0s - loss: 6.4411 - mae: 2.0271\n",
      "Epoch 41/50\n",
      "75/75 - 0s - loss: 6.4410 - mae: 2.0387\n",
      "Epoch 42/50\n",
      "75/75 - 0s - loss: 6.4317 - mae: 2.0310\n",
      "Epoch 43/50\n",
      "75/75 - 0s - loss: 6.3712 - mae: 2.0182\n",
      "Epoch 44/50\n",
      "75/75 - 0s - loss: 6.3746 - mae: 2.0217\n",
      "Epoch 45/50\n",
      "75/75 - 0s - loss: 6.4497 - mae: 2.0259\n",
      "Epoch 46/50\n",
      "75/75 - 0s - loss: 6.3779 - mae: 2.0186\n",
      "Epoch 47/50\n",
      "75/75 - 0s - loss: 6.3609 - mae: 2.0230\n",
      "Epoch 48/50\n",
      "75/75 - 0s - loss: 6.3350 - mae: 2.0169\n",
      "Epoch 49/50\n",
      "75/75 - 0s - loss: 6.3596 - mae: 2.0146\n",
      "Epoch 50/50\n",
      "75/75 - 0s - loss: 6.3358 - mae: 2.0176\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standardize the features (important for neural networks)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "# Define a simple neural network model\n",
    "model_NN = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1)  # Output layer with a single neuron (for regression)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_NN.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model_NN.fit(X_train, Y_train, epochs=50, batch_size=32, verbose=2)\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04f26ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 4)\n",
      "(28, 0.04187373571282055)\n",
      "[(16, -0.0151415095), (10, -0.015009886), (5, -0.014558872), (4, -0.011456942), (8, -0.011417782), (19, -0.011154255), (1, -0.010690497), (3, -0.009535773), (22, -0.008449068), (24, -0.008164829), (13, -0.008027699), (18, -0.0075722393), (20, -0.0070563536), (26, -0.006835861), (9, -0.0066093635), (0, -0.006463727), (25, -0.0061844494), (23, -0.004704898), (17, -0.0032228364), (21, -0.0027107021), (29, -0.0012028946), (14, -0.00038064294), (15, 0.0008013414), (12, 0.0011436099), (7, 0.001608269), (2, 0.0020497625), (28, 0.0020708197), (11, 0.0037495808), (27, 0.0077538732), (6, 0.012119165)]\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "# Use the trained model to make predictions on the test data\n",
    "predictions = model_NN.predict(X_test)\n",
    "# # Print the predictions\n",
    "# for i, pred in enumerate(predictions):\n",
    "#     print(f\"Prediction for sample {i+1}: {pred[0]}\")\n",
    "\n",
    "x = 2\n",
    "index = int(sets*0.9+1+x)\n",
    "\n",
    "print(Game_result[index])\n",
    "\n",
    "predictions_1net = predictions[x*n:(x+1)*n]\n",
    "indexed_dict = {}\n",
    "for index, item in enumerate(predictions_1net):\n",
    "    indexed_dict[index] = item[0]\n",
    "\n",
    "print(sorted(indexed_dict.items(), key=lambda x:x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b0ec89",
   "metadata": {},
   "source": [
    "### NN Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "50a38e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 Weights:\n",
      "(4, 64)\n",
      "Layer 1 Weights:\n",
      "(64,)\n",
      "Layer 2 Weights:\n",
      "(64, 32)\n",
      "Layer 3 Weights:\n",
      "(32,)\n",
      "Layer 4 Weights:\n",
      "(32, 1)\n",
      "Layer 5 Weights:\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "# Get the weights and biases of the neural network\n",
    "weights = model_NN.get_weights()\n",
    "\n",
    "# Print the weights and biases\n",
    "for layer_num, layer_weights in enumerate(weights):\n",
    "    print(f\"Layer {layer_num} Weights:\")\n",
    "    print(layer_weights.shape)\n",
    "   \n",
    "# Evaluate the model on the test data\n",
    "loss, mae = model_NN.evaluate(X_test, Y_test)\n",
    "# # Print the Mean Absolute Error\n",
    "# print(f\"Mean Absolute Error on Test Data: {mae}\")\n",
    "# Use the trained model to make predictions on the test data\n",
    "predictions = model_NN.predict(X_test)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE) manually\n",
    "mae = np.mean(np.abs(predictions - Y_test))\n",
    "print(f\"Mean Absolute Error on Test Data: {mae}\")\n",
    "print(f\"Mean Absolute Error percentage on Test Data: {mae/np.mean(Y_test)}\")\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(Y_test, predictions)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "# Calculate R-squared score\n",
    "r2 = r2_score(Y_test, predictions)\n",
    "print(f\"R-squared (R^2) Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871c2b78",
   "metadata": {},
   "source": [
    "## C. Decision Tree Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f8073cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 416  256  573 ...  556 1974 2242]\n",
      "[13  8 19 ... 18 65 74]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a label encoder to map the unique values to integers\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the original target variable into integers\n",
    "encoded_y = label_encoder.fit_transform()\n",
    "print(encoded_y)\n",
    "# Split the encoded values into batches (30 unique values in each batch)\n",
    "batch_size = n\n",
    "batched_y = np.floor(encoded_y / batch_size).astype(int)\n",
    "print(batched_y)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, batched_y)  # Train the model\n",
    "\n",
    "# Decode the predicted values\n",
    "predicted_batched_y = decision_tree.predict(X_test)\n",
    "predicted_y = predicted_batched_y * batch_size  # Decode the batched predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd9be93",
   "metadata": {},
   "source": [
    "## Sample eg - unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "eaeef7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.6226527909046995 changed to 1\n",
      "Min Action:    Agent26 's opinion 0.000984043874843299 changed to 0.5547007727634141\n",
      "Network reaches equilibrium Polarization: 0.016080010549744186\n",
      "_________________\n",
      "True\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.6226527909046995 changed to 1\n",
      "Min Action:    Agent26 's opinion 0.000984043874843299 changed to 0.5547007727634141\n",
      "Network reaches equilibrium Polarization: 0.016080010549744186\n",
      "{0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0, 6: 0.5, 7: 1.0, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.5, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0, 20: 1.0, 21: 1.0, 22: 0.5, 23: 1.0, 24: 0.5, 25: 0.5, 26: 1.0, 27: 1.0, 28: 1.0, 29: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.3541732845321627 changed to 0\n",
      "Min Action:    Agent28 's opinion 0.9453848410127564 changed to 0.4667759539039294\n",
      "Network reaches equilibrium Polarization: 0.031239528658814436\n",
      "_________________\n",
      "True\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.3541732845321627 changed to 0\n",
      "Min Action:    Agent28 's opinion 0.9453848410127564 changed to 0.4667759539039294\n",
      "Network reaches equilibrium Polarization: 0.031239528658814436\n",
      "{0: 1.0, 1: 0.6666666666666667, 2: 0.6666666666666667, 3: 0.3333333333333333, 4: 0.6666666666666667, 5: 0.6666666666666667, 6: 0.6666666666666667, 7: 0.6666666666666667, 8: 0.6666666666666667, 9: 0.6666666666666667, 10: 0.6666666666666667, 11: 0.6666666666666667, 12: 0.6666666666666667, 13: 0.6666666666666667, 14: 0.6666666666666667, 15: 0.6666666666666667, 16: 0.3333333333333333, 17: 0.6666666666666667, 18: 0.6666666666666667, 19: 0.6666666666666667, 20: 0.6666666666666667, 21: 0.6666666666666667, 22: 0.6666666666666667, 23: 0.6666666666666667, 24: 0.6666666666666667, 25: 0.6666666666666667, 26: 0.6666666666666667, 27: 0.3333333333333333, 28: 1.0, 29: 0.0}\n",
      "Actual Value: 0.00756561708792502\n",
      "Predicted Value: 0.0010581613\n",
      "Difference: 0.00650745582922751\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assume you have the necessary functions defined: make_innat_opinions, make_random_network, network_data,\n",
    "# MaxMin_play, metrics, actual_rank, and rescale\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Define the number of iterations\n",
    "num_iterations = 50  # Change this number if needed\n",
    "\n",
    "# Initialize lists to store actual and predicted values\n",
    "actual_values = []\n",
    "predicted_values = []\n",
    "\n",
    "# Create a neural network model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(3,)),  # Three features (x11, x22, x33)\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1)  # Output layer with a single neuron (for regression)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Loop through iterations\n",
    "for i in range(2):\n",
    "    s = make_innat_opinions(n)\n",
    "    G = make_random_network(n)\n",
    "    (temp_df, actual_Y_dict) = network_data(s, G, n)\n",
    "    (v1, v2, max_opinion, min_opinion, max_pol) = MaxMin_play(s, n, G)\n",
    "    (converted_dict, converted_dict1, converted_dict2, sorted_gap, scaled_MinPaths_sort) = metrics(G, v1)\n",
    "\n",
    "    # Calculate actual ranks and rescale polarization change\n",
    "    (actual_Y_dict, actual_ranks) = actual_rank(s, n, v1, max_opinion)\n",
    "    # rescaled_dict = rescale(actual_Y_dict)\n",
    "\n",
    "    # Create a temporary DataFrame for the current iteration's data\n",
    "    temp_df = pd.DataFrame({\n",
    "        'x11': [sorted_gap[x] for x in converted_dict2.keys()],\n",
    "        'x22': [converted_dict2[x] for x in converted_dict2.keys()],\n",
    "        'x33': [scaled_MinPaths_sort[x] for x in converted_dict2.keys()],\n",
    "        'y_value': [actual_Y_dict[x] for x in converted_dict2.keys()]\n",
    "    })\n",
    "    print(scaled_MinPaths_sort)\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    temp_df[['x11', 'x22', 'x33']] = scaler.fit_transform(temp_df[['x11', 'x22', 'x33']])\n",
    "\n",
    "    # Concatenate the temporary DataFrame to the main DataFrame\n",
    "    df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "    # Extract features (x11, x22, x33) and target (y_value)\n",
    "    X = temp_df[['x11', 'x22', 'x33']].values\n",
    "    y = temp_df['y_value'].values\n",
    "\n",
    "    # Train the neural network for each iteration\n",
    "    model.fit(X, y, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    # Predict the target values\n",
    "    predictions = model.predict(X)\n",
    "\n",
    "    # Append actual and predicted values to their respective lists\n",
    "    actual_values.extend(y)\n",
    "    predicted_values.extend(predictions.flatten())\n",
    "\n",
    "# Calculate the difference between actual and predicted values\n",
    "differences = np.abs(np.array(actual_values) - np.array(predicted_values))\n",
    "\n",
    "# Print the first predicted value and its actual value\n",
    "print(\"Actual Value:\", actual_values[0])\n",
    "print(\"Predicted Value:\", predicted_values[0])\n",
    "print(\"Difference:\", differences[0])\n",
    "print(f\"Predicted y_value for the test network: {predictions[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e6f4f1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent28 's opinion 0.6023554375757443 changed to 0\n",
      "Min Action:    Agent25 's opinion 0.9562842372875656 changed to 0.6065065580033292\n",
      "Network reaches equilibrium Polarization: 0.016077623621038515\n",
      "_________________\n",
      "True\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent28 's opinion 0.6023554375757443 changed to 0\n",
      "Min Action:    Agent25 's opinion 0.9562842372875656 changed to 0.6065065580033292\n",
      "Network reaches equilibrium Polarization: 0.016077623621038515\n"
     ]
    }
   ],
   "source": [
    "# create testing data\n",
    "df1 = pd.DataFrame()\n",
    "for i in range(1):  # Change the range if you want more iterations\n",
    "    s = make_innat_opinions(n)\n",
    "    G = make_random_network(n)\n",
    "    (temp_df, actual_Y_dict) = network_data(s, G, n)\n",
    "    (v1, v2, max_opinion, min_opinion, max_pol) = MaxMin_play(s, n, G)\n",
    "    (converted_dict, converted_dict1, converted_dict2, sorted_gap, scaled_MinPaths_sort) = metrics(G, v1)\n",
    "\n",
    "    # Calculate actual ranks and rescale polarization change\n",
    "    (actual_Y_dict, actual_ranks) = actual_rank(s, n, v1, max_opinion)\n",
    "    #rescaled_dict = rescale(actual_Y_dict)\n",
    "\n",
    "    # Create a temporary DataFrame for the current iteration's data\n",
    "    temp_df = pd.DataFrame({'keys': list(converted_dict2.keys()),\n",
    "                            'x11': [sorted_gap[x] for x in converted_dict2.keys()],\n",
    "                            'x22': [converted_dict2[x] for x in converted_dict2.keys()],\n",
    "                            'x33': [scaled_MinPaths_sort[x] for x in converted_dict2.keys()],\n",
    "                            'y_value': [actual_Y_dict[x] for x in converted_dict2.keys()]})\n",
    "\n",
    "    # Concatenate the temporary DataFrame to the main DataFrame\n",
    "    df1 = pd.concat([df1, temp_df], ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cc382f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df:     const  keys       x11       x22       x33   y_value\n",
      "0     1.0     0  0.698243  0.624098  0.666667  0.003389\n",
      "1     1.0     1  0.790401  0.692491  0.333333  0.003894\n",
      "2     1.0     2  0.522414  0.737438  0.666667  0.004365\n",
      "3     1.0     3  0.634123  0.660801  0.666667  0.003371\n",
      "4     1.0     4  0.742036  0.679378  0.666667  0.003375\n",
      "5     1.0     5  0.527894  0.677503  0.666667  0.003841\n",
      "6     1.0     6  0.861896  1.000000  0.333333  0.004143\n",
      "7     1.0     7  0.860905  0.903703  0.333333  0.004139\n",
      "8     1.0     8  1.000000  0.865950  0.666667  0.003112\n",
      "9     1.0     9  0.974292  0.852483  0.666667  0.003963\n",
      "10    1.0    10  0.206775  0.980180  0.666667  0.004342\n",
      "11    1.0    11  0.010986  0.883571  0.666667  0.004332\n",
      "12    1.0    12  0.762645  0.893460  0.666667  0.003564\n",
      "13    1.0    13  0.070004  0.835888  0.666667  0.004325\n",
      "14    1.0    14  0.092986  0.739548  0.666667  0.004349\n",
      "15    1.0    15  0.914326  0.749338  0.666667  0.003293\n",
      "16    1.0    16  0.000000  0.732002  0.666667  0.004241\n",
      "17    1.0    17  0.092116  0.674298  0.333333  0.004294\n",
      "18    1.0    18  0.604845  0.670243  0.333333  0.003198\n",
      "19    1.0    19  0.454999  0.683604  0.666667  0.004023\n",
      "20    1.0    20  0.839966  0.582417  0.666667  0.003970\n",
      "21    1.0    21  0.440871  0.777961  0.666667  0.004073\n",
      "22    1.0    22  0.150946  0.620826  0.666667  0.004353\n",
      "23    1.0    23  0.759306  0.443111  0.666667  0.003255\n",
      "24    1.0    24  0.708678  0.492357  0.666667  0.003565\n",
      "25    1.0    25  0.953766  0.266214  1.000000  0.003092\n",
      "26    1.0    26  0.191835  0.221273  0.666667  0.004243\n",
      "27    1.0    27  0.180224  0.126644  0.666667  0.003938\n",
      "28    1.0    28  0.233307  0.095255  0.000000  0.000000\n",
      "29    1.0    29  0.387357  0.000000  0.333333  0.004217\n",
      "predictions [(28, 0.008754212898974073), (29, 0.011951224710081311), (1, 0.01678428339222567), (18, 0.016830494185308607), (27, 0.017269292354793946), (17, 0.017460057849816024), (26, 0.01798046207250216), (7, 0.018319585410549937), (23, 0.019017032793617883), (6, 0.019055929802209038), (24, 0.01945328944834245), (20, 0.019989770566901485), (0, 0.020474422607340084), (3, 0.02083036431763774), (4, 0.020846673246607855), (5, 0.021082281084870185), (22, 0.021088227593618492), (15, 0.021181360141095687), (19, 0.02121409346165484), (25, 0.021541608836999196), (2, 0.021547696023404846), (9, 0.02190131039172312), (21, 0.021953235249769103), (8, 0.021974441086428546), (14, 0.02206513235725116), (16, 0.022115876774919767), (12, 0.022462191391619726), (13, 0.02282979058275598), (11, 0.023263870762474482), (10, 0.02377521230639021)]\n",
      "actual values [(28, 0), (25, 0.0030919865442198893), (8, 0.0031122031843165247), (18, 0.0031981204992056304), (23, 0.003254984968395963), (15, 0.0032932904390964544), (3, 0.003370577133469964), (4, 0.0033749070443898146), (0, 0.0033889576254761064), (12, 0.0035639902267741823), (24, 0.0035645974403405965), (5, 0.003841192083629201), (1, 0.0038935400818983674), (27, 0.003938006039578834), (9, 0.003962697978074501), (20, 0.003970499889970301), (19, 0.004023116457642906), (21, 0.0040733187759542724), (7, 0.004139436362001623), (6, 0.004143015034158523), (29, 0.004217195349386863), (16, 0.004241011523816004), (26, 0.004242634914863066), (17, 0.004294223541400424), (13, 0.004325430979800586), (11, 0.004332151934007138), (10, 0.004342186075297079), (14, 0.004349023610798773), (22, 0.004353080930025819), (2, 0.004364953373075589)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xzhan\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    }
   ],
   "source": [
    "#  Creat testing\n",
    "# (df, actual_Y_dict_test) = creat_data(n, 1)\n",
    "# print(\"DataFrame\", df)\n",
    "# print(\"Actual_Y_dict\", actual_Y_dict_test)\n",
    "# # actual_min = np.argmax(df[\"y_value\"])\n",
    "# # print('Min s', actual_min)\n",
    "\n",
    "test_df = sm.add_constant(df1)\n",
    "print('test_df:',test_df)\n",
    "# Use the trained model to make predictions on the new data\n",
    "predictions = model.predict(test_df[['const', 'x11', 'x22', 'x33']])\n",
    "sorted_predictions = sorted(predictions.items(), key=lambda x:x[1])\n",
    "# # Print or use the predictions as needed\n",
    "print(\"predictions\", sorted_predictions)\n",
    "\n",
    "sorted_actual_Y_dict = sorted(actual_Y_dict.items(), key=lambda x:x[1])\n",
    "print(\"actual values\", sorted_actual_Y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "09a556ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(29, 0), (25, 0.00040657091805073806), (2, 0.001773838572260926), (21, 0.0018749557517400706), (23, 0.0020531171860036293), (14, 0.002202128022298043), (10, 0.0025835762471996884), (18, 0.00271894002204999), (26, 0.0027535264735846846), (13, 0.002784035032888668), (6, 0.0028127358484876692), (17, 0.0028547120575342956), (4, 0.0028582587959319686), (22, 0.0028805401654238283), (3, 0.0029748191274902927), (24, 0.0029885525392130477), (8, 0.0030030718505019566), (1, 0.003013648350633027), (0, 0.003039554731715355), (19, 0.0030516378590010884), (15, 0.003088247734453285), (20, 0.0031010346312026794), (12, 0.003127983331037691), (7, 0.003205938458982392), (11, 0.0032301317374829747), (27, 0.0032369515651250423), (16, 0.003254671460723748), (9, 0.0032604258732439814), (28, 0.0032693800563578027), (5, 0.0032778666281935258)]\n"
     ]
    }
   ],
   "source": [
    "a = sorted(actual_Y_dict_test.items(), key=lambda x:x[1])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2dc3e5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    539\n",
      "1    209\n",
      "2    389\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find k nodes index with smallest polarization - use to predict minimizer's choice\n",
    "k = 3\n",
    "print(pred_Y.argsort()[:k])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
