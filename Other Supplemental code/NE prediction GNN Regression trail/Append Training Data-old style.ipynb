{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xzhan\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:7: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n",
      "C:\\Users\\xzhan\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:7: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n"
     ]
    }
   ],
   "source": [
    "%run excute_nonZS_MaxMin.ipynb\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_values Normalizaion \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def rescale(dic): # input x is a dictionary - sorted node index: value\n",
    "    minmax_scale = MinMaxScaler(feature_range=(0, 1))\n",
    "    x = list(dic.values())\n",
    "    x = np.array(x)\n",
    "    x = x.reshape(-1, 1)\n",
    "    x_scale = minmax_scale.fit_transform(x).flatten()\n",
    "    dic_scale = dict(zip(dic.keys(),x_scale))\n",
    "    return dic_scale  # output\n",
    "\n",
    "# Creat Metrics for Regression\n",
    "\n",
    "################### create shortest path from all nodes to max selected node v1 ############\n",
    "def shortest_pth(G, v1):\n",
    "    nxG = nx.from_numpy_matrix(G)  \n",
    "    paths = nx.single_source_shortest_path(nxG, v1)\n",
    "    # the length of shortest path from v2 to v1\n",
    "    lenths =[]\n",
    "    for v in paths.items():\n",
    "        lenth = len(v[1])\n",
    "        lenths.append(lenth)  \n",
    "    PathLen = dict(zip(paths.keys(),lenths))\n",
    "    #print(\"path_lenth\",PathLen)\n",
    "    return PathLen\n",
    "\n",
    "def metrics(G, v1):\n",
    "\n",
    "    nxG = nx.from_numpy_matrix(G) \n",
    "    # G = nx.karate_club_graph()\n",
    "   # print(\"_______________Degree Centrality_____________________________\")  \n",
    "    deg_centrality = nx.degree_centrality(nxG)\n",
    "    sortedDict = sorted(deg_centrality.items(), key=lambda x:x[1])\n",
    "    converted_dict = dict(sortedDict)\n",
    "    # print(converted_dict)\n",
    "    #print(\"                           \")\n",
    "   # print(\"_______________Closeness Rank_____________________________\")\n",
    "    close_centrality = nx.closeness_centrality(nxG)\n",
    "    sortedDict1 = sorted(close_centrality.items(), key=lambda x:x[1])\n",
    "    converted_dict1 = dict(sortedDict1)\n",
    "    # print(converted_dict1)\n",
    "    #print(\"                           \")\n",
    "   # print(\"_______________Page Rank_____________________________\")\n",
    "    pr = nx.eigenvector_centrality(nxG)\n",
    "    sortedDict2 = sorted(pr.items(), key=lambda x:x[1])\n",
    "    converted_dict2 = dict(sortedDict2)\n",
    "    # print(converted_dict2)\n",
    "    #print(\"                           \")\n",
    "   # print(\"_______________Opinion Extremity_____________________________\")\n",
    "    def gap(op, n):\n",
    "        ones = np.ones((n, 1))\n",
    "        x = op - (np.dot(np.transpose(op),ones)/n) * ones\n",
    "        return abs(x)\n",
    "    gap = gap(s,n)\n",
    "    my_gap = {index: value for index, value in enumerate(gap)}\n",
    "    sorting_gap = sorted(my_gap.items(), key=lambda x:x[1], reverse=True)\n",
    "    sorted_gap = dict(sorting_gap)\n",
    "    # print(\"opinion - mean\")\n",
    "    # print(sorted_gap)\n",
    "    \n",
    "   # print(\"________________Shortest Path_____________________________\")\n",
    "    PathLen = shortest_pth(G, v1)\n",
    "    \n",
    "    \n",
    "    # creat a dict node:shortest length to v1(max selected node)\n",
    "    scaled_MinPath = rescale(PathLen) # rescale the shortest path to the range (0,1) for regression\n",
    "    ##print(\"scaled path lenths\",scaled_MinPath)\n",
    "    # sorting all varibles based on the node index\n",
    "    scaled_MinPaths_sort = dict(sorted(scaled_MinPath.items(), key=lambda x:x[0]))\n",
    "    #print(\"scaled_paths_sort\",scaled_MinPaths_sort)\n",
    "    \n",
    "    converted_dict = dict(sorted(converted_dict.items(), key=lambda x:x[0]))\n",
    "    converted_dict1 = dict(sorted(converted_dict1.items(), key=lambda x:x[0]))\n",
    "    converted_dict2 = dict(sorted(converted_dict2.items(), key=lambda x:x[0]))\n",
    "    sorted_gap = dict(sorted(sorted_gap.items(), key=lambda x:x[0]))\n",
    "    \n",
    "    return (converted_dict, converted_dict1, converted_dict2, sorted_gap, scaled_MinPaths_sort)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the ground truth of Min's action - knowing Max chooses v1, what Min's action will be?\n",
    "def actual_rank(s, n, v1, max_opinion):\n",
    "\n",
    "    L = scipy.sparse.csgraph.laplacian(G, normed=False)  # Return the Laplacian matrix\n",
    "    A = np.linalg.inv(np.identity(n) + L)  # A = (I + L)^(-1)\\n  Stanford paper theory\n",
    "    op = copy.copy(s)\n",
    "    op[v1] = max_opinion\n",
    "    all_1 = list(range(n))    # for all agent \n",
    "    C1 = [x for x in all_1 if x != v1]  # for the vertice that Maximizer has not touched\n",
    "    innat_por = obj_polarization(A, s, n) # Calculate innate polarization\n",
    "    results = []\n",
    "    for v2 in C1:   \n",
    "        (changed_opinion, por) = derivate_s(op,n,v2,A)   # find the best new_op option  \n",
    "        por_1 = por - innat_por     # append the change of the polarization\n",
    "        results.append((v2, por_1))\n",
    "    results.append((v1,0)) # minimizer cannot choose v1, but we need all nodes for the dataframe\n",
    "    actual_Y = dict(results) # now we have - node:polarization\n",
    "    \n",
    "    # most of v are in sequential order, but v1 might not be in order, so we need to sort it\n",
    "    sorted_actual_Y = sorted(actual_Y.items(), key=lambda x:x[0])\n",
    "    actual_Y_dict = dict(sorted_actual_Y)  # dictionary -  node:polarization\n",
    "   # print(\"actual_Y_dict\",actual_Y_dict) \n",
    "\n",
    "    # create the rank of the Y values based on minimizer's choice \n",
    "    actual_Y_order = dict(sorted(actual_Y.items(), key=lambda x:x[1]))  #sort - list nodes in sequential of the polariz.\n",
    "\n",
    "    node_ranks= dict(zip(actual_Y_order.keys(), all_1)) # dictionary -  node:polarization rank(replace polarz. with rank)\n",
    "    actual_ranks = dict(sorted(node_ranks.items(), key=lambda x:x[0])) # sort - list node in sequential node index\n",
    "    \n",
    "    return (actual_Y_dict, actual_ranks)  # return two dictionary, 1. sequential node: polarization, \n",
    "                                                                # 2. seq. node: pol rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'converted_dict2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6747ecda85ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'keys'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverted_dict2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_innat_opinions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_random_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'converted_dict2' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'keys': list(converted_dict2.keys())})\n",
    "print(df)\n",
    "for i in range(2):\n",
    "    s = make_innat_opinions(n)\n",
    "    G = make_random_network(n)\n",
    "    (v1, v2, max_opinion, min_opinion, max_pol) = MaxMin_play(s,n,G)\n",
    "    (converted_dict, converted_dict1, converted_dict2, sorted_gap, scaled_MinPaths_sort) = metrics(G, v1) \n",
    "   # print('where')\n",
    "    ##################################the actual rank based on polarization ####################\n",
    "    (actual_Y_dict, actual_ranks) = actual_rank(s, n, v1, max_opinion)\n",
    "     # rescale the polarization change to the range (0,1) for regression\n",
    "    rescaled_dict = rescale(actual_Y_dict)\n",
    "    #max_pred = sorted(np.unique(a+b+c))\n",
    "    \n",
    "    df['x11'] = df['keys'].apply(lambda x: sorted_gap[x][0])\n",
    "    df['x22'] = df['keys'].apply(lambda x: converted_dict2[x])\n",
    "    df['x33'] = df['keys'].apply(lambda x: scaled_MinPaths_sort[x])\n",
    "    df['y_value'] = df['keys'].apply(lambda x: actual_Y_dict[x])\n",
    "\n",
    "    print(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.5411009471018632 changed to 1\n",
      "Min Action:    Agent18 's opinion 0.05618440720807116 changed to 0.7072943666421232\n",
      "Network reaches equilibrium Polarization: 0.022919381937473733\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.27004348197857564 changed to 0\n",
      "Min Action:    Agent28 's opinion 0.033540726648598085 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.08503668742763593\n",
      "    keys       x11       x22       x33   y_value\n",
      "0      0  0.044516  0.193785  1.000000  0.017544\n",
      "1      1  0.313042  0.162840  1.000000  0.017779\n",
      "2      2  0.062595  0.205713  0.666667  0.017621\n",
      "3      3  0.330022  0.213409  1.000000  0.016599\n",
      "4      4  0.110308  0.250376  0.666667  0.017289\n",
      "5      5  0.212714  0.228595  0.666667  0.017633\n",
      "6      6  0.142566  0.259323  0.666667  0.017468\n",
      "7      7  0.053996  0.222373  0.666667  0.017433\n",
      "8      8  0.348151  0.252278  0.666667  0.017792\n",
      "9      9  0.469164  0.215515  1.000000  0.015839\n",
      "10    10  0.156467  0.219674  0.666667  0.017604\n",
      "11    11  0.095800  0.182515  0.666667  0.017555\n",
      "12    12  0.170809  0.228393  1.000000  0.016541\n",
      "13    13  0.161139  0.181639  0.666667  0.017858\n",
      "14    14  0.076258  0.197415  0.666667  0.017797\n",
      "15    15  0.498980  0.264595  0.666667  0.015355\n",
      "16    16  0.317871  0.223036  0.666667  0.017829\n",
      "17    17  0.222116  0.194970  0.333333  0.016396\n",
      "18    18  0.478037  0.124440  0.666667  0.014178\n",
      "19    19  0.363295  0.173841  0.333333  0.016291\n",
      "20    20  0.002219  0.114585  0.666667  0.016826\n",
      "21    21  0.224180  0.158317  0.666667  0.017284\n",
      "22    22  0.166037  0.124072  0.666667  0.016848\n",
      "23    23  0.229242  0.129179  0.666667  0.016774\n",
      "24    24  0.135623  0.117731  0.666667  0.016753\n",
      "25    25  0.161803  0.070654  1.000000  0.014504\n",
      "26    26  0.159391  0.056516  0.666667  0.016971\n",
      "27    27  0.172810  0.055113  0.666667  0.017767\n",
      "28    28  0.021830  0.033547  0.333333  0.016221\n",
      "29    29  0.006880  0.026094  0.000000  0.000000\n",
      "30     0  0.376328  0.193527  1.000000  0.057388\n",
      "31     1  0.378230  0.205335  0.666667  0.057968\n",
      "32     2  0.214293  0.207192  1.000000  0.064815\n",
      "33     3  0.158064  0.191543  1.000000  0.060458\n",
      "34     4  0.491381  0.210840  1.000000  0.068298\n",
      "35     5  0.429605  0.209378  1.000000  0.056861\n",
      "36     6  0.210673  0.232830  0.666667  0.066209\n",
      "37     7  0.051404  0.244922  1.000000  0.062496\n",
      "38     8  0.182610  0.201626  1.000000  0.059933\n",
      "39     9  0.219102  0.210652  0.666667  0.063322\n",
      "40    10  0.082569  0.219156  0.666667  0.063336\n",
      "41    11  0.449362  0.198757  1.000000  0.067847\n",
      "42    12  0.029556  0.209898  1.000000  0.061358\n",
      "43    13  0.325586  0.221662  1.000000  0.066279\n",
      "44    14  0.058918  0.172631  1.000000  0.064048\n",
      "45    15  0.342221  0.244159  1.000000  0.066282\n",
      "46    16  0.123022  0.207062  1.000000  0.059763\n",
      "47    17  0.389630  0.204969  1.000000  0.066835\n",
      "48    18  0.063259  0.217237  1.000000  0.061024\n",
      "49    19  0.129453  0.207014  1.000000  0.061393\n",
      "50    20  0.429459  0.161470  1.000000  0.056170\n",
      "51    21  0.416648  0.131415  1.000000  0.052960\n",
      "52    22  0.425526  0.092084  1.000000  0.051827\n",
      "53    23  0.059972  0.114225  1.000000  0.063881\n",
      "54    24  0.440232  0.113025  1.000000  0.053208\n",
      "55    25  0.244244  0.115816  0.666667  0.068416\n",
      "56    26  0.302186  0.089927  0.666667  0.068301\n",
      "57    27  0.000272  0.060327  0.666667  0.068606\n",
      "58    28  0.490011  0.073289  0.333333  0.034554\n",
      "59    29  0.253509  0.004717  0.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "ue': [actual_Y_dict[x] for x in converted_dict2.keys()]})\n",
    "\n",
    "for i in range(1, 2):  # Change the range if you want more iterations\n",
    "    s = make_innat_opinions(n)\n",
    "    G = make_random_network(n)\n",
    "    (v1, v2, max_opinion, min_opinion, max_pol) = MaxMin_play(s, n, G)\n",
    "    (converted_dict, converted_dict1, converted_dict2, sorted_gap, scaled_MinPaths_sort) = metrics(G, v1)\n",
    "    \n",
    "    # Calculate actual ranks and rescale polarization change\n",
    "    (actual_Y_dict, actual_ranks) = actual_rank(s, n, v1, max_opinion)\n",
    "    rescaled_dict = rescale(actual_Y_dict)\n",
    "    \n",
    "    # Create a temporary DataFrame for the current iteration's data\n",
    "    temp_df = pd.DataFrame({'keys': list(converted_dict2.keys()),\n",
    "                            'x11': [sorted_gap[x][0] for x in converted_dict2.keys()],\n",
    "                            'x22': [converted_dict2[x] for x in converted_dict2.keys()],\n",
    "                            'x33': [scaled_MinPaths_sort[x] for x in converted_dict2.keys()],\n",
    "                            'y_value': [actual_Y_dict[x] for x in converted_dict2.keys()]})\n",
    "    \n",
    "    # Concatenate the temporary DataFrame to the main DataFrame\n",
    "    df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "# Print the final DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
