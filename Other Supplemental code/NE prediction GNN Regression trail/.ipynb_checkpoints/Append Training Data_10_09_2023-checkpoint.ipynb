{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run excute_nonZS_MaxMin.ipynb\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_values Normalizaion \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def rescale(dic): # input x is a dictionary - sorted node index: value\n",
    "    minmax_scale = MinMaxScaler(feature_range=(0, 1))\n",
    "    x = list(dic.values())\n",
    "    x = np.array(x)\n",
    "    x = x.reshape(-1, 1)\n",
    "    x_scale = minmax_scale.fit_transform(x).flatten()\n",
    "    dic_scale = dict(zip(dic.keys(),x_scale))\n",
    "    return dic_scale  # output\n",
    "\n",
    "# Creat Metrics for Regression\n",
    "\n",
    "################### create shortest path from all nodes to max selected node v1 ############\n",
    "def shortest_pth(G, v1):\n",
    "    nxG = nx.from_numpy_matrix(G)  \n",
    "    paths = nx.single_source_shortest_path(nxG, v1)\n",
    "    # the length of shortest path from v2 to v1\n",
    "    lenths =[]\n",
    "    for v in paths.items():\n",
    "        lenth = len(v[1])\n",
    "        lenths.append(lenth)  \n",
    "    PathLen = dict(zip(paths.keys(),lenths))\n",
    "    #print(\"path_lenth\",PathLen)\n",
    "    return PathLen\n",
    "\n",
    "def metrics(G, v1):\n",
    "\n",
    "    nxG = nx.from_numpy_matrix(G) \n",
    "    # G = nx.karate_club_graph()\n",
    "   # print(\"_______________Degree Centrality_____________________________\")  \n",
    "    deg_centrality = nx.degree_centrality(nxG)\n",
    "    sortedDict = sorted(deg_centrality.items(), key=lambda x:x[1])\n",
    "    converted_dict = dict(sortedDict)\n",
    "    # print(converted_dict)\n",
    "    #print(\"                           \")\n",
    "   # print(\"_______________Closeness Rank_____________________________\")\n",
    "    close_centrality = nx.closeness_centrality(nxG)\n",
    "    sortedDict1 = sorted(close_centrality.items(), key=lambda x:x[1])\n",
    "    converted_dict1 = dict(sortedDict1)\n",
    "    # print(converted_dict1)\n",
    "    #print(\"                           \")\n",
    "   # print(\"_______________Page Rank_____________________________\")\n",
    "    pr = nx.eigenvector_centrality(nxG)\n",
    "    sortedDict2 = sorted(pr.items(), key=lambda x:x[1])\n",
    "    converted_dict2 = dict(sortedDict2)\n",
    "    # print(converted_dict2)\n",
    "    #print(\"                           \")\n",
    "   # print(\"_______________Opinion Extremity_____________________________\")\n",
    "    def gap(op, n):\n",
    "        ones = np.ones((n, 1))\n",
    "        x = op - (np.dot(np.transpose(op),ones)/n) * ones\n",
    "        return abs(x)\n",
    "    gap = gap(s,n)\n",
    "    my_gap = {index: value for index, value in enumerate(gap)}\n",
    "    sorting_gap = sorted(my_gap.items(), key=lambda x:x[1], reverse=True)\n",
    "    sorted_gap = dict(sorting_gap)\n",
    "    # print(\"opinion - mean\")\n",
    "    # print(sorted_gap)\n",
    "    \n",
    "   # print(\"________________Shortest Path_____________________________\")\n",
    "    PathLen = shortest_pth(G, v1)\n",
    "    # creat a dict node:shortest length to v1(max selected node)\n",
    "    scaled_MinPath = rescale(PathLen) # rescale the shortest path to the range (0,1) for regression\n",
    "    scaled_deg_cent= rescale(converted_dict)\n",
    "    scaled_clo_cent = rescale(converted_dict1)\n",
    "    scaled_eigen_cent = rescale(converted_dict2)\n",
    "    scaled_op_extre = rescale(sorted_gap)\n",
    "    \n",
    "    # sorting all varibles based on the node index\n",
    "    scaled_MinPaths_sort = dict(sorted(scaled_MinPath.items(), key=lambda x:x[0]))\n",
    "    #print(\"scaled_paths_sort\",scaled_MinPaths_sort)\n",
    "    \n",
    "    scaled_deg_cent = dict(sorted(scaled_deg_cent.items(), key=lambda x:x[0]))\n",
    "    scaled_clo_cent = dict(sorted(scaled_clo_cent.items(), key=lambda x:x[0]))\n",
    "    scaled_eigen_cent = dict(sorted(scaled_eigen_cent.items(), key=lambda x:x[0]))\n",
    "    scaled_op_extre = dict(sorted(scaled_op_extre.items(), key=lambda x:x[0]))\n",
    "    \n",
    "    return (scaled_deg_cent, scaled_clo_cent, scaled_eigen_cent, scaled_op_extre, scaled_MinPaths_sort)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the ground truth of Min's action - knowing Max chooses v1, what Min's action will be?\n",
    "def actual_rank(s, n, v1, max_opinion):\n",
    "\n",
    "    L = scipy.sparse.csgraph.laplacian(G, normed=False)  # Return the Laplacian matrix\n",
    "    A = np.linalg.inv(np.identity(n) + L)  # A = (I + L)^(-1)\\n  Stanford paper theory\n",
    "    op = copy.copy(s)\n",
    "    op[v1] = max_opinion\n",
    "    \n",
    "    all_1 = list(range(n))    # for all agent \n",
    "    C1 = [x for x in all_1 if x != v1]  # for the vertice that Maximizer has not touched\n",
    "    innat_por = obj_polarization(A, s, n) # Calculate innate polarization\n",
    "    results = []\n",
    "    real_por1 = []\n",
    "    for v2 in C1:   \n",
    "        (changed_opinion, por) = derivate_s(op,n,v2,A)   # find the best new_op option  \n",
    "        por_1 = por - innat_por     # append the change of the polarization\n",
    "        results.append((v2, por_1))\n",
    "        real_por1.append((v2,por))\n",
    "    results.append((v1,0)) # minimizer cannot choose v1, but we need all nodes for the dataframe\n",
    "   # print(\"actul_rank_cal:\", results)\n",
    "    #print(\"real por1:\", real_por1)\n",
    "    actual_por = dict(real_por1)\n",
    "    actual_por_dict = dict(sorted(actual_por.items(), key=lambda x:x[0]))  \n",
    "    \n",
    "    actual_Y = dict(results) # now we have - node:polarization\n",
    "    # most of v are in sequential order, but v1 might not be in order, so we need to sort it\n",
    "    actual_Y_dict = dict(sorted(actual_Y.items(), key=lambda x:x[0]))   #sort - list nodes in sequential of the node index\n",
    "    # dictionary -  node:polarization\n",
    "   # print(\"actual_Y_dict\",actual_Y_dict) \n",
    "\n",
    "    # create the rank of the Y values based on minimizer's choice \n",
    "    actual_Y_order = dict(sorted(actual_Y.items(), key=lambda x:x[1]))  #sort - list nodes in sequential of the polariz.\n",
    "    node_ranks= dict(zip(actual_Y_order.keys(), all_1)) # dictionary -  node:polarization rank(replace polarz. with rank)\n",
    "    actual_ranks = dict(sorted(node_ranks.items(), key=lambda x:x[0])) # sort - list node in sequential node index\n",
    "    \n",
    "    return (actual_Y_dict, actual_ranks)  # return two dictionary, 1. sequential node: polarization, \n",
    "                                                                # 2. seq. node: pol rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_data(s, G, n):\n",
    "    (v1, v2, max_opinion, min_opinion, max_pol) = MaxMin_play(s, n, G)\n",
    "    (converted_dict, converted_dict1, converted_dict2, sorted_gap, scaled_MinPaths_sort) = metrics(G, v1)\n",
    "    # print(v1, max_opinion)\n",
    "    #print(\"actual_ranks INPUT:\",s, n, v1, max_opinion )\n",
    "    (actual_Y_dict, actual_ranks) = actual_rank(s, n, v1, max_opinion)\n",
    "    \n",
    "    df = pd.DataFrame({'keys': list(converted_dict2.keys()),\n",
    "                   'x11': [sorted_gap[x] for x in converted_dict2.keys()],\n",
    "                   'x22': [converted_dict2[x] for x in converted_dict2.keys()],\n",
    "                   'x33': [scaled_MinPaths_sort[x] for x in converted_dict2.keys()],\n",
    "                   'y_value': [actual_Y_dict[x] for x in converted_dict2.keys()]})\n",
    "\n",
    "    print(\"_________________\")\n",
    "    a = sorted(actual_Y_dict.items(), key=lambda x:x[1])\n",
    "#     print(a)\n",
    "    if a[0][0]!= v1:\n",
    "        print(a[0][0]==v2)\n",
    "    else:\n",
    "        print(a[1][0]==v2)\n",
    "    \n",
    "    return (df, actual_Y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.49448967518108033 changed to 0\n",
      "Min Action:    Agent26 's opinion 0.07622274145837149 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.04045540570993513\n",
      "_________________\n",
      "True\n",
      "{0: 0.03676007670572219, 1: 0.03686537900583772, 2: 0.036600482867684775, 3: 0.03494886606101223, 4: 0.036994554440703195, 5: 0.03347018724753134, 6: 0.032360317521452825, 7: 0.0315683407158666, 8: 0.03551881128515885, 9: 0.03400000923427028, 10: 0.03473993299810045, 11: 0.032932945567768546, 12: 0.03651291484877178, 13: 0.030451492239640932, 14: 0.03187814704954439, 15: 0.03557179459222545, 16: 0.03009207395625302, 17: 0.03454354992646101, 18: 0.03169775646163772, 19: 0.03231775946032772, 20: 0.03553581189639479, 21: 0.03481174344927093, 22: 0.03683068063112192, 23: 0.03701958435977569, 24: 0.03420019349248615, 25: 0.037066015123840834, 26: 0.02922270609149123, 27: 0.03709378899573337, 28: 0.03410087602062667, 29: 0}\n"
     ]
    }
   ],
   "source": [
    "s = make_innat_opinions(n)\n",
    "G = make_random_network(n)\n",
    "(df, actual_Y_dict) = network_data(s, G, n)\n",
    "print(actual_Y_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creat Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent28 's opinion 0.5084671545937193 changed to 0\n",
      "Min Action:    Agent29 's opinion 0.17934348970639713 changed to 0.5049045183306006\n",
      "Network reaches equilibrium Polarization: 0.013843777272779368\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.6043393588685068 changed to 0\n",
      "Min Action:    Agent19 's opinion 0.9887353281073781 changed to 0.13631645611094811\n",
      "Network reaches equilibrium Polarization: 0.01984399524040873\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.30554498211867775 changed to 0\n",
      "Min Action:    Agent27 's opinion 0.026184838412766864 changed to 0.755966875650458\n",
      "Network reaches equilibrium Polarization: 0.026203967130283303\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent28 's opinion 0.3332856406919029 changed to 1\n",
      "Min Action:    Agent4 's opinion 0.19801183479318596 changed to 0.91106470381609\n",
      "Network reaches equilibrium Polarization: 0.022832406270458516\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.718646136346613 changed to 1\n",
      "Min Action:    Agent13 's opinion 0.10527141509499083 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.039762336425150306\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.597076707484186 changed to 0\n",
      "Min Action:    Agent28 's opinion 0.08316043517523775 changed to 0.8426894149998165\n",
      "Network reaches equilibrium Polarization: 0.027783012884540083\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent27 's opinion 0.3659261320463951 changed to 1\n",
      "Min Action:    Agent28 's opinion 0.5774412784033263 changed to 0.1823751719675797\n",
      "Network reaches equilibrium Polarization: 0.02277027245782677\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.0978585320500851 changed to 1\n",
      "Min Action:    Agent28 's opinion 0.9757474608500131 changed to 0.19719582241461378\n",
      "Network reaches equilibrium Polarization: 0.026885490667512307\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.15888796719123155 changed to 1\n",
      "Min Action:    Agent28 's opinion 0.7387814219710526 changed to 0.29993267600241036\n",
      "Network reaches equilibrium Polarization: 0.018301401610714252\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.5796751361538007 changed to 0\n",
      "Min Action:    Agent26 's opinion 0.982604498337601 changed to 0.5550380059688801\n",
      "Network reaches equilibrium Polarization: 0.027676090624848857\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent28 's opinion 0.6844365770620421 changed to 1\n",
      "Min Action:    Agent29 's opinion 0.8383992005362136 changed to 0.5160802227667836\n",
      "Network reaches equilibrium Polarization: 0.047791838463254695\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent28 's opinion 0.5012893271793449 changed to 0\n",
      "Min Action:    Agent29 's opinion 0.975452748301337 changed to 0.4147968185266451\n",
      "Network reaches equilibrium Polarization: 0.011859590448962915\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.6382308052054685 changed to 0\n",
      "Min Action:    Agent5 's opinion 0.9641042214076945 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.06629047699748014\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.3504780550198593 changed to 1\n",
      "Min Action:    Agent28 's opinion 0.21025964024725752 changed to 0.5497604722636967\n",
      "Network reaches equilibrium Polarization: 0.08988520017902747\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.4508171766451786 changed to 0\n",
      "Min Action:    Agent27 's opinion 0.03461717586502755 changed to 0.9152555150193241\n",
      "Network reaches equilibrium Polarization: 0.025742061145644837\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.0930042630001977 changed to 1\n",
      "Min Action:    Agent25 's opinion 0.09586039006350155 changed to 0.8604855092153673\n",
      "Network reaches equilibrium Polarization: 0.08724511467603376\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent28 's opinion 0.2351377927457673 changed to 0\n",
      "Min Action:    Agent16 's opinion 0.8848046145079969 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.02613496711178264\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent28 's opinion 0.36005334853932425 changed to 0\n",
      "Min Action:    Agent19 's opinion 0.9380525755377759 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.020756727282780406\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent28 's opinion 0.36894812851603165 changed to 0\n",
      "Min Action:    Agent5 's opinion 0.8012892153245991 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.03386037887076072\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.23709123089889594 changed to 0\n",
      "Min Action:    Agent27 's opinion 0.352785385031825 changed to 0.8368889226919597\n",
      "Network reaches equilibrium Polarization: 0.02758094744833596\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.6179258144365309 changed to 1\n",
      "Min Action:    Agent26 's opinion 0.036570366759137274 changed to 0.6374533222983322\n",
      "Network reaches equilibrium Polarization: 0.02783593664801071\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.2844168202637315 changed to 0\n",
      "Min Action:    Agent15 's opinion 0.7696115231134997 changed to 0.13002355847677066\n",
      "Network reaches equilibrium Polarization: 0.027151736391110026\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.5585302306537553 changed to 1\n",
      "Min Action:    Agent27 's opinion 0.07157902968225915 changed to 0.6640406818829655\n",
      "Network reaches equilibrium Polarization: 0.048961025244224424\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.5937364408288683 changed to 0\n",
      "Min Action:    Agent28 's opinion 0.9924154656477351 changed to 0.4991779066782179\n",
      "Network reaches equilibrium Polarization: 0.03264323203649755\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent28 's opinion 0.6546855377038553 changed to 1\n",
      "Min Action:    Agent5 's opinion 0.13792807145419061 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.0287014201311299\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.34533329669660695 changed to 1\n",
      "Min Action:    Agent27 's opinion 0.07338902674710435 changed to 0.5924609507877546\n",
      "Network reaches equilibrium Polarization: 0.01618709632687219\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.49872440459654277 changed to 0\n",
      "Min Action:    Agent23 's opinion 0.8431320083748163 changed to 0.29800829885945107\n",
      "Network reaches equilibrium Polarization: 0.01849097126835865\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.07993685990371813 changed to 1\n",
      "Min Action:    Agent28 's opinion 0.8044444089911057 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.035737836324710254\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.03694726057934383 changed to 0\n",
      "Min Action:    Agent28 's opinion 0.17769942012449869 changed to 0.9345619654895623\n",
      "Network reaches equilibrium Polarization: 0.03254661230259242\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.7734330712076177 changed to 0\n",
      "Min Action:    Agent27 's opinion 0.8136446234301343 changed to 0.34463932763852523\n",
      "Network reaches equilibrium Polarization: 0.023683316440345836\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent27 's opinion 0.8778300331282738 changed to 0\n",
      "Min Action:    Agent29 's opinion 0.07337347845138664 changed to 0.44161823446178455\n",
      "Network reaches equilibrium Polarization: 0.031403010623878146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.27507425995920065 changed to 1\n",
      "Min Action:    Agent21 's opinion 0.014181068722273205 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.26518961719180273\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.7894250256605397 changed to 0\n",
      "Min Action:    Agent9 's opinion 0.906997375235912 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.03996107335376198\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.498237007985726 changed to 1\n",
      "Min Action:    Agent6 's opinion 0.1517239615849486 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.034023491779272795\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.33730715933252153 changed to 0\n",
      "Min Action:    Agent21 's opinion 0.939400442783137 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.046042707541771054\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent27 's opinion 0.652222440078705 changed to 0\n",
      "Min Action:    Agent28 's opinion 0.38794053979774945 changed to 0.9104583464408136\n",
      "Network reaches equilibrium Polarization: 0.03095246139818012\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent28 's opinion 0.668295776118089 changed to 1\n",
      "Min Action:    Agent27 's opinion 0.7235600622999775 changed to 0.15409265920391302\n",
      "Network reaches equilibrium Polarization: 0.020995507039697596\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.36527270171058124 changed to 1\n",
      "Min Action:    Agent27 's opinion 0.7947548706886558 changed to 0.2123700886996313\n",
      "Network reaches equilibrium Polarization: 0.01957683510058903\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.4344053231122311 changed to 1\n",
      "Min Action:    Agent28 's opinion 0.691143550213583 changed to 0.11667259136406849\n",
      "Network reaches equilibrium Polarization: 0.037754270855257364\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.8703526415430402 changed to 1\n",
      "Min Action:    Agent28 's opinion 0.017073781085810147 changed to 0.657944323924182\n",
      "Network reaches equilibrium Polarization: 0.07389658982555983\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.25572237519932883 changed to 0\n",
      "Min Action:    Agent27 's opinion 0.1130536205747874 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.04858007155849864\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.12201623488053404 changed to 1\n",
      "Min Action:    Agent28 's opinion 0.5159876200940546 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.045353268425640796\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.36593145204846267 changed to 0\n",
      "Min Action:    Agent8 's opinion 0.9314914946292533 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.06924298582256952\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent28 's opinion 0.8495055688072242 changed to 1\n",
      "Min Action:    Agent27 's opinion 0.7536488944769534 changed to 0.29992777395416265\n",
      "Network reaches equilibrium Polarization: 0.026214919800661946\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent28 's opinion 0.0966152096572086 changed to 1\n",
      "Min Action:    Agent26 's opinion 0.978291269663588 changed to 0.03871345525074895\n",
      "Network reaches equilibrium Polarization: 0.04125527511742751\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent27 's opinion 0.6335317862692983 changed to 0\n",
      "Min Action:    Agent22 's opinion 0.09889992550404314 changed to 0.8800307350732617\n",
      "Network reaches equilibrium Polarization: 0.03238482290905318\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.5439203726805061 changed to 0\n",
      "Min Action:    Agent28 's opinion 0.29215621782750767 changed to 0.8317968055248465\n",
      "Network reaches equilibrium Polarization: 0.018546717658809626\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent28 's opinion 0.18984467148017048 changed to 0\n",
      "Min Action:    Agent27 's opinion 0.048828147056676485 changed to 0.8235131716622411\n",
      "Network reaches equilibrium Polarization: 0.032944794348501893\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent28 's opinion 0.5069616995266488 changed to 0\n",
      "Min Action:    Agent29 's opinion 0.8964539279635413 changed to 0.08929062159951844\n",
      "Network reaches equilibrium Polarization: 0.07948659221280327\n",
      "Epoch 1/50\n",
      "9/9 - 0s - loss: 0.0106 - mae: 0.0782\n",
      "Epoch 2/50\n",
      "9/9 - 0s - loss: 0.0030 - mae: 0.0421\n",
      "Epoch 3/50\n",
      "9/9 - 0s - loss: 0.0017 - mae: 0.0311\n",
      "Epoch 4/50\n",
      "9/9 - 0s - loss: 9.3336e-04 - mae: 0.0244\n",
      "Epoch 5/50\n",
      "9/9 - 0s - loss: 8.0299e-04 - mae: 0.0227\n",
      "Epoch 6/50\n",
      "9/9 - 0s - loss: 6.4248e-04 - mae: 0.0205\n",
      "Epoch 7/50\n",
      "9/9 - 0s - loss: 5.6948e-04 - mae: 0.0187\n",
      "Epoch 8/50\n",
      "9/9 - 0s - loss: 5.3291e-04 - mae: 0.0185\n",
      "Epoch 9/50\n",
      "9/9 - 0s - loss: 4.6496e-04 - mae: 0.0171\n",
      "Epoch 10/50\n",
      "9/9 - 0s - loss: 4.5170e-04 - mae: 0.0173\n",
      "Epoch 11/50\n",
      "9/9 - 0s - loss: 4.7791e-04 - mae: 0.0176\n",
      "Epoch 12/50\n",
      "9/9 - 0s - loss: 4.0298e-04 - mae: 0.0161\n",
      "Epoch 13/50\n",
      "9/9 - 0s - loss: 3.9469e-04 - mae: 0.0160\n",
      "Epoch 14/50\n",
      "9/9 - 0s - loss: 3.8425e-04 - mae: 0.0163\n",
      "Epoch 15/50\n",
      "9/9 - 0s - loss: 3.8757e-04 - mae: 0.0158\n",
      "Epoch 16/50\n",
      "9/9 - 0s - loss: 3.6210e-04 - mae: 0.0152\n",
      "Epoch 17/50\n",
      "9/9 - 0s - loss: 3.7078e-04 - mae: 0.0154\n",
      "Epoch 18/50\n",
      "9/9 - 0s - loss: 3.6599e-04 - mae: 0.0155\n",
      "Epoch 19/50\n",
      "9/9 - 0s - loss: 3.5169e-04 - mae: 0.0151\n",
      "Epoch 20/50\n",
      "9/9 - 0s - loss: 3.6557e-04 - mae: 0.0154\n",
      "Epoch 21/50\n",
      "9/9 - 0s - loss: 3.6460e-04 - mae: 0.0151\n",
      "Epoch 22/50\n",
      "9/9 - 0s - loss: 3.9090e-04 - mae: 0.0159\n",
      "Epoch 23/50\n",
      "9/9 - 0s - loss: 3.7293e-04 - mae: 0.0157\n",
      "Epoch 24/50\n",
      "9/9 - 0s - loss: 4.2457e-04 - mae: 0.0164\n",
      "Epoch 25/50\n",
      "9/9 - 0s - loss: 5.1661e-04 - mae: 0.0174\n",
      "Epoch 26/50\n",
      "9/9 - 0s - loss: 3.7433e-04 - mae: 0.0154\n",
      "Epoch 27/50\n",
      "9/9 - 0s - loss: 3.1800e-04 - mae: 0.0141\n",
      "Epoch 28/50\n",
      "9/9 - 0s - loss: 3.3968e-04 - mae: 0.0148\n",
      "Epoch 29/50\n",
      "9/9 - 0s - loss: 3.0651e-04 - mae: 0.0141\n",
      "Epoch 30/50\n",
      "9/9 - 0s - loss: 3.3133e-04 - mae: 0.0143\n",
      "Epoch 31/50\n",
      "9/9 - 0s - loss: 3.3838e-04 - mae: 0.0149\n",
      "Epoch 32/50\n",
      "9/9 - 0s - loss: 3.1852e-04 - mae: 0.0143\n",
      "Epoch 33/50\n",
      "9/9 - 0s - loss: 2.9262e-04 - mae: 0.0135\n",
      "Epoch 34/50\n",
      "9/9 - 0s - loss: 2.8596e-04 - mae: 0.0135\n",
      "Epoch 35/50\n",
      "9/9 - 0s - loss: 2.9316e-04 - mae: 0.0134\n",
      "Epoch 36/50\n",
      "9/9 - 0s - loss: 3.0011e-04 - mae: 0.0138\n",
      "Epoch 37/50\n",
      "9/9 - 0s - loss: 3.1049e-04 - mae: 0.0138\n",
      "Epoch 38/50\n",
      "9/9 - 0s - loss: 3.4509e-04 - mae: 0.0143\n",
      "Epoch 39/50\n",
      "9/9 - 0s - loss: 2.9599e-04 - mae: 0.0137\n",
      "Epoch 40/50\n",
      "9/9 - 0s - loss: 2.9378e-04 - mae: 0.0134\n",
      "Epoch 41/50\n",
      "9/9 - 0s - loss: 3.0451e-04 - mae: 0.0139\n",
      "Epoch 42/50\n",
      "9/9 - 0s - loss: 3.0803e-04 - mae: 0.0138\n",
      "Epoch 43/50\n",
      "9/9 - 0s - loss: 3.0370e-04 - mae: 0.0137\n",
      "Epoch 44/50\n",
      "9/9 - 0s - loss: 3.0613e-04 - mae: 0.0136\n",
      "Epoch 45/50\n",
      "9/9 - 0s - loss: 3.1304e-04 - mae: 0.0139\n",
      "Epoch 46/50\n",
      "9/9 - 0s - loss: 3.3371e-04 - mae: 0.0146\n",
      "Epoch 47/50\n",
      "9/9 - 0s - loss: 2.8398e-04 - mae: 0.0132\n",
      "Epoch 48/50\n",
      "9/9 - 0s - loss: 2.9550e-04 - mae: 0.0133\n",
      "Epoch 49/50\n",
      "9/9 - 0s - loss: 2.6813e-04 - mae: 0.0126\n",
      "Epoch 50/50\n",
      "9/9 - 0s - loss: 2.7021e-04 - mae: 0.0129\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize an empty DataFrame to store your data\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Initialize empty lists to store data for training and testing\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "for i in range(1, 50):  # Change the range if you want more iterations\n",
    "    # Your existing code here to generate data for each iteration\n",
    "    s = make_innat_opinions(n)\n",
    "    G = make_random_network(n)\n",
    "    (v1, v2, max_opinion, min_opinion, max_pol) = MaxMin_play(s, n, G)\n",
    "    (converted_dict, converted_dict1, converted_dict2, sorted_gap, scaled_MinPaths_sort) = metrics(G, v1)\n",
    "    \n",
    "    # Calculate actual ranks and rescale polarization change\n",
    "    (actual_Y_dict, actual_ranks) = actual_rank(s, n, v1, max_opinion)\n",
    "    rescaled_dict = rescale(actual_Y_dict)\n",
    "    \n",
    "    keys = list(converted_dict2.keys())\n",
    "    # Assuming you have generated 'temp_df' as you did in your original code\n",
    "    temp_df = pd.DataFrame({'keys': list(converted_dict2.keys()),\n",
    "                            'x11': [sorted_gap[x] for x in keys],\n",
    "                            'x22': [converted_dict2[x] for x in converted_dict2.keys()],\n",
    "                            'x33': [scaled_MinPaths_sort.get(x,0) for x in keys],\n",
    "                            'y_value': [actual_Y_dict[x] for x in keys]})\n",
    "\n",
    "    # Append the temporary DataFrame to the main DataFrame\n",
    "    df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "    # Append the data to either the training or testing list\n",
    "    if i <= 40:  # Use every 5th iteration for testing, adjust as needed\n",
    "        test_data.append(temp_df)\n",
    "    else:\n",
    "        train_data.append(temp_df)\n",
    "\n",
    "# Concatenate the training and testing dataframes\n",
    "train_df = pd.concat(train_data, ignore_index=True)\n",
    "test_df = pd.concat(test_data, ignore_index=True)\n",
    "\n",
    "# Split the data into features (X) and target (Y)\n",
    "X_train = train_df[['x11', 'x22', 'x33']].values\n",
    "Y_train = train_df['y_value'].values\n",
    "X_test = test_df[['x11', 'x22', 'x33']].values\n",
    "Y_test = test_df['y_value'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standardize the features (important for neural networks)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define a simple neural network model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1)  # Output layer with a single neuron (for regression)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=32, verbose=2)\n",
    "\n",
    "# Use the trained model to make predictions on the test data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# # Print the predictions\n",
    "# for i, pred in enumerate(predictions):\n",
    "#     print(f\"Prediction for sample {i+1}: {pred[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Check Model Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 Weights:\n",
      "[[ 0.078 -0.085  0.058 -0.013 -0.22  -0.282  0.224 -0.214 -0.151  0.224\n",
      "   0.099  0.254 -0.144  0.046 -0.183  0.218  0.002  0.039 -0.305  0.18\n",
      "  -0.115 -0.09   0.154 -0.094 -0.144 -0.059  0.306  0.302 -0.04  -0.299\n",
      "  -0.048 -0.136 -0.258 -0.21  -0.23  -0.111 -0.208 -0.098 -0.115  0.271\n",
      "   0.032 -0.133 -0.024 -0.228  0.114 -0.06   0.009 -0.213 -0.049 -0.141\n",
      "   0.093  0.044 -0.217 -0.09  -0.152  0.227 -0.216  0.157  0.235 -0.232\n",
      "  -0.132  0.263  0.042 -0.035]\n",
      " [-0.034 -0.095  0.103 -0.006  0.273  0.183 -0.257  0.213  0.152 -0.19\n",
      "   0.274 -0.118 -0.267 -0.176  0.215 -0.223 -0.177 -0.014  0.246 -0.249\n",
      "   0.239  0.09   0.053 -0.177 -0.1   -0.023  0.05  -0.262 -0.221 -0.245\n",
      "  -0.246 -0.085 -0.044  0.119  0.03   0.11   0.3    0.065 -0.039  0.184\n",
      "   0.019 -0.171  0.185 -0.196  0.244 -0.03   0.225  0.083  0.205  0.259\n",
      "   0.097 -0.301  0.227 -0.276  0.188 -0.038  0.261  0.009 -0.253 -0.271\n",
      "   0.187 -0.014 -0.101 -0.173]\n",
      " [-0.275 -0.075  0.103  0.286  0.012  0.151  0.02  -0.171 -0.126 -0.179\n",
      "  -0.265  0.136 -0.141 -0.103  0.055 -0.172 -0.034  0.135  0.068  0.036\n",
      "   0.175  0.199 -0.192 -0.284  0.2    0.039 -0.269 -0.226  0.014  0.254\n",
      "   0.209  0.134 -0.013  0.282  0.171  0.146  0.099 -0.37   0.224  0.047\n",
      "  -0.14  -0.095 -0.154 -0.193 -0.249  0.146 -0.265  0.032  0.212 -0.065\n",
      "  -0.285  0.109  0.226 -0.186 -0.127  0.03  -0.171  0.087 -0.081 -0.264\n",
      "   0.035 -0.101  0.083  0.23 ]]\n",
      "Layer 1 Weights:\n",
      "[ 0.007  0.005 -0.029 -0.082 -0.006  0.003 -0.02  -0.005 -0.006 -0.005\n",
      "  0.01   0.001 -0.009  0.011 -0.067 -0.05  -0.01  -0.028 -0.002 -0.006\n",
      " -0.006  0.012 -0.023 -0.051  0.017 -0.037  0.035 -0.024 -0.021 -0.026\n",
      "  0.017 -0.029  0.002 -0.002 -0.008 -0.044 -0.005 -0.006 -0.068 -0.012\n",
      "  0.04  -0.03  -0.04   0.029 -0.006 -0.007 -0.03  -0.038  0.003 -0.007\n",
      " -0.027 -0.005 -0.004 -0.066 -0.012  0.005 -0.043 -0.026 -0.024  0.004\n",
      " -0.025 -0.016  0.004  0.037]\n",
      "Layer 2 Weights:\n",
      "[[ 0.221 -0.139  0.051 ... -0.165 -0.22  -0.145]\n",
      " [ 0.137  0.021  0.02  ... -0.165  0.235  0.228]\n",
      " [-0.012 -0.111 -0.169 ...  0.115 -0.03   0.093]\n",
      " ...\n",
      " [-0.066  0.225  0.114 ... -0.171  0.059 -0.219]\n",
      " [-0.028 -0.077  0.05  ...  0.227 -0.078  0.208]\n",
      " [-0.068 -0.015 -0.082 ... -0.124  0.078  0.184]]\n",
      "Layer 3 Weights:\n",
      "[-0.015 -0.008 -0.003  0.005 -0.006  0.002 -0.014  0.01  -0.015  0.019\n",
      " -0.     0.017 -0.02  -0.009 -0.001  0.078 -0.009 -0.003 -0.011 -0.002\n",
      "  0.008 -0.002 -0.008  0.008 -0.023 -0.007  0.001 -0.004  0.02   0.009\n",
      " -0.02   0.017]\n",
      "Layer 4 Weights:\n",
      "[[-0.149]\n",
      " [-0.241]\n",
      " [-0.165]\n",
      " [ 0.022]\n",
      " [-0.107]\n",
      " [-0.349]\n",
      " [-0.26 ]\n",
      " [ 0.054]\n",
      " [-0.098]\n",
      " [ 0.229]\n",
      " [-0.306]\n",
      " [ 0.198]\n",
      " [-0.189]\n",
      " [-0.339]\n",
      " [ 0.271]\n",
      " [-0.191]\n",
      " [-0.218]\n",
      " [ 0.234]\n",
      " [-0.089]\n",
      " [ 0.4  ]\n",
      " [-0.077]\n",
      " [ 0.139]\n",
      " [ 0.415]\n",
      " [-0.258]\n",
      " [-0.123]\n",
      " [ 0.246]\n",
      " [-0.276]\n",
      " [-0.338]\n",
      " [ 0.012]\n",
      " [ 0.41 ]\n",
      " [-0.141]\n",
      " [ 0.317]]\n",
      "Layer 5 Weights:\n",
      "[0.013]\n"
     ]
    }
   ],
   "source": [
    "# Get the weights and biases of the neural network\n",
    "weights = model.get_weights()\n",
    "\n",
    "# Print the weights and biases\n",
    "for layer_num, layer_weights in enumerate(weights):\n",
    "    print(f\"Layer {layer_num} Weights:\")\n",
    "    print(layer_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0017 - mae: 0.0226\n",
      "Mean Absolute Error on Test Data: 0.022606603801250458\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, mae = model.evaluate(X_test, Y_test)\n",
    "# Print the Mean Absolute Error\n",
    "print(f\"Mean Absolute Error on Test Data: {mae}\")\n",
    "# Use the trained model to make predictions on the test data\n",
    "predictions = model.predict(X_test)\n",
    "print(predictions)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE) manually\n",
    "mae = np.mean(np.abs(predictions - Y_test))\n",
    "print(f\"Mean Absolute Error on Test Data: {mae}\")\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(Y_test, predictions)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "# Calculate R-squared score\n",
    "r2 = r2_score(Y_test, predictions)\n",
    "print(f\"R-squared (R^2) Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.6226527909046995 changed to 1\n",
      "Min Action:    Agent26 's opinion 0.000984043874843299 changed to 0.5547007727634141\n",
      "Network reaches equilibrium Polarization: 0.016080010549744186\n",
      "_________________\n",
      "True\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.6226527909046995 changed to 1\n",
      "Min Action:    Agent26 's opinion 0.000984043874843299 changed to 0.5547007727634141\n",
      "Network reaches equilibrium Polarization: 0.016080010549744186\n",
      "{0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0, 6: 0.5, 7: 1.0, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.5, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0, 20: 1.0, 21: 1.0, 22: 0.5, 23: 1.0, 24: 0.5, 25: 0.5, 26: 1.0, 27: 1.0, 28: 1.0, 29: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.3541732845321627 changed to 0\n",
      "Min Action:    Agent28 's opinion 0.9453848410127564 changed to 0.4667759539039294\n",
      "Network reaches equilibrium Polarization: 0.031239528658814436\n",
      "_________________\n",
      "True\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.3541732845321627 changed to 0\n",
      "Min Action:    Agent28 's opinion 0.9453848410127564 changed to 0.4667759539039294\n",
      "Network reaches equilibrium Polarization: 0.031239528658814436\n",
      "{0: 1.0, 1: 0.6666666666666667, 2: 0.6666666666666667, 3: 0.3333333333333333, 4: 0.6666666666666667, 5: 0.6666666666666667, 6: 0.6666666666666667, 7: 0.6666666666666667, 8: 0.6666666666666667, 9: 0.6666666666666667, 10: 0.6666666666666667, 11: 0.6666666666666667, 12: 0.6666666666666667, 13: 0.6666666666666667, 14: 0.6666666666666667, 15: 0.6666666666666667, 16: 0.3333333333333333, 17: 0.6666666666666667, 18: 0.6666666666666667, 19: 0.6666666666666667, 20: 0.6666666666666667, 21: 0.6666666666666667, 22: 0.6666666666666667, 23: 0.6666666666666667, 24: 0.6666666666666667, 25: 0.6666666666666667, 26: 0.6666666666666667, 27: 0.3333333333333333, 28: 1.0, 29: 0.0}\n",
      "Actual Value: 0.00756561708792502\n",
      "Predicted Value: 0.0010581613\n",
      "Difference: 0.00650745582922751\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assume you have the necessary functions defined: make_innat_opinions, make_random_network, network_data,\n",
    "# MaxMin_play, metrics, actual_rank, and rescale\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Define the number of iterations\n",
    "num_iterations = 50  # Change this number if needed\n",
    "\n",
    "# Initialize lists to store actual and predicted values\n",
    "actual_values = []\n",
    "predicted_values = []\n",
    "\n",
    "# Create a neural network model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(3,)),  # Three features (x11, x22, x33)\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1)  # Output layer with a single neuron (for regression)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Loop through iterations\n",
    "for i in range(2):\n",
    "    s = make_innat_opinions(n)\n",
    "    G = make_random_network(n)\n",
    "    (temp_df, actual_Y_dict) = network_data(s, G, n)\n",
    "    (v1, v2, max_opinion, min_opinion, max_pol) = MaxMin_play(s, n, G)\n",
    "    (converted_dict, converted_dict1, converted_dict2, sorted_gap, scaled_MinPaths_sort) = metrics(G, v1)\n",
    "\n",
    "    # Calculate actual ranks and rescale polarization change\n",
    "    (actual_Y_dict, actual_ranks) = actual_rank(s, n, v1, max_opinion)\n",
    "    # rescaled_dict = rescale(actual_Y_dict)\n",
    "\n",
    "    # Create a temporary DataFrame for the current iteration's data\n",
    "    temp_df = pd.DataFrame({\n",
    "        'x11': [sorted_gap[x] for x in converted_dict2.keys()],\n",
    "        'x22': [converted_dict2[x] for x in converted_dict2.keys()],\n",
    "        'x33': [scaled_MinPaths_sort[x] for x in converted_dict2.keys()],\n",
    "        'y_value': [actual_Y_dict[x] for x in converted_dict2.keys()]\n",
    "    })\n",
    "    print(scaled_MinPaths_sort)\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    temp_df[['x11', 'x22', 'x33']] = scaler.fit_transform(temp_df[['x11', 'x22', 'x33']])\n",
    "\n",
    "    # Concatenate the temporary DataFrame to the main DataFrame\n",
    "    df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "    # Extract features (x11, x22, x33) and target (y_value)\n",
    "    X = temp_df[['x11', 'x22', 'x33']].values\n",
    "    y = temp_df['y_value'].values\n",
    "\n",
    "    # Train the neural network for each iteration\n",
    "    model.fit(X, y, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    # Predict the target values\n",
    "    predictions = model.predict(X)\n",
    "\n",
    "    # Append actual and predicted values to their respective lists\n",
    "    actual_values.extend(y)\n",
    "    predicted_values.extend(predictions.flatten())\n",
    "\n",
    "# Calculate the difference between actual and predicted values\n",
    "differences = np.abs(np.array(actual_values) - np.array(predicted_values))\n",
    "\n",
    "# Print the first predicted value and its actual value\n",
    "print(\"Actual Value:\", actual_values[0])\n",
    "print(\"Predicted Value:\", predicted_values[0])\n",
    "print(\"Difference:\", differences[0])\n",
    "print(f\"Predicted y_value for the test network: {predictions[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Trainning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.33182652280157865 changed to 1\n",
      "Min Action:    Agent19 's opinion 0.01888198846842215 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.2305021873252756\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-83380ea8cb83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_innat_opinions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_random_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactual_Y_dict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_opinion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_opinion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_pol\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMaxMin_play\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mconverted_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconverted_dict1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconverted_dict2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_gap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaled_MinPaths_sort\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-56f4fb491fb5>\u001b[0m in \u001b[0;36mnetwork_data\u001b[1;34m(s, G, n)\u001b[0m\n\u001b[0;32m      9\u001b[0m                    \u001b[1;34m'x11'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msorted_gap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconverted_dict2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                    \u001b[1;34m'x22'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconverted_dict2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconverted_dict2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                    \u001b[1;34m'x33'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mscaled_MinPaths_sort\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconverted_dict2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m                    'y_value': [actual_Y_dict[x] for x in converted_dict2.keys()]})\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-56f4fb491fb5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m                    \u001b[1;34m'x11'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msorted_gap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconverted_dict2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                    \u001b[1;34m'x22'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconverted_dict2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconverted_dict2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                    \u001b[1;34m'x33'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mscaled_MinPaths_sort\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconverted_dict2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m                    'y_value': [actual_Y_dict[x] for x in converted_dict2.keys()]})\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# def creat_data(n, N):\n",
    "#     # Initialize the DataFrame with data from the first iteration\n",
    "#     s = make_innat_opinions(n)\n",
    "#     G = make_random_network(n)\n",
    "#     (v1, v2, max_opinion, min_opinion, max_pol) = MaxMin_play(s, n, G)\n",
    "#     (converted_dict, converted_dict1, converted_dict2, sorted_gap, scaled_MinPaths_sort) = metrics(G, v1)\n",
    "#     (actual_Y_dict, actual_ranks) = actual_rank(s, n, v1, max_opinion)\n",
    "#     #rescaled_dict = rescale(actual_Y_dict)\n",
    "#     print(\"_________________\")\n",
    "#     a = sorted(actual_Y_dict.items(), key=lambda x:x[1])\n",
    "#     print(a[1][0]==v2)\n",
    "\n",
    "\n",
    "#     df = pd.DataFrame({'keys': list(converted_dict2.keys()),\n",
    "#                        'x11': [sorted_gap[x][0] for x in converted_dict2.keys()],\n",
    "#                        'x22': [converted_dict2[x] for x in converted_dict2.keys()],\n",
    "#                        'x33': [scaled_MinPaths_sort[x] for x in converted_dict2.keys()],\n",
    "#                        'y_value': [actual_Y_dict[x] for x in converted_dict2.keys()]})\n",
    "\n",
    "\n",
    "#     print(\"_________________\")\n",
    "#     a = sorted(actual_Y_dict.items(), key=lambda x:x[1])\n",
    "#     print(a[1][0]==v2)\n",
    "#     print(\"__________________\")\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i in range(1, 50):  # Change the range if you want more iterations\n",
    "    s = make_innat_opinions(n)\n",
    "    G = make_random_network(n)\n",
    "    (temp_df, actual_Y_dict) = network_data(s, G, n)\n",
    "    (v1, v2, max_opinion, min_opinion, max_pol) = MaxMin_play(s, n, G)\n",
    "    (converted_dict, converted_dict1, converted_dict2, sorted_gap, scaled_MinPaths_sort) = metrics(G, v1)\n",
    "\n",
    "    # Calculate actual ranks and rescale polarization change\n",
    "    (actual_Y_dict, actual_ranks) = actual_rank(s, n, v1, max_opinion)\n",
    "    #rescaled_dict = rescale(actual_Y_dict)\n",
    "\n",
    "    # Create a temporary DataFrame for the current iteration's data\n",
    "    temp_df = pd.DataFrame({'keys': list(converted_dict2.keys()),\n",
    "                            'x11': [sorted_gap[x] for x in converted_dict2.keys()],\n",
    "                            'x22': [converted_dict2[x] for x in converted_dict2.keys()],\n",
    "                            'x33': [scaled_MinPaths_sort[x] for x in scaled_MinPaths_sort.keys()],\n",
    "                            'y_value': [actual_Y_dict[x] for x in converted_dict2.keys()]})\n",
    "\n",
    "    # Concatenate the temporary DataFrame to the main DataFrame\n",
    "    df = pd.concat([df, temp_df], ignore_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent28 's opinion 0.6023554375757443 changed to 0\n",
      "Min Action:    Agent25 's opinion 0.9562842372875656 changed to 0.6065065580033292\n",
      "Network reaches equilibrium Polarization: 0.016077623621038515\n",
      "_________________\n",
      "True\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent28 's opinion 0.6023554375757443 changed to 0\n",
      "Min Action:    Agent25 's opinion 0.9562842372875656 changed to 0.6065065580033292\n",
      "Network reaches equilibrium Polarization: 0.016077623621038515\n"
     ]
    }
   ],
   "source": [
    "# create testing data\n",
    "df1 = pd.DataFrame()\n",
    "for i in range(1):  # Change the range if you want more iterations\n",
    "    s = make_innat_opinions(n)\n",
    "    G = make_random_network(n)\n",
    "    (temp_df, actual_Y_dict) = network_data(s, G, n)\n",
    "    (v1, v2, max_opinion, min_opinion, max_pol) = MaxMin_play(s, n, G)\n",
    "    (converted_dict, converted_dict1, converted_dict2, sorted_gap, scaled_MinPaths_sort) = metrics(G, v1)\n",
    "\n",
    "    # Calculate actual ranks and rescale polarization change\n",
    "    (actual_Y_dict, actual_ranks) = actual_rank(s, n, v1, max_opinion)\n",
    "    #rescaled_dict = rescale(actual_Y_dict)\n",
    "\n",
    "    # Create a temporary DataFrame for the current iteration's data\n",
    "    temp_df = pd.DataFrame({'keys': list(converted_dict2.keys()),\n",
    "                            'x11': [sorted_gap[x] for x in converted_dict2.keys()],\n",
    "                            'x22': [converted_dict2[x] for x in converted_dict2.keys()],\n",
    "                            'x33': [scaled_MinPaths_sort[x] for x in converted_dict2.keys()],\n",
    "                            'y_value': [actual_Y_dict[x] for x in converted_dict2.keys()]})\n",
    "\n",
    "    # Concatenate the temporary DataFrame to the main DataFrame\n",
    "    df1 = pd.concat([df1, temp_df], ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df:     const  keys       x11       x22       x33   y_value\n",
      "0     1.0     0  0.698243  0.624098  0.666667  0.003389\n",
      "1     1.0     1  0.790401  0.692491  0.333333  0.003894\n",
      "2     1.0     2  0.522414  0.737438  0.666667  0.004365\n",
      "3     1.0     3  0.634123  0.660801  0.666667  0.003371\n",
      "4     1.0     4  0.742036  0.679378  0.666667  0.003375\n",
      "5     1.0     5  0.527894  0.677503  0.666667  0.003841\n",
      "6     1.0     6  0.861896  1.000000  0.333333  0.004143\n",
      "7     1.0     7  0.860905  0.903703  0.333333  0.004139\n",
      "8     1.0     8  1.000000  0.865950  0.666667  0.003112\n",
      "9     1.0     9  0.974292  0.852483  0.666667  0.003963\n",
      "10    1.0    10  0.206775  0.980180  0.666667  0.004342\n",
      "11    1.0    11  0.010986  0.883571  0.666667  0.004332\n",
      "12    1.0    12  0.762645  0.893460  0.666667  0.003564\n",
      "13    1.0    13  0.070004  0.835888  0.666667  0.004325\n",
      "14    1.0    14  0.092986  0.739548  0.666667  0.004349\n",
      "15    1.0    15  0.914326  0.749338  0.666667  0.003293\n",
      "16    1.0    16  0.000000  0.732002  0.666667  0.004241\n",
      "17    1.0    17  0.092116  0.674298  0.333333  0.004294\n",
      "18    1.0    18  0.604845  0.670243  0.333333  0.003198\n",
      "19    1.0    19  0.454999  0.683604  0.666667  0.004023\n",
      "20    1.0    20  0.839966  0.582417  0.666667  0.003970\n",
      "21    1.0    21  0.440871  0.777961  0.666667  0.004073\n",
      "22    1.0    22  0.150946  0.620826  0.666667  0.004353\n",
      "23    1.0    23  0.759306  0.443111  0.666667  0.003255\n",
      "24    1.0    24  0.708678  0.492357  0.666667  0.003565\n",
      "25    1.0    25  0.953766  0.266214  1.000000  0.003092\n",
      "26    1.0    26  0.191835  0.221273  0.666667  0.004243\n",
      "27    1.0    27  0.180224  0.126644  0.666667  0.003938\n",
      "28    1.0    28  0.233307  0.095255  0.000000  0.000000\n",
      "29    1.0    29  0.387357  0.000000  0.333333  0.004217\n",
      "predictions [(28, 0.008754212898974073), (29, 0.011951224710081311), (1, 0.01678428339222567), (18, 0.016830494185308607), (27, 0.017269292354793946), (17, 0.017460057849816024), (26, 0.01798046207250216), (7, 0.018319585410549937), (23, 0.019017032793617883), (6, 0.019055929802209038), (24, 0.01945328944834245), (20, 0.019989770566901485), (0, 0.020474422607340084), (3, 0.02083036431763774), (4, 0.020846673246607855), (5, 0.021082281084870185), (22, 0.021088227593618492), (15, 0.021181360141095687), (19, 0.02121409346165484), (25, 0.021541608836999196), (2, 0.021547696023404846), (9, 0.02190131039172312), (21, 0.021953235249769103), (8, 0.021974441086428546), (14, 0.02206513235725116), (16, 0.022115876774919767), (12, 0.022462191391619726), (13, 0.02282979058275598), (11, 0.023263870762474482), (10, 0.02377521230639021)]\n",
      "actual values [(28, 0), (25, 0.0030919865442198893), (8, 0.0031122031843165247), (18, 0.0031981204992056304), (23, 0.003254984968395963), (15, 0.0032932904390964544), (3, 0.003370577133469964), (4, 0.0033749070443898146), (0, 0.0033889576254761064), (12, 0.0035639902267741823), (24, 0.0035645974403405965), (5, 0.003841192083629201), (1, 0.0038935400818983674), (27, 0.003938006039578834), (9, 0.003962697978074501), (20, 0.003970499889970301), (19, 0.004023116457642906), (21, 0.0040733187759542724), (7, 0.004139436362001623), (6, 0.004143015034158523), (29, 0.004217195349386863), (16, 0.004241011523816004), (26, 0.004242634914863066), (17, 0.004294223541400424), (13, 0.004325430979800586), (11, 0.004332151934007138), (10, 0.004342186075297079), (14, 0.004349023610798773), (22, 0.004353080930025819), (2, 0.004364953373075589)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xzhan\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    }
   ],
   "source": [
    "#  Creat testing\n",
    "# (df, actual_Y_dict_test) = creat_data(n, 1)\n",
    "# print(\"DataFrame\", df)\n",
    "# print(\"Actual_Y_dict\", actual_Y_dict_test)\n",
    "# # actual_min = np.argmax(df[\"y_value\"])\n",
    "# # print('Min s', actual_min)\n",
    "\n",
    "test_df = sm.add_constant(df1)\n",
    "print('test_df:',test_df)\n",
    "# Use the trained model to make predictions on the new data\n",
    "predictions = model.predict(test_df[['const', 'x11', 'x22', 'x33']])\n",
    "sorted_predictions = sorted(predictions.items(), key=lambda x:x[1])\n",
    "# # Print or use the predictions as needed\n",
    "print(\"predictions\", sorted_predictions)\n",
    "\n",
    "sorted_actual_Y_dict = sorted(actual_Y_dict.items(), key=lambda x:x[1])\n",
    "print(\"actual values\", sorted_actual_Y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(29, 0), (25, 0.00040657091805073806), (2, 0.001773838572260926), (21, 0.0018749557517400706), (23, 0.0020531171860036293), (14, 0.002202128022298043), (10, 0.0025835762471996884), (18, 0.00271894002204999), (26, 0.0027535264735846846), (13, 0.002784035032888668), (6, 0.0028127358484876692), (17, 0.0028547120575342956), (4, 0.0028582587959319686), (22, 0.0028805401654238283), (3, 0.0029748191274902927), (24, 0.0029885525392130477), (8, 0.0030030718505019566), (1, 0.003013648350633027), (0, 0.003039554731715355), (19, 0.0030516378590010884), (15, 0.003088247734453285), (20, 0.0031010346312026794), (12, 0.003127983331037691), (7, 0.003205938458982392), (11, 0.0032301317374829747), (27, 0.0032369515651250423), (16, 0.003254671460723748), (9, 0.0032604258732439814), (28, 0.0032693800563578027), (5, 0.0032778666281935258)]\n"
     ]
    }
   ],
   "source": [
    "a = sorted(actual_Y_dict_test.items(), key=lambda x:x[1])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    539\n",
      "1    209\n",
      "2    389\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find k nodes index with smallest polarization - use to predict minimizer's choice\n",
    "k = 3\n",
    "print(pred_Y.argsort()[:k])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
