{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### This code is from Updated Testing Reddit - No Con- bias (Fictitious Play)-01092022\n",
    "##### This code replace the big real datanetwork with small sythetic network \n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "import time\n",
    "import random\n",
    "from scipy.stats import beta\n",
    "import pandas as pd\n",
    "import copy\n",
    "%matplotlib inline\n",
    "#%run pure_strategy_selection.ipynb  #include simple selection algorithm\n",
    "import scipy.io\n",
    "import collections\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathmatic Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing players' behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def MinMax_play(s,n):    # maxmizer first-time play, greedy algorithm\n",
    "    # print('Minimizer Play')\n",
    "   \n",
    "    (v1, min_opinion, min_pol, max_action) = choose_min_vertex(s, n) # The best choice among all opinions and vertexs, function is in \"pure_strategy_selection.ipynb\"\n",
    "    (v2, max_opinion) = max_action\n",
    "    if v1 == None:   # if maximizer cannot find one\n",
    "        print('Maximizer fail')\n",
    "\n",
    "    else:\n",
    "        # print(\"                                \")\n",
    "        # print(\"Maximizer finds its target agent:\")\n",
    "#         print('v1', 'changed_opinion', 'innate_obj', 'obj')\n",
    "#         print(max_champion)\n",
    "\n",
    "        #Store innate_op of the max_selected vertex\n",
    "        old_opinion_min = s[v1, 0]\n",
    "        old_opinion_max = s[v2, 0]\n",
    "        ##### change the agent's opinion with best action(agent v1, max_op)\n",
    "\n",
    "        ## check if agent's opinionis is changed or not\n",
    "        # print(\"Max Action:    \"+\"Agent\" + str(v2) +\" 's opinion \" + str(old_opinion_max) + \" changed to \"+ str(max_opinion))\n",
    "        # print(\"Min Action:    \"+\"Agent\" + str(v1) +\" 's opinion \" + str(old_opinion_min) + \" changed to \"+ str(min_opinion))\n",
    "        # print(\"Network reaches equilibrium Polarization: \" + str(min_pol))\n",
    "\n",
    "\n",
    "    return(v1, v2, min_opinion, min_pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine which agent maximizer should select to maximizer the equilibrium polarization\n",
    "def choose_min_vertex(s, n):\n",
    "   # max_por = obj_polarization(A, L, op, n)  # use \"innate\"(after min action) polarization as a comparable standard to find max_por\n",
    "    min_por = 10000\n",
    "    C1 = list(range(n))    # for all agent \n",
    "    for v1 in C1:         \n",
    "            # print('Minimizer start from agent'+str(v1))\n",
    "            (min_opinion, por, max_action) = get_min_opinion(s, n, v1)\n",
    " \n",
    "            if por < min_por: # if the polarization of most recent action > maximum polarization of previous actions\n",
    "                min_por = por\n",
    "                champion = (v1, min_opinion,min_por, max_action)   # save the this action as champion    \n",
    "    # print(\"Min champion\", champion)\n",
    "    return (champion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determines if value of opinion at v should be set to 0 or 1 to maximize equilibrium polarization \n",
    "def get_min_opinion(s, n, v1):\n",
    "    \n",
    "    por_arr = np.zeros(11)  # create a two_element array to store polarization value of each option\n",
    "    min_opi_option = np.arange(0, 1.01, 0.01) #Min has two options to change agent v2's opinion\n",
    "    #min_opi_option = np.arange(0, 1.01, 0.1)\n",
    "    #[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] \n",
    "    \n",
    "    min_pol = 1000\n",
    "    # objective if set opinion to 0, 1.0\n",
    "    j = 0\n",
    "    max_champion = (None, None)\n",
    "    for min_opinion in min_opi_option:\n",
    "        #print(v1,min_opinion)\n",
    "        (v2,max_opinion, pol) = minmax_polar(s,v1,min_opinion)\n",
    "        por_arr[j] = pol\n",
    "        #print(\"max_pol: \", max_pol)\n",
    "        j = j + 1   # index increase 1, put the polarization in array\n",
    "        \n",
    "        if  pol < min_pol:\n",
    "            min_pol = pol\n",
    "            max_champion = (v2,max_opinion)\n",
    "    #print(\"Max_champion:\",max_champion)   \n",
    "    #print(\"Min choice:\", por_arr)\n",
    "    minmize_op = int(np.argmin(por_arr))/10  # the index of maximum polarization = max_opinion --[0,1]\n",
    "    min_por = np.min(por_arr)        # find the maximum polarization in the record\n",
    "    \n",
    "    return (minmize_op, min_por, max_champion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_polar(s, v1, min_opinion):\n",
    "    op = copy.copy(s)\n",
    "    op[v1] = min_opinion  \n",
    "    (v2,max_opinion, max_pol) = maximizer_play(op,n,v1)\n",
    "    \n",
    "    return (v2,max_opinion, max_pol)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### minimizer first-time play, greedy algorithm\n",
    "def maximizer_play(op,n,min_touched): \n",
    "    \n",
    "    op1 = copy.copy(op)\n",
    "    max_champion = choose_max_vertex(op1, n, min_touched) \n",
    "    (v2, max_opinion, max_pol) = max_champion\n",
    "    \n",
    "    if v2 == None:\n",
    "        print('Minimizer fail')\n",
    "\n",
    "    return (v2,max_opinion, max_pol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimizer Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimizer search: Go through each agent \n",
    "\n",
    "def choose_max_vertex(op, n, min_touched):\n",
    "    # current opinion array that changed by maximizer, \"innate\" opinion that min start with\n",
    "\n",
    "    #champion = (None, None, 0, None)  # assume the best action is champion\n",
    "    max_por = 0\n",
    "    all = list(range(n))    # for all agent \n",
    "    C1 = [x for x in all if x != min_touched]  # for the vertice that Maximizer has not touched\n",
    "    \n",
    "    for v2 in C1:   \n",
    "        #print('Max start with agent '+ str(v2) )\n",
    "        (changed_opinion, por) = get_max_opinion(op,n,v2)   # find the best new_op option           \n",
    "\n",
    "        if por > max_por:  # if the recent polarization is smaller than the minimum polarization in the history\n",
    "            max_por = por                         # update the recent option as champion\n",
    "            champion = (v2, changed_opinion, max_por)  \n",
    "    # print(\"Max champion\", champion)\n",
    "    return (champion)  # find the best minimizer's action after going through every new_op option of every agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determines if value of opinion at v should be set to 0 or 1 to maximize equilibrium polarization \n",
    "def get_max_opinion(op, n, v2):\n",
    "    \n",
    "    por_arr = np.zeros(2)  # create a two_element array to store polarization value of each option\n",
    "    max_opi_option = [0, 1.0]   # Maximizer has two options to change agent v1's opinion\n",
    "    op1 = copy.copy(op)\n",
    "    \n",
    "    # objective if set opinion to 0, 1.0\n",
    "    j = 0\n",
    "    for max_opinion in max_opi_option:\n",
    "        op1[v2] = max_opinion\n",
    "#         print(\"max change opinion:\",op1)\n",
    "        max_pol = obj_polarization(A, op1, n)\n",
    "        por_arr[j] = max_pol\n",
    "        j = j + 1   # index increase 1, put the polarization in array\n",
    "\n",
    "    maxmize_op = np.argmax(por_arr)  # the index of maximum polarization = max_opinion --[0,1]\n",
    "    max_por = np.max(por_arr)        # find the maximum polarization in the record\n",
    "    \n",
    "    return (maxmize_op, max_por)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "125d6e56934ce2649cb3782cc815dc11821615614828859fcaee5b1c4840aa60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
