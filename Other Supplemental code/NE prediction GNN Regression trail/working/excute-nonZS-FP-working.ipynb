{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### #03/22/2023 Xilin found out it used the last min_action no matter what - revised it\n",
    "import scipy\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "import time\n",
    "import random\n",
    "from scipy.stats import beta\n",
    "import pandas as pd\n",
    "import copy\n",
    "%matplotlib inline\n",
    "%run Helpers.ipynb\n",
    "#%run pure_strategy_selection.ipynb  #include simple selection algorithm\n",
    "import scipy.io\n",
    "import collections\n",
    "import sys\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathmatic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centers the opinion vector around 0\\n\",\n",
    "def mean_center(op, n):\n",
    "    ones = np.ones((n, 1))\n",
    "    x = op - (np.dot(np.transpose(op),ones)/n) * ones\n",
    "    return x\n",
    "    \n",
    "# compute number of edges, m\\n\n",
    "def num_edges(L, n):\n",
    "    m = 0\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i > j and L[i,j] < 0:\n",
    "                m += 1            \n",
    "    return m\n",
    "\n",
    "# maximizing polarization only: \\\\bar{z}^T \\\\bar{z}   \n",
    "def obj_polarization(A,op, n):\n",
    "    op_mean = mean_center(op, n)\n",
    "    z_mean = np.dot(A, op_mean) \n",
    "    return np.dot(np.transpose(z_mean), z_mean)[0,0] \n",
    "\n",
    "def obj_polarization_1(A, L, op, n):\n",
    "    z = np.dot(A, op) \n",
    "    z_mean = mean_center(z, n)\n",
    "    return np.dot(np.transpose(z_mean), z_mean)[0,0] \n",
    "\n",
    "# Calculate innate polarization\n",
    "def obj_innate_polarization(s, n):  \n",
    "#     np.set_printoptions(precision=5)\n",
    "    op_mean = mean_center(s, n)\n",
    "    return np.dot(np.transpose(op_mean), op_mean)[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the network\n",
    "np.set_printoptions(precision=3)\n",
    "n = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Network\n",
    "### 1. Make Random Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_erdos_renyi_network(n, p, u, v):\n",
    "    A = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "#         for j in range(i+1,n):\n",
    "#             r = np.random.rand()\n",
    "#             if r < p:\n",
    "            if j<i:\n",
    "                A[i,j] = A[j,i] = 1\n",
    "#             if i==u or i==v:\n",
    "#                 A[i,j] = A[j,i] = 1\n",
    "    return A\n",
    "\n",
    "\n",
    "def make_innat_opinions(n): # Make opinion for agents only - no info source is involved\n",
    "    \n",
    "    # Make list of ind innate opinion to define info source opinion\n",
    "    innat_s = np.random.uniform(low=0, high=1, size=int(n))   #individual's innate opinion \n",
    "\n",
    "    s = np.zeros((n, 1))\n",
    "    \n",
    "    idx1 = 0\n",
    "    for i in range(len(s)):\n",
    "        s[i] = innat_s[idx1]  #set innate opinion for ind.\n",
    "        idx1 += 1\n",
    "  \n",
    "    return s\n",
    "\n",
    "def make_random_network(n):\n",
    "    # Create empty graph\n",
    "    nxG = nx.Graph()\n",
    "    # Add nodes to graph\n",
    "    nxG.add_nodes_from(range(n))\n",
    "    # Add edges based on node index\n",
    "    for i in range(n):\n",
    "        for j in range(i):\n",
    "            p = (n-i)/(n-j) # Probability of edge existing\n",
    "            if np.random.random() < p:\n",
    "                nxG.add_edge(i, j)\n",
    "\n",
    "    # Draw graph\n",
    "#     nx.draw(nxG, with_labels=True)\n",
    "#     plt.show()\n",
    "    G = nx.adjacency_matrix(nxG).todense()\n",
    "    \n",
    "    return G\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(s,G):\n",
    "    # what the twitter graph looks like \n",
    "    s_use = s.flatten()   # Convert array to a list for later operation\n",
    "    s_use = s_use.tolist()\n",
    "    new_s = [i * 30 for i in s_use]\n",
    "    df = pd.DataFrame(new_s, columns=['Opinion']) #create a datafram with index at column 1, opinion at column 2\n",
    "\n",
    "    nxG = nx.from_numpy_matrix(G)   \n",
    "   \n",
    "    #plt.figure(figsize=(10, 10))\n",
    "        ##### Calculate Key Values  ######\n",
    "    L = scipy.sparse.csgraph.laplacian(G, normed=False)  # Return the Laplacian matrix\n",
    "    A = np.linalg.inv(np.identity(n) + L)  # A = (I + L)^(-1)\\n  Stanford paper theory\n",
    "    columnsum_ij = np.sum(A, axis=0)\n",
    "    m = num_edges(L, n)                    # call the function to calculate the number of edges\n",
    "\n",
    "#     print(n)\n",
    "    # what the twitter graph looks like \n",
    "\n",
    "    def node_edge(G, n):\n",
    "        edges =[]\n",
    "        for v in range(n):\n",
    "            a = np.array(np.nonzero(G[v])[0])\n",
    "            edge = len(a)\n",
    "    #         print(edge)\n",
    "            edges.append(edge)\n",
    "\n",
    "        return edges\n",
    "\n",
    "    node_edges = node_edge(G, n)\n",
    "    # print(node_edges)\n",
    "\n",
    "    node_sizes =[]\n",
    "    for i in node_edges:\n",
    "        node_size = 1/i*8000\n",
    "        node_sizes.append(node_size)\n",
    "        \n",
    "#     plt.figure(figsize=(20, 20))\n",
    "\n",
    "    # Fix seed - fix network shape\n",
    "    my_pos = nx.spring_layout(nxG, seed = 2)\n",
    "    nx.draw(nxG, pos= my_pos, with_labels= True, node_color=df['Opinion'].astype(int),cmap=plt.cm.Blues, node_size= node_sizes, edge_color='black', width=0.8, font_color='black',font_size=26, font_weight='bold', alpha=0.8)\n",
    "    #nx.draw(nxG, pos = my_pos, with_labels=False, node_color=color_map, node_size= node_sizes, edge_color='grey', width=0.5, font_color='white',font_size=9, font_weight='bold')\n",
    "    sm = plt.cm.ScalarMappable(cmap=plt.cm.Blues, norm=plt.Normalize(vmin = 0, vmax=1))\n",
    "    cbar = plt.colorbar(sm, shrink = 0.5)\n",
    "    tick_font_size = 24\n",
    "    cbar.ax.tick_params(labelsize=tick_font_size)\n",
    "   # plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "# if we want to customize the color bar range to min/max s\n",
    "# vmin = min(s)\n",
    "# vmax = max(s)\n",
    "# sm = plt.cm.ScalarMappable(cmap=plt.cm.Blues, norm=plt.Normalize(vmin = vmin, vmax=vmax))\n",
    "# sm._A = []\n",
    "# plt.colorbar(sm,shrink=0.5)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min [245, ] [284, ]       Max [50, ] [481, ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Equilibrium & Polarization  - based on derivation\n",
    "$$P(z) = z ^T * z $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# op = s\n",
    "# y = mean_center(s,n)\n",
    "# # print(y)\n",
    "# innat_pol = np.dot(np.transpose(y), y)[0,0] \n",
    "# print('Innate_polarization:')\n",
    "# print(innat_pol)\n",
    "\n",
    "# # Test equilibrium polarization\n",
    "# equ_pol = obj_polarization(A, s, n)\n",
    "# print('Equi_polarization:')\n",
    "# print(equ_pol)\n",
    "\n",
    "# di = equ_pol-innat_pol\n",
    "# print(\"Difference:\")\n",
    "# print(di)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing players' behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row are Column are depended on min and max's choice: agent v and opinion \n",
    "def row_index(v2, min_opinion):\n",
    "    row = 11*v2 + min_opinion*10 \n",
    "    return int(row)\n",
    "def column_index(v1,max_opinion):\n",
    "    column = 2*v1 + max_opinion\n",
    "    return int(column)  #the python dataframe index\n",
    "\n",
    "def random_play(s,n):  # player randomly choose an agent and randomly change the agent\n",
    "    \n",
    "    op = copy.copy(s)\n",
    "  \n",
    "    v = random.randint(0,n-1)  # randomly select an agent index\n",
    "    new_op = random.randint(0, 1)  # randomly select an opininon between 0 and 1)\n",
    "    \n",
    "    # Store old opinion\n",
    "    old_opinion = op[v,0]\n",
    "    \n",
    "    #update the opinion\n",
    "    op[v,0] = new_op \n",
    "    por = obj_innate_polarization(op, n)\n",
    "    print(\"    \"+\"Agent\" + str(v) +\" 's opinion \" + str(old_opinion) + \" changed to \"+ str(new_op))\n",
    "    \n",
    "    #restore op op array to innate opinion\n",
    "    op[v] = old_opinion\n",
    "#     print(\"Network reaches equilibrium Polarization: \" + str(por))\n",
    "    return (v, new_op, por)\n",
    "\n",
    "def random_play1(s,n):  # player randomly choose an agent and randomly change the agent\n",
    "    \n",
    "    op = copy.copy(s)  \n",
    "    v = random.randint(0,n-1)  # randomly select an agent index\n",
    "    new_op = random.uniform(0, 1)  # randomly select an opininon between 0 and 1\n",
    "    \n",
    "    # Store old opinion\n",
    "    old_opinion = op[v,0]\n",
    "    \n",
    "    #update the opinion\n",
    "    op[v,0] = new_op \n",
    "    print(\"    \"+\"Agent\" + str(v) +\" 's opinion \" + str(old_opinion) + \" changed to \"+ str(new_op))\n",
    "#     por = obj_polarization(A, op, n)\n",
    "    por = obj_innate_polarization(op, n)\n",
    "    #restore op op array to innate opinion\n",
    "    op[v] = old_opinion\n",
    "#     print(\"Network reaches equilibrium Polarization: \" + str(por))\n",
    "    return (v, new_op, por)\n",
    "\n",
    "def make_payoff_row(op1,v2,G):\n",
    "    payoff_row = np.zeros(2*n)\n",
    "    for column in range(2*n):\n",
    "#         print(column)\n",
    "        v1 = int(column/2)  #i.e., column 11 is agent 5, opinion 1\n",
    "        max_opinion = column%2\n",
    "        # update the maximizer's change to the opinion array that has changed by minimizer(op1)\n",
    "        op2 = copy.copy(op1)\n",
    "#         temp = op1[v1]\n",
    "        op2[v1,0] = max_opinion\n",
    "        # calculate the polarization with both max and min's action\n",
    "        L = scipy.sparse.csgraph.laplacian(G, normed=False)  # Return the Laplacian matrix\n",
    "        A = np.linalg.inv(np.identity(n) + L)  # A = (I + L)^(-1)\\n  Stanford paper theory\n",
    "        payoff_row[column] = obj_polarization(A, op2, n)\n",
    "\n",
    "    # when v1 == v2, the polarization should be negative for max, infinet for min. \n",
    "    # Replace the the column_index of agent v2 with 0 for max\n",
    "    j_1 = 2*v2 + 0\n",
    "    j_2 = 2*v2 + 1\n",
    "    payoff_row[j_1] = -100\n",
    "    payoff_row[j_2] = -100\n",
    "    \n",
    "    return payoff_row\n",
    "\n",
    "\n",
    "# Calculate polarization of minimizer's Mixed Strategy\n",
    "def mixed_min_polarization(s,v2,weight_op,fla_max_fre, G):\n",
    "\n",
    "    op1 =  copy.copy(s) # make a copy of the innate opinion array \n",
    "    op1[v2,0] = weight_op # then only updated by minimizer's current change\n",
    "    # calculate the polarization with both min(did here) and max's action(in make_payoff_row)\n",
    "    payoff_row = make_payoff_row(op1,v2,G)  # the vector list out 2*n payoffs after min's action combine with 2*n possible max's actions\n",
    "    #print(payoff_row)\n",
    "\n",
    "    # Replace the the column_index of agent v2 with 100 for min\n",
    "    j_1 = 2*v2 + 0\n",
    "    j_2 = 2*v2 + 1\n",
    "    payoff_row[j_1] = 100\n",
    "    payoff_row[j_2] = 100\n",
    "\n",
    "    #calculate fictitious payoff - equi_min  \n",
    "    payoff_cal = payoff_row * fla_max_fre # fla_max_fre recorded the frequency of each maximizer's action, frequency sum = 1   \n",
    "    mixed_pol = np.sum(payoff_cal) # add up all, calculate average/expected payoff\n",
    "    # Replace the the column_index of agent v2 with 100 for min\n",
    "\n",
    "    payoff_row[j_1] = -100\n",
    "    payoff_row[j_2] = -100\n",
    "\n",
    "    return (mixed_pol,payoff_row)\n",
    "\n",
    "def derivate_s(op,n,v2,G):\n",
    "               #op - opinion array that updated by maximizer\n",
    "    c = [1/n] * n\n",
    "#     print(c)\n",
    "    sum_term = 0\n",
    "    j = 0\n",
    "        ##### Calculate Key Values  ######\n",
    "    L = scipy.sparse.csgraph.laplacian(G, normed=False)  # Return the Laplacian matrix\n",
    "    A = np.linalg.inv(np.identity(n) + L)  # A = (I + L)^(-1)\\n  Stanford paper theory\n",
    "    \n",
    "    sum_term = np.dot(np.dot((A-c),(A[v2]-c)),op)  # sum up all terms\n",
    "    \n",
    "    term_out = op[v2]*np.dot((A[v2]-c),(A[v2]-c)) # exclude the term that j = v2\n",
    "    sum_s = sum_term - term_out    # numerator\n",
    "    \n",
    "    s_star = -sum_s/np.dot((A[v2]-c),(A[v2]-c))\n",
    "    s_star = s_star[0] #take value out of array\n",
    "    min_opinion =min(max(0,s_star),1)\n",
    "    return min_opinion\n",
    "    \n",
    "    \n",
    "def min_mixed_opinion_1(s, n, v2, fla_max_fre,A):\n",
    "    \n",
    "    weight_op = 0\n",
    "    # loop for each max_action(in total 2*n) \n",
    "    for column in range(2*n):\n",
    "\n",
    "        if fla_max_fre[column] !=0:\n",
    "            v1 = int(column/2)  #i.e., column 11 is agent 5, opinion 1\n",
    "            max_opinion = column%2\n",
    "            op = copy.copy(s)\n",
    "            op[v1] = max_opinion\n",
    "            min_opinion = derivate_s(op, n, v2,G)# find min_s_star for each max_action\n",
    "            op1 = copy.copy(op)\n",
    "            op1[v2] = min_opinion   #after max action, update min action on opinion array\n",
    "            min_por = obj_polarization(A, op1, n)\n",
    "            t = 0  \n",
    "            weight_op = weight_op + fla_max_fre[column]*min_opinion # sum up p_i*s_i\n",
    "\n",
    "  \n",
    "    (mixed_por, payoff_row) = mixed_min_polarization(s, v2, weight_op,fla_max_fre, G)\n",
    "#     print('Weighted polarization')\n",
    "#     print(mixed_por)\n",
    "\n",
    "    return(weight_op,payoff_row,mixed_por)  \n",
    "\n",
    "\n",
    "def mixed_choose_min_vertex(s, n, v1, max_opinion, max_touched, fla_max_fre,A):\n",
    "    # current polarization that changed by maximizer, \"innate\" objective that min start with\n",
    "    op = copy.copy(s)\n",
    "    op[v1,0] = max_opinion\n",
    "#     print('Check if op has been updated by Maximizer')\n",
    "#     print(op)\n",
    "    min_por = 1000 #min_por- set a standard to compare with pol after min's action\n",
    "    maxup_por = obj_polarization(A, op, n)# store innate max updated polarization\n",
    "    champion = (None, None, 0, None)  # assume the best action is champion\n",
    "\n",
    "    all = list(range(n))    # for all agent \n",
    "    C1 = [x for x in all if x not in max_touched]  # for the vertice that Maximizer has not touched\n",
    "    \n",
    "    for v2 in C1:   \n",
    "#         print('_________________________________')\n",
    "#         print('Min start with agent '+ str(v2) )\n",
    "        (changed_opinion, payoff_row, por) =  min_mixed_opinion_1(s, n, v2, fla_max_fre,A) # find the best new_op option           \n",
    "#         print('changed opinion, por, Maxup_por')\n",
    "#         print(changed_opinion, por, maxup_por)\n",
    "        if por < min_por:  # if the recent polarization is smaller than the minimum polarization in the history\n",
    "            min_por = por # update the recent option as champion\n",
    "            champion = (v2, changed_opinion, payoff_row, min_por)  \n",
    "\n",
    "    return (champion)  # find the best minimizer's action after going through every new_op option of every agent\n",
    "\n",
    "####Op has been updated by maximizer, fla_max_fre includes max's hisotry, so minimizer react to the innate op after that\n",
    "def mixed_min_play(s,v1,max_opinion,n, max_touched,fla_max_fre,A): \n",
    "\n",
    "    print('_______________________')\n",
    "    print('Minimizer Play')\n",
    "    \n",
    "    min_champion = mixed_choose_min_vertex(s, n, v1, max_opinion, max_touched, fla_max_fre,A)\n",
    "    (v2, min_opinion, payoff_row, min_pol) = min_champion\n",
    "    \n",
    "    if v2 == None:    # if minimizer cannot find a action to minimize polarization after maximizer's action\n",
    "        print('Minimizer fail')\n",
    "\n",
    "    else:\n",
    "        print(\"                                \")\n",
    "        print(\"Minimizer finds its target agent:\")\n",
    "\n",
    "        # Store innate_op of the min_selected vertex\n",
    "        op = copy.copy(s)\n",
    "        old_opinion_min = op[v2,0]\n",
    "\n",
    "        print(\"    \"+\"Agent\" + str(v2) +\" 's opinion \" + str(old_opinion_min) + \" changed to \"+ str(min_opinion))\n",
    "        print('fla_max_fre')\n",
    "        print(np.nonzero(fla_max_fre))\n",
    "        print(fla_max_fre [np.nonzero(fla_max_fre)])\n",
    "    return (v2, payoff_row, min_opinion, min_pol)                 \n",
    "\n",
    "\n",
    "####Op has been updated by minimizer, fla_min_fre includes min's hisotry, so maxmizer react to the innate op after that\n",
    "def mixed_max_polarization(payoff_matrix,v1,max_opinion,fla_min_fre):\n",
    "\n",
    "    # create payoff matrix for maxmizer\n",
    "    column = int(column_index(v1,max_opinion))\n",
    "    payoff_vector = payoff_matrix[:,column]\n",
    "    #calculate fictitious payoff - equi_max   \n",
    "    payoff_cal = payoff_vector * fla_min_fre #payoff * frequency\n",
    "    mixed_pol = np.sum(payoff_cal) # add up\n",
    "    return mixed_pol\n",
    "\n",
    "\n",
    "# determines if value of opinion at v should be set to 0 or 1 to maximize equilibrium polarization \n",
    "def max_mixed_opinion(payoff_matrix, n, v1, fla_min_fre):\n",
    "    \n",
    "    por_arr = np.zeros(2)  # create a two_element array to store polarization value of each option\n",
    "    max_opi_option = [0, 1.0]   # Maximizer has two options to change agent v1's opinion\n",
    "    \n",
    "    # objective if set opinion to 0, 1.0\n",
    "    j = 0\n",
    "    for new_op in max_opi_option:\n",
    "#         print('change op to '+ str(i/10))\n",
    "        max_opinion = new_op\n",
    "        por_arr[j] = mixed_max_polarization(payoff_matrix,v1,max_opinion, fla_min_fre)\n",
    "        j = j + 1   # index increase 1, put the polarization in array\n",
    "    \n",
    "    maxmize_op = np.argmax(por_arr)  # the index of maximum polarization = max_opinion --[0,1]\n",
    "    max_por = np.max(por_arr)        # find the maximum polarization in the record\n",
    "    return (maxmize_op, max_por)\n",
    "\n",
    "# determine which agent maximizer should select to maximizer the equilibrium polarization\n",
    "def mixed_choose_max_vertex(payoff_matrix,op, n, min_touched, fla_min_fre, A):\n",
    "    \n",
    "    max_por = obj_polarization(A, op, n)  # use \"innate\"(after min action) polarization as a comparable standard to find max_por\n",
    "    minup_por = max_por # store innate min_update polarization\n",
    "    champion = (None, None, max_por)  # assume champion is the best action\n",
    "\n",
    "    all = list(range(n))    # for all agent \n",
    "    C1 = [x for x in all if x not in min_touched]  # for the vertice that Minimizer has not touched\n",
    "    for v1 in C1:  \n",
    "            (changed_opinion, por) = max_mixed_opinion(payoff_matrix, n, v1, fla_min_fre)\n",
    "            if por > max_por: # if the polarization of most recent action > maximum polarization of previous actions\n",
    "                max_por = por\n",
    "                champion = (v1, changed_opinion,max_por)   # save the this action as champion    \n",
    "    return (champion)\n",
    "\n",
    "def mixed_max_play(payoff_matrix,s,v2,min_opinion,n,min_touched,fla_min_fre, A): \n",
    "    op = copy.copy(s)   # op is a copy of innate opinion\n",
    "    \n",
    "    #update innat opinion \n",
    "    op[v2,0] = min_opinion  # Op has been updated by minimizer, so maximizer react to the innate op after that\n",
    "    max_champion = mixed_choose_max_vertex(payoff_matrix,op, n, min_touched, fla_min_fre, A) # The best choice among all opinions and vertexs\n",
    "    (v1, max_opinion, max_pol) = max_champion\n",
    "\n",
    "    if v1 == None:\n",
    "        print('Maximizer fail')\n",
    "    else:\n",
    "        print(\"                                \")\n",
    "        print(\"Maximizer finds its target agent:\")\n",
    "        #Store innate_op of the max_selected vertex\n",
    "        old_opinion_max = op[v1, 0]\n",
    "        \n",
    "        ## check if agent's opinionis is changed or not\n",
    "        print(\"    \"+\"Agent\" + str(v1) +\" 's opinion \" + str(old_opinion_max) + \" changed to \"+ str(max_opinion))\n",
    "\n",
    "    return(v1, max_opinion, max_pol)\n",
    "\n",
    "def push(obj, element):\n",
    "    if len(obj) >= memory:\n",
    "        obj.pop(0)\n",
    "        print('pop')\n",
    "    obj.append(element)\n",
    "    return obj\n",
    "\n",
    "def all_fre_limited_touch(s, n, G, Game_rounds, memory):\n",
    "    # Preparation for the game\n",
    "    op = copy.copy(s)\n",
    "    payoff_matrix = np.empty((0, 2*n), float)\n",
    "    max_history = np.zeros([n, 2])  # n*2 matrix, agent i & opinion options\n",
    "    min_history = []  # append a list of (agent i, min_opinion), min_opinion can be any value\n",
    "#     print(type(min_history))\n",
    "\n",
    "    max_history_last_100 = np.zeros([n, 2]) \n",
    "    min_history_last_100= []\n",
    "\n",
    "    max_touched = []\n",
    "    min_touched = []\n",
    "    min_touched_all = []\n",
    "    min_touched_last_100 =[]\n",
    "    print('min_touched')\n",
    "    print(min_touched)\n",
    "    \n",
    "    \n",
    "    L = scipy.sparse.csgraph.laplacian(G, normed=False)  # Return the Laplacian matrix\n",
    "    A = np.linalg.inv(np.identity(n) + L)  # A = (I + L)^(-1)\\n  Stanford paper theory\n",
    "\n",
    "    # Game start from maximizer random play\n",
    "    print('Maximizer first selection')\n",
    "    (v1, max_opinion, max_pol) = random_play(op,n)   # Maximizer does random action \n",
    "    #(v1, max_opinion, max_pol) = maximizer_fir_play(s,n,min_touched)\n",
    "    First_max = (v1, max_opinion, max_pol) \n",
    "#     (v1, max_opinion, max_pol) = maximizer_fir_play(s,n,max_touched)\n",
    "\n",
    "    # Maximizer start with greedy play\n",
    "    # (v1, max_opinion, max_pol) = maximizer_fir_play(s,n,min_touched)   # Maximizer choose action greedily\n",
    "    max_touched.append(v1)    # save Maximizer's action history\n",
    "\n",
    "    # store maximizer play history, using agent(row) and changed opinion(column) as indicator to locate history\n",
    "    max_history[v1,int(max_opinion)] = max_history[v1,int(max_opinion)] +1\n",
    "\n",
    "    print('history at spot')\n",
    "    print(max_history[v1,int(max_opinion)])\n",
    "\n",
    "    max_frequency = max_history/1  # its frequency, only played  1 time so far, divided by 1 \n",
    "    # print('fre_max at spot')\n",
    "    # print(max_frequency[v1,int(max_opinion)])\n",
    "\n",
    "    fla_max_fre = max_frequency.flatten()   # flatten the n*2 matrix to a 2n*1 matrix\n",
    "                                            # so we can multiply the freuency (2n*1)with payoff array (1*2n) \n",
    "                                            # to get average payoff of fictitious play\n",
    "    print('fre_max at spot')\n",
    "    print(fla_max_fre)\n",
    "\n",
    "    column = int(column_index(v1,max_opinion))    # the frequency of maximizer's most recent action (v1,max_opinion)\n",
    "\n",
    "    print(fla_max_fre[column])\n",
    "\n",
    "    # if game start from minimizer random play - make sure two random play are not same agent!!!\n",
    "    print('Minimizer first selection')\n",
    "    (v2, min_opinion, min_pol) = random_play(op,n) \n",
    "    #(v2, min_opinion, min_pol) = minimizer_fir_play(s,n,min_touched)\n",
    "    \n",
    "    #(v2, min_opinion, min_pol) = (29, 1, 0.5933309600094931)\n",
    "    First_min = (v2, min_opinion, min_pol)\n",
    "\n",
    "    if v1==v2:   # if Max and Min randomly selected the same agent, then we need to restart - cannot choose same agent\n",
    "        sys.exit()\n",
    "\n",
    "    # Minimizer start with greedy play\n",
    "    # (v2, min_opinion, min_pol) = minimizer_fir_play(s,n,max_touched)\n",
    "\n",
    "    min_touched.append(v2)\n",
    "   \n",
    "\n",
    "    # store minimizer play history\n",
    "    min_history.append((v2,min_opinion))\n",
    "    print('min_history')\n",
    "    print(min_history)\n",
    "\n",
    "\n",
    "    counter=collections.Counter(min_history)  #return a dictionary include {'min_option': count of this choice}\n",
    "    print(counter)\n",
    "    fla_min_fre = np.array(list(counter.values()))/1 #return only frequency of all min options in order\n",
    "\n",
    "    (a,payoff_row) = mixed_min_polarization(s,v2,min_opinion,fla_max_fre,G)\n",
    "    payoff_matrix = np.vstack([payoff_matrix, payoff_row])\n",
    "\n",
    "    print('fla_min_fre at the spot')\n",
    "    min_counter = dict(counter)\n",
    "    print(min_counter) \n",
    "    print(min_counter[(v2,min_opinion)]) \n",
    "    equi_min = min_pol\n",
    "    equi_max = max_pol\n",
    "\n",
    "\n",
    "    Flag = 0\n",
    "\n",
    "    i = 0\n",
    "    while Flag == 0: \n",
    "        i = i + 1\n",
    "        print(\"Game \" + str(i))\n",
    "        print(\"_____________________\")\n",
    "\n",
    "    #     if max_pol == min_pol:\n",
    "        if i == Game_rounds:            # i == # of iterations you want to run + 2\n",
    "                                # because Game 101 is skipped for collecting data, to get 200 game result, we need to run 201 iteration\n",
    "            print('min_recent_'+str(memory)+'_touched')# then stop at Game 202\n",
    "            print(min_touched)\n",
    "            print('max_recent_'+str(memory)+'_touched')\n",
    "            print(max_touched)\n",
    "            print('Min last 100 action')\n",
    "            print(min_touched_last_100)\n",
    "\n",
    "            break\n",
    "\n",
    "        elif equi_min == equi_max:\n",
    "            print(\"Reached Nash Equilibrium at game\"+ str(i) + \"and Equi_Por = \" + str(equi_min))\n",
    "            print('max_distribution')\n",
    "            print(max_frequency)\n",
    "            print('min_distribution')\n",
    "            print(fla_min_fre)\n",
    "            Flag = 1\n",
    "            break\n",
    "        ############################## maximizer play  \n",
    "        else:\n",
    "            if i == Game_rounds-100:    #if Game_round = 200, after 100 iteration, Game 101 print previous historical result\n",
    "    # Remove max frequncy less than 0.1--\n",
    "                max_history_last_100 = np.zeros([n, 2]) \n",
    "                min_history_last_100 = [] \n",
    "                min_touched_last_100 =[]\n",
    "\n",
    "            (v1, max_opinion, equi_max) = mixed_max_play(payoff_matrix,s,v2,min_opinion,n,min_touched,fla_min_fre, A)\n",
    "            max_touched = push(max_touched, v1)\n",
    "\n",
    "            max_history[v1,int(max_opinion)] = max_history[v1,int(max_opinion)] +1\n",
    "\n",
    "            max_history_last_100[v1,int(max_opinion)] = max_history_last_100[v1,int(max_opinion)] +1\n",
    "    #         print('max_history')\n",
    "    #         print(max_history)\n",
    "    #________________________________________________________________\n",
    "            max_frequency = max_history/(i+1)  # its frequency \n",
    "    #         print('max_distribution')\n",
    "    #         print(max_frequency)\n",
    "        #     print(i+1) \n",
    "            fla_max_fre = max_frequency.flatten() #flaten max_frequency to calculate average payoff\n",
    "#             print('fla_max_fre')\n",
    "#             print(fla_max_fre)\n",
    "            print('fre_max at spot')\n",
    "            print(fla_max_fre[column])\n",
    "            # create payoff matrix for maxmizer\n",
    "            row = int(row_index(v2, min_opinion))\n",
    "            column = int(column_index(v1,max_opinion))\n",
    "\n",
    "    ############################### minimizer play\n",
    "            (v2, payoff_row, min_opinion, equi_min) = mixed_min_play(s,v1,max_opinion,n, max_touched,fla_max_fre,A)\n",
    "            min_touched = push(min_touched, v2)\n",
    "            min_touched_all.append(v2) \n",
    "            min_touched_last_100.append(v2)\n",
    "\n",
    "            if (v2,min_opinion) in counter.keys():\n",
    "                payoff_matrix = payoff_matrix # if this min_option is in min_history, no need to update paryoff matrix, only update frequency\n",
    "                print(\"Same history\")\n",
    "                print((str(v2),str(min_opinion)))\n",
    "            else:\n",
    "                payoff_matrix = np.vstack([payoff_matrix, payoff_row]) # if this is a new option, append to previous matrix\n",
    "            min_history.append((v2,min_opinion))\n",
    "            min_history_last_100.append((v2,min_opinion))\n",
    "\n",
    "            counter=collections.Counter(min_history)  #return a dictionary include {'min_option': count of this choice}\n",
    "\n",
    "            fla_min_fre = np.array(list(counter.values()))/(i+1) #return only frequency of all min options in order\n",
    "\n",
    "            # create payoff matrix for minimizer\n",
    "            row = row_index(v2, min_opinion)\n",
    "            column = column_index(v1,max_opinion)\n",
    "            print(\"Not Reached Nash Equilibrium at Equi_Min = \" + str(equi_min) + \" and Equi_Max = \"+ str(equi_max)) \n",
    "    return (First_max, First_min, max_touched, min_touched, payoff_matrix, min_history, fla_min_fre, min_history_last_100, min_touched_last_100, min_touched_all, max_history, fla_max_fre, max_history_last_100)\n",
    "\n",
    "\n",
    "def result(max_history_last_100, min_touched_last_100):\n",
    "    # MAXimizer's distribution of LAST 100 iteration \n",
    "    print('Max_distribution_last_100')  \n",
    "    max_l100_fre = max_history_last_100/100\n",
    "    print(max_l100_fre [np.nonzero(max_l100_fre)])\n",
    "    print(np.nonzero(max_l100_fre)[0])\n",
    "    v1 = np.nonzero(max_l100_fre)[0]\n",
    "\n",
    "    # MINimizer's Strategy in the last 100 round\n",
    "    print('Min_distribution_last_100')\n",
    "    counter_h=collections.Counter(min_touched_last_100)  #return a dictionary include {'min_option': count of this choice}\n",
    "    print(counter_h.keys())\n",
    "    v2 = set(counter_h.keys())\n",
    "    \n",
    "    return(v1,v2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimizer Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (v1,v2,max_pol) = MaxMin_play(s,n)\n",
    "def run(n):\n",
    "    s = make_innat_opinions(n)\n",
    "    G = make_random_network(n)\n",
    "    (a,b,c,d)= net_rank(s,G)\n",
    "    #   visualize(s,G)\n",
    "    Game_rounds =100 # Rounds + 1- use for printing data\n",
    "    memory = 50\n",
    "    (First_max, First_min, max_touched, min_touched, payoff_matrix, min_history, fla_min_fre, min_history_last_100, min_touched_last_100, min_touched_all, max_history, fla_max_fre, max_history_last_100) = all_fre_limited_touch(s, n, G, Game_rounds, memory)\n",
    "    (v1,v2) = result(max_history_last_100, min_touched_last_100)\n",
    "    return (v1,v2,a,b,c,d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_rank(s,G):\n",
    "    #print(\"___________________Max Analyze__________________________________________\")\n",
    "    nxG = nx.from_numpy_matrix(G) \n",
    "    # G = nx.karate_club_graph()\n",
    "    #print(\"_______________Degree Centrality_____________________________\")  \n",
    "    deg_centrality = nx.degree_centrality(nxG)\n",
    "    sortedDict = sorted(deg_centrality.items(), key=lambda x:x[1])\n",
    "    converted_dict = dict(sortedDict)\n",
    "    # print(converted_dict)\n",
    "    #print(\"                           \")\n",
    "    #print(\"_______________Closeness Rank_____________________________\")\n",
    "    close_centrality = nx.closeness_centrality(nxG)\n",
    "    sortedDict1 = sorted(close_centrality.items(), key=lambda x:x[1])\n",
    "    converted_dict1 = dict(sortedDict1)\n",
    "    # print(converted_dict1)\n",
    "    #print(\"                           \")\n",
    "    #print(\"_______________Page Rank_____________________________\")\n",
    "    pr = nx.eigenvector_centrality(nxG)\n",
    "    sortedDict2 = sorted(pr.items(), key=lambda x:x[1])\n",
    "    converted_dict2 = dict(sortedDict2)\n",
    "    # print(converted_dict2)\n",
    "\n",
    "    #print(\"                           \")\n",
    "\n",
    "    def gap(op, n):\n",
    "        ones = np.ones((n, 1))\n",
    "        x = op - (np.dot(np.transpose(op),ones)/n) * ones\n",
    "        return abs(x)\n",
    "\n",
    "    gap = gap(s,n)\n",
    "    my_gap = {index: value for index, value in enumerate(gap)}\n",
    "    sorting_gap = sorted(my_gap.items(), key=lambda x:x[1], reverse=True)\n",
    "    sorted_gap = dict(sorting_gap)\n",
    "    #print(sorted_gap)\n",
    "    return (converted_dict,converted_dict1,converted_dict2,sorted_gap)\n",
    "\n",
    "def pred(N,converted_dict,converted_dict1,converted_dict2,sorted_gap):\n",
    "    # Using islice() + items()\n",
    "    # Get first N items in dictionary\n",
    "    a = list(itertools.islice(converted_dict.keys(), N))\n",
    "    b = list(itertools.islice(converted_dict1.keys(), N))\n",
    "    c = list(itertools.islice(converted_dict2.keys(), N))\n",
    "\n",
    "\n",
    "    max_pred = sorted(np.unique(a+b+c))\n",
    "#     print(\"Max limited by K is : \" + str(max_pred))\n",
    "    min_pred = list(itertools.islice(sorted_gap.keys(), N))\n",
    "    # printing result\n",
    "#     print(\"Min limited by K is : \" + str(min_pred))\n",
    "    \n",
    "    return (max_pred, min_pred)\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def net_rank(s,G):\n",
    "#     #print(\"___________________Max Analyze__________________________________________\")\n",
    "#     nxG = nx.from_numpy_matrix(G) \n",
    "#     # G = nx.karate_club_graph()\n",
    "#     #print(\"_______________Degree Centrality_____________________________\")  \n",
    "#     deg_centrality = nx.degree_centrality(nxG)\n",
    "#     sortedDict = sorted(deg_centrality.items(), key=lambda x:x[1])\n",
    "#     converted_dict = dict(sortedDict)\n",
    "#     # print(converted_dict)\n",
    "#     #print(\"                           \")\n",
    "#     #print(\"_______________Closeness Rank_____________________________\")\n",
    "#     close_centrality = nx.closeness_centrality(nxG)\n",
    "#     sortedDict1 = sorted(close_centrality.items(), key=lambda x:x[1])\n",
    "#     converted_dict1 = dict(sortedDict1)\n",
    "#     # print(converted_dict1)\n",
    "#     #print(\"                           \")\n",
    "#     #print(\"_______________Page Rank_____________________________\")\n",
    "#     pr = nx.eigenvector_centrality(nxG)\n",
    "#     sortedDict2 = sorted(pr.items(), key=lambda x:x[1])\n",
    "#     converted_dict2 = dict(sortedDict2)\n",
    "#     # print(converted_dict2)\n",
    "\n",
    "#     #print(\"                           \")\n",
    "\n",
    "#     def gap(op, n):\n",
    "#         ones = np.ones((n, 1))\n",
    "#         x = op - (np.dot(np.transpose(op),ones)/n) * ones\n",
    "#         return abs(x)\n",
    "\n",
    "#     gap = gap(s,n)\n",
    "#     my_gap = {index: value for index, value in enumerate(gap)}\n",
    "#     sorting_gap = sorted(my_gap.items(), key=lambda x:x[1], reverse=True)\n",
    "#     sorted_gap = dict(sorting_gap)\n",
    "#     #print(sorted_gap)\n",
    "#     return (converted_dict,converted_dict1,converted_dict2,sorted_gap)\n",
    "\n",
    "# def pred(N,converted_dict,converted_dict1,converted_dict2,sorted_gap):\n",
    "#     # Using islice() + items()\n",
    "#     # Get first N items in dictionary\n",
    "#     a = list(itertools.islice(converted_dict.keys(), N))\n",
    "#     b = list(itertools.islice(converted_dict1.keys(), N))\n",
    "#     c = list(itertools.islice(converted_dict2.keys(), N))\n",
    "    \n",
    "#     max_pred = c\n",
    "\n",
    "#     #max_pred = sorted(np.unique(a+b+c))\n",
    "# #     print(\"Max limited by K is : \" + str(max_pred))\n",
    "\n",
    "\n",
    "#     #print(\"*********opinion*************\")\n",
    "#     rank1_list = list(range(n))\n",
    "#     #print(rank1_list)\n",
    "#     op_order = sorted_gap.keys()\n",
    "#     #print(sorted_gap)\n",
    "#     op_ranks= dict(zip(op_order, rank1_list))\n",
    "#     #print(op_ranks)\n",
    "\n",
    "#     #print(\"*********centrality*************\")\n",
    "#     ecen_order = converted_dict2.keys()\n",
    "#     #print(ecen_order)\n",
    "#     ecen_ranks=dict(zip(ecen_order, rank1_list))\n",
    "#     #print(converted_dict2)\n",
    "#     #print(ecen_ranks)\n",
    "\n",
    "#     #print(\"*********new ranks*************\")      \n",
    "#     new_rank = {i: 0.5*op_ranks.get(i, 0) + 0.5*ecen_ranks.get(i, 0) for i in set(op_ranks).union(ecen_ranks)}\n",
    "#     #print(new_rank)\n",
    "#     sorting_rank = sorted(new_rank.items(), key=lambda x:x[1])\n",
    "#     sorted_rank = dict(sorting_rank)\n",
    "# #     print(sorted_rank)\n",
    "#     min_pred1= list(itertools.islice(sorted_rank.keys(), N))\n",
    "    \n",
    "#     first_key = next(iter(converted_dict2)) \n",
    "#     converted_dict2.pop(first_key)\n",
    "#     min_pred2= list(itertools.islice(converted_dict2.keys(), N))\n",
    "    \n",
    "#     min_pred = min_pred1 + min_pred2\n",
    "# #     print(min_pred)\n",
    "\n",
    "#     # printing result\n",
    "# #     print(\"Min limited by K is : \" + str(min_pred))\n",
    "    \n",
    "#     return (max_pred, min_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_touched\n",
      "[]\n",
      "Maximizer first selection\n",
      "    Agent3 's opinion 0.6842418254088685 changed to 0\n",
      "history at spot\n",
      "1.0\n",
      "fre_max at spot\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0\n",
      "Minimizer first selection\n",
      "    Agent17 's opinion 0.24048185019006352 changed to 0\n",
      "min_history\n",
      "[(17, 0)]\n",
      "Counter({(17, 0): 1})\n",
      "fla_min_fre at the spot\n",
      "{(17, 0): 1}\n",
      "1\n",
      "Game 1\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "fre_max at spot\n",
      "0.5\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.2944275707411682\n",
      "fla_max_fre\n",
      "(array([ 6, 36], dtype=int64),)\n",
      "[0.5 0.5]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.037116723644482354 and Equi_Max = 0.051932280930214736\n",
      "Game 2\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "fre_max at spot\n",
      "0.6666666666666666\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.1962850471607788\n",
      "fla_max_fre\n",
      "(array([ 6, 36], dtype=int64),)\n",
      "[0.333 0.667]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.03855062684070093 and Equi_Max = 0.04745556888927751\n",
      "Game 3\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.5\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.3386544952191926\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.25 0.5  0.25]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.04398587477067333 and Equi_Max = 0.04804699193808309\n",
      "Game 4\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.4\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4240761640542409\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.2 0.4 0.4]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.046842841140901925 and Equi_Max = 0.05047682801904661\n",
      "Game 5\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.5\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6779397674127936\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.167 0.333 0.5  ]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.04824138360078031 and Equi_Max = 0.05175278584414841\n",
      "Game 6\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.5714285714285714\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.7103138119193942\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.143 0.286 0.571]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.047947464248601065 and Equi_Max = 0.050851108553305234\n",
      "Game 7\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.625\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.7345943452993449\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.125 0.25  0.625]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.04769725461629842 and Equi_Max = 0.05016492964094115\n",
      "Game 8\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "fre_max at spot\n",
      "0.5555555555555556\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6912442156528686\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.111 0.333 0.556]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.049277487955467054 and Equi_Max = 0.051359759380461785\n",
      "Game 9\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "fre_max at spot\n",
      "0.4\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4417669338454506\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.1 0.4 0.5]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.049523004644690796 and Equi_Max = 0.052496897137789066\n",
      "Game 10\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "fre_max at spot\n",
      "0.45454545454545453\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.40160630349586424\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.091 0.455 0.455]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.04901361160345088 and Equi_Max = 0.051782436919705827\n",
      "Game 11\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "fre_max at spot\n",
      "0.5\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.3681391115378756\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.083 0.5   0.417]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.04853520239580487 and Equi_Max = 0.05113364585012072\n",
      "Game 12\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.46153846153846156\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.3987255521422262\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.077 0.462 0.462]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.049289856079960406 and Equi_Max = 0.05120219400541958\n",
      "Game 13\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.5\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4249425012316696\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.071 0.429 0.5  ]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.049905004527847074 and Equi_Max = 0.0516562944352987\n",
      "Game 14\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.5333333333333333\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4476638571091872\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.067 0.4   0.533]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.050414465665911345 and Equi_Max = 0.05202716100501824\n",
      "Game 15\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.5625\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6795474870096868\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.062 0.375 0.562]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05081851428140674 and Equi_Max = 0.052334752463742945\n",
      "Game 16\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.5882352941176471\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6927834041831757\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.059 0.353 0.588]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05055051668774723 and Equi_Max = 0.051959268457658137\n",
      "Game 17\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.6111111111111112\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.7045486638929437\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.056 0.333 0.611]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.050305930858598955 and Equi_Max = 0.05162059933517051\n",
      "Game 18\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "fre_max at spot\n",
      "0.5789473684210527\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6855957436081076\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.053 0.368 0.579]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05090297834999035 and Equi_Max = 0.05147248244451899\n",
      "Game 19\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "fre_max at spot\n",
      "0.4\n",
      "_______________________\n",
      "Minimizer Play\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.45061231874105556\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.05 0.4  0.55]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05085983489901369 and Equi_Max = 0.05200076772563234\n",
      "Game 20\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "fre_max at spot\n",
      "0.42857142857142855\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.42915458927719574\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.048 0.429 0.524]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05054453535328347 and Equi_Max = 0.0516764253197909\n",
      "Game 21\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.4090909090909091\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.44445496428252473\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.045 0.409 0.545]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.050863031571986725 and Equi_Max = 0.05158762848766918\n",
      "Game 22\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.5652173913043478\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.458424871896086\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.043 0.391 0.565]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05114509101760387 and Equi_Max = 0.05181862061623907\n",
      "Game 23\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.5833333333333334\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.684536655099715\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.042 0.375 0.583]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05120760405991623 and Equi_Max = 0.05202423714530688\n",
      "Game 24\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.6\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6933375120540863\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.04 0.36 0.6 ]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05100878192913409 and Equi_Max = 0.051784850468080436\n",
      "Game 25\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "fre_max at spot\n",
      "0.5769230769230769\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.46443452816918634\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.038 0.385 0.577]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05136282165499249 and Equi_Max = 0.0517133422370535\n",
      "Game 26\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.37037037037037035\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6882384836589708\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.037 0.37  0.593]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05122321083014009 and Equi_Max = 0.05175116777586232\n",
      "Game 27\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "fre_max at spot\n",
      "0.5714285714285714\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4586093061354743\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.036 0.393 0.571]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05133247941135789 and Equi_Max = 0.05185753536496828\n",
      "Game 28\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.3793103448275862\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6838427695252507\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.034 0.379 0.586]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05140716009766455 and Equi_Max = 0.05172573547352996\n",
      "Game 29\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "fre_max at spot\n",
      "0.5666666666666667\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4535607803729238\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.033 0.4   0.567]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05130496328044405 and Equi_Max = 0.05197584301670165\n",
      "Game 30\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "fre_max at spot\n",
      "0.41935483870967744\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4389297874576682\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.032 0.419 0.548]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.051080679162576734 and Equi_Max = 0.05176225745601481\n",
      "Game 31\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.40625\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4491433203306921\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.031 0.406 0.562]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05127995773482427 and Equi_Max = 0.051868218593009295\n",
      "Game 32\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.5757575757575758\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.45873785121141164\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.03  0.394 0.576]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05146308488807272 and Equi_Max = 0.05201696253637525\n",
      "Game 33\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.5882352941176471\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.683352967943276\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.029 0.382 0.588]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05154801063600256 and Equi_Max = 0.052154179949897045\n",
      "Game 34\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.6\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6896731139722967\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.029 0.371 0.6  ]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05139692472700529 and Equi_Max = 0.051981711706893405\n",
      "Game 35\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.6111111111111112\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6956421407774829\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.028 0.361 0.611]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05125264498044159 and Equi_Max = 0.051817394584060934\n",
      "Game 36\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "fre_max at spot\n",
      "0.5945945945945946\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6861502769316336\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.027 0.378 0.595]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.051531986753411994 and Equi_Max = 0.052056323972327824\n",
      "Game 37\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "fre_max at spot\n",
      "0.39473684210526316\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4588325686357865\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.026 0.395 0.579]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.051559321261864424 and Equi_Max = 0.0523120475876189\n",
      "Game 38\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "fre_max at spot\n",
      "0.41025641025641024\n",
      "_______________________\n",
      "Minimizer Play\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4470676309784586\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.026 0.41  0.564]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05137776687542993 and Equi_Max = 0.05213715330772737\n",
      "Game 39\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "fre_max at spot\n",
      "0.425\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.43589094020399716\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.025 0.425 0.55 ]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.051199739083972184 and Equi_Max = 0.05196565937885602\n",
      "Game 40\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.4146341463414634\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4439365962818127\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.024 0.415 0.561]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05135385172952543 and Equi_Max = 0.05189964135222298\n",
      "Game 41\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.5714285714285714\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.45159912587973217\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.024 0.405 0.571]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05149804175608635 and Equi_Max = 0.052016090916084314\n",
      "Game 42\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.5813953488372093\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.45890525875216714\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.023 0.395 0.581]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05163317752058827 and Equi_Max = 0.05212538794449964\n",
      "Game 43\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.5909090909090909\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6827073204034003\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.023 0.386 0.591]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05173366138933981 and Equi_Max = 0.052228139703445246\n",
      "Game 44\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.6\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6876373372601914\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.022 0.378 0.6  ]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05161230848063697 and Equi_Max = 0.05209332858314118\n",
      "Game 45\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "fre_max at spot\n",
      "0.6086956521739131\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6923530055579916\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.022 0.37  0.609]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05149524740336774 and Equi_Max = 0.05196346876092493\n",
      "Game 46\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "fre_max at spot\n",
      "0.5957446808510638\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6849506688116738\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.021 0.383 0.596]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.051709283310776614 and Equi_Max = 0.05202426794984459\n",
      "Game 47\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "fre_max at spot\n",
      "0.3958333333333333\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4589628050943019\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.021 0.396 0.583]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05169164732787224 and Equi_Max = 0.052225887494501605\n",
      "Game 48\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "fre_max at spot\n",
      "0.40816326530612246\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4495962172352344\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.02  0.408 0.571]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.051544914015184656 and Equi_Max = 0.052089275057362015\n",
      "Game 49\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "fre_max at spot\n",
      "0.42\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4406042928905298\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.02 0.42 0.56]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05140047890357161 and Equi_Max = 0.051954702974480065\n",
      "Game 50\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.4117647058823529\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.44697995066511614\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.02  0.412 0.569]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05151942189045984 and Equi_Max = 0.05201416345323299\n",
      "Game 51\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.5769230769230769\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4531103908329876\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.019 0.404 0.577]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05163214278575087 and Equi_Max = 0.05210500469128569\n",
      "Game 52\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.5849056603773585\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.45900949363603377\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.019 0.396 0.585]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.051739085270801705 and Equi_Max = 0.052191320828440455\n",
      "Game 53\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.5925925925925926\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.46469011115007824\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.019 0.389 0.593]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.051840653510329536 and Equi_Max = 0.05227342472935286\n",
      "Game 54\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.6\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6863418429888516\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.018 0.382 0.6  ]\n",
      "pop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Reached Nash Equilibrium at Equi_Min = 0.051749277472341794 and Equi_Max = 0.05235160199777484\n",
      "Game 55\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.6071428571428571\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6902385614883185\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.018 0.375 0.607]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.0516509588374476 and Equi_Max = 0.05224087898461491\n",
      "Game 56\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.6140350877192983\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6939985530228918\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.018 0.368 0.614]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.051555466938549 and Equi_Max = 0.05213345900589053\n",
      "Game 57\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.6206896551724138\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6976288896769627\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.017 0.362 0.621]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05146268723578003 and Equi_Max = 0.05202920160196044\n",
      "Game 58\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "pop\n",
      "fre_max at spot\n",
      "0.6101694915254238\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6916426911821169\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.017 0.373 0.61 ]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05163526819428671 and Equi_Max = 0.052068792547101034\n",
      "Game 59\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "pop\n",
      "fre_max at spot\n",
      "0.38333333333333336\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6858560326370993\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.017 0.383 0.6  ]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05180062211619287 and Equi_Max = 0.052230338164688875\n",
      "Game 60\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "pop\n",
      "fre_max at spot\n",
      "0.39344262295081966\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4615789731095403\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.016 0.393 0.59 ]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05184020729100759 and Equi_Max = 0.0523850616570629\n",
      "Game 61\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "pop\n",
      "fre_max at spot\n",
      "0.4032258064516129\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.45413415096261234\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.016 0.403 0.581]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05172294017306508 and Equi_Max = 0.05227575432308381\n",
      "Game 62\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "pop\n",
      "fre_max at spot\n",
      "0.4126984126984127\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4469256723759041\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.016 0.413 0.571]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05160711220007934 and Equi_Max = 0.05216774013376861\n",
      "Game 63\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "pop\n",
      "fre_max at spot\n",
      "0.421875\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.43994245874503063\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.016 0.422 0.562]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05149276128427675 and Equi_Max = 0.052061050496908824\n",
      "Game 64\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.4153846153846154\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4449550799857907\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.015 0.415 0.569]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05158498364589294 and Equi_Max = 0.0520431939206775\n",
      "Game 65\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.5757575757575758\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.44981580361319445\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.015 0.409 0.576]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05167337930781108 and Equi_Max = 0.05211429873463622\n",
      "Game 66\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.582089552238806\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4545314310129144\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.015 0.403 0.582]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05175816513770991 and Equi_Max = 0.05218259923944911\n",
      "Game 67\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.5882352941176471\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4591083634891132\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.015 0.397 0.588]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05183954260790694 and Equi_Max = 0.05224824944004824\n",
      "Game 68\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.5942028985507246\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.46355263125585694\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.014 0.391 0.594]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.051917699099384804 and Equi_Max = 0.05231139264616033\n",
      "Game 69\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.6\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6850926163700597\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.014 0.386 0.6  ]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05188128591746775 and Equi_Max = 0.05237216236330789\n",
      "Game 70\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.6056338028169014\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.688183679223425\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.014 0.38  0.606]\n",
      "pop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Reached Nash Equilibrium at Equi_Min = 0.05180209862095652 and Equi_Max = 0.05228504103037757\n",
      "Game 71\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.6111111111111112\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6911888792197525\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.014 0.375 0.611]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.051724714488734586 and Equi_Max = 0.05219996317712612\n",
      "Game 72\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.6164383561643836\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.694111744969605\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.014 0.37  0.616]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05164907548877211 and Equi_Max = 0.05211686041357873\n",
      "Game 73\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "pop\n",
      "fre_max at spot\n",
      "0.6081081081081081\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6893864940711113\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.014 0.378 0.608]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05178356720939202 and Equi_Max = 0.05204613442189433\n",
      "Game 74\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "pop\n",
      "fre_max at spot\n",
      "0.38666666666666666\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6847872498632439\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.013 0.387 0.6  ]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05191354437483184 and Equi_Max = 0.05217478379984651\n",
      "Game 75\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "pop\n",
      "fre_max at spot\n",
      "0.39473684210526316\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4611603015030509\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.013 0.395 0.592]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05191015588631738 and Equi_Max = 0.052299093064222445\n",
      "Game 76\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "pop\n",
      "fre_max at spot\n",
      "0.4025974025974026\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4551712066783359\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.013 0.403 0.584]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05181487948764686 and Equi_Max = 0.052212387736467684\n",
      "Game 77\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "pop\n",
      "fre_max at spot\n",
      "0.41025641025641024\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.449335678387588\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.013 0.41  0.577]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05172055492547288 and Equi_Max = 0.0521264874676012\n",
      "Game 78\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.4050632911392405\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4533410854889405\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.013 0.405 0.582]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05179202065938045 and Equi_Max = 0.052062053329720685\n",
      "Game 79\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.5875\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4572463574127592\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.013 0.4   0.588]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05186103505956831 and Equi_Max = 0.05211938741760524\n",
      "Game 80\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.5925925925925926\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.46105520286932306\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.012 0.395 0.593]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05192771323040818 and Equi_Max = 0.05217486826051561\n",
      "Game 81\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.5975609756097561\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6830561657441764\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.012 0.39  0.598]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05198915528402104 and Equi_Max = 0.05222857976173291\n",
      "Game 82\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.6024096385542169\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6857248634937525\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.012 0.386 0.602]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05192037402210194 and Equi_Max = 0.052156195902481974\n",
      "Game 83\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.6071428571428571\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6883300208207197\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.012 0.381 0.607]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05185293307192051 and Equi_Max = 0.05208524983035487\n",
      "Game 84\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "pop\n",
      "fre_max at spot\n",
      "0.6\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6842842932637826\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.012 0.388 0.6  ]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05196666715328446 and Equi_Max = 0.05215087009554281\n",
      "Game 85\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "pop\n",
      "fre_max at spot\n",
      "0.3953488372093023\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.460962325006959\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.012 0.395 0.593]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05194322843218786 and Equi_Max = 0.05226074897668827\n",
      "Game 86\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "pop\n",
      "fre_max at spot\n",
      "0.40229885057471265\n",
      "_______________________\n",
      "Minimizer Play\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4556639074781433\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.011 0.402 0.586]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.051858546328312126 and Equi_Max = 0.05218452851321644\n",
      "Game 87\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "pop\n",
      "fre_max at spot\n",
      "0.4090909090909091\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.45048590852952813\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.011 0.409 0.58 ]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05177461679170422 and Equi_Max = 0.052108926986924466\n",
      "Game 88\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.4044943820224719\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4540283459549765\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.011 0.404 0.584]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05183731272045878 and Equi_Max = 0.052105843329492044\n",
      "Game 89\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.5888888888888889\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4574920625487482\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.011 0.4   0.589]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05189809313086148 and Equi_Max = 0.05215617659686388\n",
      "Game 90\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.5934065934065934\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4608796535030964\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.011 0.396 0.593]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.051957038200534864 and Equi_Max = 0.052205060807253345\n",
      "Game 91\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.5978260869565217\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4641936011758283\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.011 0.391 0.598]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05201422388878872 and Equi_Max = 0.05225255444961859\n",
      "Game 92\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.6021505376344086\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6851643533081686\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.011 0.387 0.602]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05196821163426649 and Equi_Max = 0.05229871301150563\n",
      "Game 93\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.6063829787234043\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6874983291129648\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.011 0.383 0.606]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05190750625510946 and Equi_Max = 0.05223392026656004\n",
      "Game 94\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.6105263157894737\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6897831685850283\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.011 0.379 0.611]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05184785049575977 and Equi_Max = 0.052170271563152786\n",
      "Game 95\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent19 's opinion 0.29927996971193704 changed to 1\n",
      "pop\n",
      "fre_max at spot\n",
      "0.6145833333333334\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6920204072347571\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.01  0.375 0.615]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05178921861838377 and Equi_Max = 0.05210773806319069\n",
      "Game 96\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "pop\n",
      "fre_max at spot\n",
      "0.6082474226804123\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6884371368352343\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.01  0.381 0.608]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.051890141206207094 and Equi_Max = 0.05216558562231467\n",
      "Game 97\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "pop\n",
      "fre_max at spot\n",
      "0.3877551020408163\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent16 's opinion 0.2014556818627249 changed to 0.6849269944030489\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.01  0.388 0.602]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05198846530010563 and Equi_Max = 0.05226235312951292\n",
      "Game 98\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "pop\n",
      "fre_max at spot\n",
      "0.3939393939393939\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.46231174409852466\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.01  0.394 0.596]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05200167090842377 and Equi_Max = 0.052356615216385724\n",
      "Game 99\n",
      "_____________________\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "    Agent18 's opinion 0.7845920227842521 changed to 0\n",
      "pop\n",
      "fre_max at spot\n",
      "0.4\n",
      "_______________________\n",
      "Minimizer Play\n",
      "                                \n",
      "Minimizer finds its target agent:\n",
      "    Agent0 's opinion 0.9890270075814377 changed to 0.4576886266575394\n",
      "fla_max_fre\n",
      "(array([ 6, 36, 39], dtype=int64),)\n",
      "[0.01 0.4  0.59]\n",
      "pop\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.051927738383637644 and Equi_Max = 0.05228969004740584\n",
      "Game 100\n",
      "_____________________\n",
      "min_recent_50_touched\n",
      "[0, 0, 0, 0, 16, 16, 16, 16, 16, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 16, 16, 16, 16, 16, 0, 0, 0, 0, 0, 0, 16, 16, 16, 16, 0, 0, 0, 0, 0, 0, 0, 16, 16, 16, 16, 16, 16, 0, 0]\n",
      "max_recent_50_touched\n",
      "[19, 19, 19, 19, 19, 19, 19, 19, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 18, 18, 18, 18]\n",
      "Min last 100 action\n",
      "[0, 0, 0, 0, 16, 16, 16, 16, 0, 0, 0, 0, 0, 0, 16, 16, 16, 16, 0, 0, 0, 0, 16, 16, 0, 16, 0, 16, 0, 0, 0, 0, 16, 16, 16, 16, 0, 0, 0, 0, 0, 0, 16, 16, 16, 16, 0, 0, 0, 0, 0, 0, 0, 16, 16, 16, 16, 16, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 16, 16, 16, 16, 16, 0, 0, 0, 0, 0, 0, 16, 16, 16, 16, 0, 0, 0, 0, 0, 0, 0, 16, 16, 16, 16, 16, 16, 0, 0]\n",
      "Max_distribution_last_100\n",
      "[0.4  0.59]\n",
      "[18 19]\n",
      "Min_distribution_last_100\n",
      "dict_keys([0, 16])\n"
     ]
    }
   ],
   "source": [
    "(v1,v2,a,b,c,d) = run(n)                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 18, 19] [0, 6, 2]\n",
      "Maxs\n",
      "Max predic right\n",
      "Mins\n",
      "Min predic right\n",
      "{0: array([0.585]), 6: array([0.57]), 2: array([0.42]), 7: array([0.32]), 16: array([0.317]), 10: array([0.282]), 17: array([0.27]), 3: array([0.249]), 15: array([0.208]), 13: array([0.149]), 9: array([0.148]), 12: array([0.136]), 5: array([0.085]), 8: array([0.075]), 11: array([0.052]), 4: array([0.051]), 18: array([0.032]), 14: array([0.023]), 1: array([0.019]), 19: array([0.005])}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(s,G)\n",
    "N = 3\n",
    "(converted_dict,converted_dict1,converted_dict2,sorted_gap) = net_rank(s,G)\n",
    "(max_pred, min_pred) = pred(N,converted_dict,converted_dict1,converted_dict2,sorted_gap)\n",
    "\n",
    "print(max_pred,min_pred)\n",
    "\n",
    "\n",
    "print(\"Maxs\")\n",
    "if any(x in v1 for x in max_pred):\n",
    "    print(\"Max predic right\")\n",
    "else:\n",
    "    print(\"NNN\")\n",
    "    \n",
    "print(\"Mins\")\n",
    "if any(x in v2 for x in min_pred):\n",
    "    print(\"Min predic right\")\n",
    "else:\n",
    "    print('NNN')\n",
    "    v2 = random.sample(v2,1)\n",
    "    print(v2)\n",
    "    network_anl(s,n,G,v2[0])\n",
    "\n",
    "\n",
    "# print(\"Predict Min's action\")\n",
    "# print(np.nonzero(G[v1]))\n",
    "print(sorted_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********opinion*************\n",
      "{0: array([0.585]), 6: array([0.57]), 2: array([0.42]), 7: array([0.32]), 16: array([0.317]), 10: array([0.282]), 17: array([0.27]), 3: array([0.249]), 15: array([0.208]), 13: array([0.149]), 9: array([0.148]), 12: array([0.136]), 5: array([0.085]), 8: array([0.075]), 11: array([0.052]), 4: array([0.051]), 18: array([0.032]), 14: array([0.023]), 1: array([0.019]), 19: array([0.005])}\n",
      "{0: 0, 6: 1, 2: 2, 7: 3, 16: 4, 10: 5, 17: 6, 3: 7, 15: 8, 13: 9, 9: 10, 12: 11, 5: 12, 8: 13, 11: 14, 4: 15, 18: 16, 14: 17, 1: 18, 19: 19}\n",
      "*********centrality*************\n",
      "dict_keys([18, 19, 16, 17, 14, 1, 8, 12, 15, 0, 9, 11, 13, 5, 3, 4, 10, 2, 7, 6])\n",
      "{18: 0.030547679212102042, 19: 0.0733171950173153, 16: 0.12720170681389006, 17: 0.16881031846575956, 14: 0.17832631851958522, 1: 0.18478804709778923, 8: 0.20048762163420686, 12: 0.20213702947867968, 15: 0.21603515801663362, 0: 0.21769461440758944, 9: 0.22687136970220576, 11: 0.22717435487965654, 13: 0.2284214537103003, 5: 0.2353319834350393, 3: 0.2571302079813812, 4: 0.26901974455400735, 10: 0.27985904117967697, 2: 0.2854649464056756, 7: 0.296706835450428, 6: 0.33313719691045884}\n",
      "{18: 0, 19: 1, 16: 2, 17: 3, 14: 4, 1: 5, 8: 6, 12: 7, 15: 8, 0: 9, 9: 10, 11: 11, 13: 12, 5: 13, 3: 14, 4: 15, 10: 16, 2: 17, 7: 18, 6: 19}\n",
      "*********new ranks*************\n",
      "{16: 6, 0: 9, 17: 9, 15: 16, 18: 16, 12: 18, 2: 19, 8: 19, 6: 20, 9: 20, 19: 20, 3: 21, 7: 21, 10: 21, 13: 21, 14: 21, 1: 23, 5: 25, 11: 25, 4: 30}\n",
      "[19, 16, 17]\n"
     ]
    }
   ],
   "source": [
    "# s = make_innat_opinions(n)\n",
    "def gap(op, n):\n",
    "    ones = np.ones((n, 1))\n",
    "    x = op - (np.dot(np.transpose(op),ones)/n) * ones\n",
    "    return abs(x)\n",
    "\n",
    "gap = gap(s,n)\n",
    "my_gap = {index: value for index, value in enumerate(gap)}\n",
    "sorting_gap = sorted(my_gap.items(), key=lambda x:x[1], reverse=True)\n",
    "sorted_gap = dict(sorting_gap)\n",
    "\n",
    "# G = make_random_network(n)\n",
    "\n",
    "nxG = nx.from_numpy_matrix(G) \n",
    "pr = nx.eigenvector_centrality(nxG)\n",
    "sortedDict2 = sorted(pr.items(), key=lambda x:x[1])\n",
    "converted_dict2 = dict(sortedDict2)\n",
    "\n",
    "print(\"*********opinion*************\")\n",
    "rank1_list = list(range(n))\n",
    "#print(rank1_list)\n",
    "op_order = sorted_gap.keys()\n",
    "print(sorted_gap)\n",
    "op_ranks= dict(zip(op_order, rank1_list))\n",
    "print(op_ranks)\n",
    "\n",
    "print(\"*********centrality*************\")\n",
    "ecen_order = converted_dict2.keys()\n",
    "print(ecen_order)\n",
    "ecen_ranks=dict(zip(ecen_order, rank1_list))\n",
    "print(converted_dict2)\n",
    "print(ecen_ranks)\n",
    "      \n",
    "print(\"*********new ranks*************\")      \n",
    "new_rank = {i: op_ranks.get(i, 0) + ecen_ranks.get(i, 0) for i in set(op_ranks).union(ecen_ranks)}\n",
    "# print(new_rank)\n",
    "sorting_rank = sorted(new_rank.items(), key=lambda x:x[1])\n",
    "sorted_rank = dict(sorting_rank)\n",
    "print(sorted_rank)\n",
    "#min_pred= list(itertools.islice(sorted_rank.keys(), N))\n",
    "\n",
    "first_key = next(iter(converted_dict2)) \n",
    "converted_dict2.pop(first_key)\n",
    "min_pred= list(itertools.islice(converted_dict2.keys(), N))\n",
    "print(min_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def network_anl(s,n,G,agent):\n",
    "\n",
    "    print(str(agent)+' opinion: ' + str(s[agent]))\n",
    "    print(str(agent)+' neighbors: '+ str(np.nonzero(G[agent])))\n",
    "\n",
    "    s_aa = s[:, 0]\n",
    "    my_dict = {index: value for index, value in enumerate(s_aa)}\n",
    "    sorting_s = sorted(my_dict.items(), key=lambda x:x[1])\n",
    "    sorted_S = dict(sorting_s)\n",
    "    res = rank(sorted_S,agent)\n",
    "    # printing result \n",
    "    print(\"Opinion rank of this agent is : \" + str(res))\n",
    "\n",
    "\n",
    "\n",
    "    #print(\"___________________Max Analyze__________________________________________\")\n",
    "    nxG = nx.from_numpy_matrix(G) \n",
    "    # G = nx.karate_club_graph()\n",
    "    print(\"_______________Degree Centrality___________________\")  \n",
    "    deg_centrality = nx.degree_centrality(nxG)\n",
    "    sortedDict = sorted(deg_centrality.items(), key=lambda x:x[1])\n",
    "    converted_dict = dict(sortedDict)\n",
    "    res1 = rank(converted_dict,agent)\n",
    "    print(\"rank of this agent is : \" + str(res1))\n",
    "    print(converted_dict[agent])\n",
    "\n",
    "    # print(converted_dict)\n",
    "    print(\"                           \")\n",
    "    print(\"_______________Closeness Rank________________________\")\n",
    "    close_centrality = nx.closeness_centrality(nxG)\n",
    "    sortedDict1 = sorted(close_centrality.items(), key=lambda x:x[1])\n",
    "    converted_dict1 = dict(sortedDict1)\n",
    "    res2 = rank(converted_dict1,agent)\n",
    "    print(\"rank of this agent is : \" + str(res2))\n",
    "    print(converted_dict1[agent])\n",
    "    # print(converted_dict1)\n",
    "    print(\"                           \")\n",
    "    print(\"_______________Page Rank_____________________________\")\n",
    "    pr = nx.eigenvector_centrality(nxG)\n",
    "    sortedDict3 = sorted(pr.items(), key=lambda x:x[1])\n",
    "    converted_dict3 = dict(sortedDict3)\n",
    "    res3 = rank(converted_dict3,agent)\n",
    "    print(\"rank of this agent is : \" + str(res3))\n",
    "    print(converted_dict3[agent])\n",
    "    # print(converted_dict3)\n",
    "\n",
    "    print(\"                           \")\n",
    "\n",
    "    def gap(op, n):\n",
    "        ones = np.ones((n, 1))\n",
    "        x = op - (np.dot(np.transpose(op),ones)/n) * ones\n",
    "        return x\n",
    "\n",
    "    gap = gap(s,n)\n",
    "    if gap[agent] < 0:\n",
    "        my_gap = {index: value for index, value in enumerate(gap) if value<0}\n",
    "        sorting_gap = sorted(my_gap.items(), key=lambda x:x[1])\n",
    "        sorted_gap = dict(sorting_gap)\n",
    "        temp4 = list(sorted_gap.items()) \n",
    "        res4 = [idx for idx, key in enumerate(temp4) if key[0]==agent][0]+1\n",
    "        print(\"Agent's opinion extremity is ranked as: \" + str(res4))\n",
    "    else:\n",
    "        my_gap = {index: value for index, value in enumerate(gap) if value>=0}\n",
    "        sorting_gap = sorted(my_gap.items(), key=lambda x:x[1], reverse=True)\n",
    "        sorted_gap = dict(sorting_gap)\n",
    "        temp4 = list(sorted_gap.items()) \n",
    "        res4 = [idx for idx, key in enumerate(temp4) if key[0]==agent][0]+1\n",
    "        print(\"Agent's opinion extremity is ranked as: \" + str(res4))\n",
    "    print(\"Agent's min_pref is ranked as: \" + str(res4+res1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(scores,agent):\n",
    "    ranks =1\n",
    "    for i in range(len(scores)):\n",
    "        if scores[agent] > scores[i]:\n",
    "            ranks += 1\n",
    "        elif scores[agent]  == scores[i]:\n",
    "            ranks = ranks\n",
    "    return ranks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "125d6e56934ce2649cb3782cc815dc11821615614828859fcaee5b1c4840aa60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
