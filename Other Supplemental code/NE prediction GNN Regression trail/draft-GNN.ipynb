{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95e3904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "%run excute_nonZS_MaxMin.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e3f6f3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In the context of graph neural networks (GNNs), the input data typically consists of three parts:\n",
    "\n",
    "The graph structure: This is typically represented as an adjacency matrix or an edge list. The adjacency matrix is a square matrix where the (i,j)-th entry is 1 if there is an edge from node i to node j, and 0 otherwise. An edge list is simply a list of tuples (i,j) representing the edges in the graph.\n",
    "\n",
    "Node features: These are the properties of each node in the graph that the model uses to learn representations. Node features can include things like text embeddings, image features, or numerical attributes. In the case of the Cora dataset, each node is represented by a 1433-dimensional binary vector indicating the presence or absence of certain keywords in a document.\n",
    "\n",
    "Node labels: These are the ground truth labels for each node that the model tries to predict. In the case of the Cora dataset, each node is assigned one of seven possible labels indicating the topic of the corresponding document.\n",
    "The data for the Cora dataset looks like this:\n",
    "\n",
    "css\n",
    "Copy code\n",
    "Data(edge_index=[2, 10556], x=[2708, 1433], y=[2708])\n",
    "Here, edge_index is the edge list representing the graph structure, x is the node feature matrix, and y is the node label vector.\n",
    "\n",
    "In more detail, edge_index is a 2D tensor of shape (2, E) where E is the number of edges in the graph. \n",
    "The first row of edge_index contains the indices of the source nodes of each edge, while the second row contains the indices of the target nodes. \n",
    "Each row of x represents the feature vector for a node, and y is a 1D tensor of length N where N is the number of nodes in the graph. \n",
    "The i-th entry of y contains the label for the i-th node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d735dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create the data\n",
    "# adj_list = []\n",
    "# feat_list = []\n",
    "# labels_list = []\n",
    "# for i in range(10):\n",
    "#     (v1,v2, max_opinion, min_opinion,max_pol, s, G, a,b,c,d) = run(n)\n",
    "#     adj_list.append(torch.tensor(G))\n",
    "#     feat_list.append(torch.tensor(s))\n",
    "#     #create min_action label\n",
    "#     c1 = [0 for i in range(20)]\n",
    "#     c1[v2]=1\n",
    "#     print(c1)\n",
    "#     labels= c1\n",
    "#     labels_list.append(torch.tensor(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "999a9229",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_graphs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16416\\687516520.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load the graph data from multiple files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mgraph_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_graphs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0madj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'graph_{i}_adj.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mnode_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'graph_{i}_features.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_graphs' is not defined"
     ]
    }
   ],
   "source": [
    "# load the graph data from multiple files\n",
    "graph_data = []\n",
    "for i in range(num_graphs):\n",
    "    adj = np.load(f'graph_{i}_adj.npy')\n",
    "    node_features = np.load(f'graph_{i}_features.npy')\n",
    "    labels = np.load(f'graph_{i}_labels.npy')\n",
    "    graph_data.append((adj, node_features, labels))\n",
    "\n",
    "# Convert each graph data into PyTorch Geometric format\n",
    "data_list = []\n",
    "for i, (adj, features, labels) in enumerate(graph_data):\n",
    "    edge_index = torch.tensor(adj.nonzero(), dtype=torch.long).t()\n",
    "    x = torch.tensor(features, dtype=torch.float)\n",
    "    y = torch.tensor(labels, dtype=torch.long)\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "    data_list.append(data)\n",
    "\n",
    "# Create a PyTorch Geometric DataLoader to handle batching and shuffling\n",
    "loader = DataLoader(data_list, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab8e7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graphical Convelution Network model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)  # define the first GCN layer\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim) # define the second GCN layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        # Pass the node features and adjacency matrix through the first layer\n",
    "        x, edge_index = data.x, data.edge_index  # read each variable\n",
    "        x = F.relu(self.conv1(x, edge_index)) # apply the ReLU activation function on first layer\n",
    "        # Pass the output of the first layer through the second layer\n",
    "        x = self.conv2(x, edge_index)  \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b54eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "adjacency_matrix = [[0, 1, 1, 0], [1, 0, 1, 1], [1, 1, 0, 1], [0, 1, 1, 0]]\n",
    "num_nodes = len(adjacency_matrix)\n",
    "edge_index = torch.tensor([[i, j] for i in range(num_nodes) for j in range(num_nodes) if adjacency_matrix[i][j] == 1],\n",
    "                          dtype=torch.long).t()\n",
    "node_features = torch.randn((num_nodes, 16))\n",
    "node_labels = torch.tensor([0, 1, 1, 0], dtype=torch.long)\n",
    "\n",
    "data = Data(x=node_features, edge_index=edge_index, y=node_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d4b4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "# Create a torch geometric data object\n",
    "# data = Data(x=torch.tensor(node_props, dtype=torch.float),\n",
    "#             edge_index=torch.tensor(adj_matrix.nonzero(), dtype=torch.long),\n",
    "#             y=torch.tensor(labels, dtype=torch.long))\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data, val_data = torch.utils.data.random_split(data, [int(0.8*len(data)), len(data)-int(0.8*len(data))])\n",
    "\n",
    "# Create data loaders for batch processing\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7363fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(input_dim=node_props.shape[1], hidden_dim=64, output_dim=2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(model, loader, optimizer, criterion, device):\n",
    "    model.train()   # set the model in training mode\n",
    "    total_loss, total_correct = 0, 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()  # zero the gradients\n",
    "        \n",
    "        # forward pass\n",
    "        output = model(data)  \n",
    "        loss = criterion(output, data.y)  # compute the loss on labeled nodes only\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward() \n",
    "        optimizer.step()  # update the parameters\n",
    "        total_loss += loss.item()\n",
    "        total_correct += (output.argmax(dim=1) == data.y).sum().item()\n",
    "    return total_loss/len(loader.dataset), total_correct/len(loader.dataset)\n",
    "\n",
    "def test(model, loader, criterion, device):\n",
    "    model.eval() # set the model in evaluation mode\n",
    "    total_loss, total_correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)  # forward pass\n",
    "            loss = criterion(output, data.y) \n",
    "            total_loss += loss.item()\n",
    "            total_correct += (output.argmax(dim=1) == data.y).sum().item() # compute the number of correct predictions\n",
    "    return total_loss/len    # compute the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088016a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "start = time.process_time()\n",
    "\n",
    "for epoch in range(200):\n",
    "    train_loss = train() # train the model for one epoch\n",
    "    test_losses = test() # evaluate the model on the test set\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    if e % 5 == 0:\n",
    "        print('In epoch {}, loss: {:.3f}, val acc: {:.3f} (best {:.3f}), test acc: {:.3f} (best {:.3f})'.format(\n",
    "            e, loss, val_acc, best_val_acc, test_acc, best_test_acc))\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(train_losses, label='Train loss', c='blue')\n",
    "plt.plot(test_losses, label='Test loss', c='red')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accurarcy')\n",
    "plt.title('GCN')\n",
    "plt.legend(loc='lower right', fontsize='x-large')\n",
    "plt.savefig('gcn_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd02f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall ipykernel\n",
    "! pip uninstall ipython\n",
    "! pip uninstall jupyter_client\n",
    "! pip uninstall jupyter_core\n",
    "! pip uninstall traitlets\n",
    "! pip uninstall python_genutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc55b5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! conda clean -tipsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6b2d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "! pip install ipykernel\n",
    "! pip install ipython\n",
    "! pip install jupyter_client\n",
    "! pip install jupyter_core\n",
    "! pip install traitlets\n",
    "! pip install python_genutils"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
