{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e4f798b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run excute_nonZS_MaxMin.ipynb\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23245334",
   "metadata": {},
   "source": [
    "## 1. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f9f7e867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if I use this, then the result will not be correct - just logics outside of the function\n",
    "\n",
    "def network_data(s, G, n):\n",
    "    (v1, v2, max_opinion, min_opinion, max_pol) = MaxMin_play(s, n, G)\n",
    "    (scaled_deg_cent, scaled_clo_cent, scaled_eigen_cent, scaled_MinPaths_sort, scaled_op_extre, scaled_cc) = metrics(G, v1)\n",
    "    # print(v1, max_opinion)\n",
    "    #print(\"actual_ranks INPUT:\",s, n, v1, max_opinion )\n",
    "    (actual_Y_dict, actual_ranks, innate_por_dict) = actual_rank(s, n, v1, max_opinion)\n",
    "    keys = converted_dict2.keys()\n",
    "    df = pd.DataFrame({'keys': list(keys),\n",
    "                   'x1_d': [sorted_gap[x] for x in keys],\n",
    "                   'x2_deg':[converted_dict[x] for x in keys],\n",
    "                   'x3_clo':[converted_dict1[x] for x in keys],\n",
    "                   'x4_eigen': [converted_dict2[x] for x in keys],\n",
    "                   'x5_path': [scaled_MinPaths_sort[x] for x in keys],\n",
    "                   'x6_cc': [scaled_cc[x] for x in keys],\n",
    "                   'y_value': [actual_Y_dict[x] for x in keys],\n",
    "                    'ranks_y':[actual_ranks[x] for x in keys]})\n",
    "\n",
    "    print(\"_________________\")\n",
    "    a = sorted(actual_Y_dict.items(), key=lambda x:x[1])\n",
    "#     print(a)\n",
    "    if a[0][0]!= v1:\n",
    "        print(a[0][0]==v2)\n",
    "    else:\n",
    "        print(a[1][0]==v2)\n",
    "    \n",
    "    return (df, actual_Y_dict, innate_por_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b72dfb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_values Normalizaion \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def rescale(dic): # input x is a dictionary - sorted node index: value\n",
    "    minmax_scale = MinMaxScaler(feature_range=(0, 1))\n",
    "    x = list(dic.values())\n",
    "    x = np.array(x)\n",
    "    x = x.reshape(-1, 1)\n",
    "    x_scale = minmax_scale.fit_transform(x).flatten()\n",
    "    dic_scale = dict(zip(dic.keys(),x_scale))\n",
    "    return dic_scale  # output\n",
    "\n",
    "# Creat Metrics for Regression\n",
    "\n",
    "################### create shortest path from all nodes to max selected node v1 ############\n",
    "def shortest_pth(G, v1):\n",
    "    nxG = nx.from_numpy_matrix(G)  \n",
    "    paths = nx.single_source_shortest_path(nxG, v1) \n",
    "    # the length of shortest path from v2 to v1\n",
    "    lenths =[]\n",
    "    for v in paths.items():\n",
    "        lenth = len(v[1])\n",
    "        lenths.append(lenth)  \n",
    "    PathLen = dict(zip(paths.keys(),lenths))\n",
    "    #print(\"path_lenth\",PathLen)\n",
    "    return PathLen\n",
    "\n",
    "def local_clustering_coefficient(G):\n",
    "    clus_coef = []\n",
    "    for node in range(len(G)):\n",
    "        neighbors = np.nonzero(G[node])[1]\n",
    "        num_neighbors = len(neighbors)\n",
    "        if num_neighbors < 2:\n",
    "            clustering_coefficient = 0.0  # No triangles possible\n",
    "        else:\n",
    "            num_triangles = 0\n",
    "            for i in range(num_neighbors - 1):\n",
    "                for j in range(i + 1, num_neighbors):\n",
    "                    #print(neighbors[i], neighbors[i])\n",
    "                    if G[neighbors[i], neighbors[j]] == 1:\n",
    "                        num_triangles = num_triangles + 1\n",
    "                        #print(num_triangles)\n",
    "#             print(\"num_triangles:\",num_triangles)\n",
    "            clustering_coefficient = (2.0 * num_triangles) / (num_neighbors * (num_neighbors - 1))\n",
    "        clus_coef.append((node, clustering_coefficient))\n",
    "    cc = dict(clus_coef)\n",
    "    \n",
    "    return cc\n",
    "\n",
    "\n",
    "def metrics(G, v1):\n",
    "\n",
    "    nxG = nx.from_numpy_matrix(G) \n",
    "    # G = nx.karate_club_graph()\n",
    "   # print(\"_______________Degree Centrality_____________________________\")  \n",
    "    deg_centrality = nx.degree_centrality(nxG)\n",
    "    sortedDict = sorted(deg_centrality.items(), key=lambda x:x[1])\n",
    "    converted_dict = dict(sortedDict)\n",
    "    # print(converted_dict)\n",
    "    #print(\"                           \")\n",
    "   # print(\"_______________Closeness Rank_____________________________\")\n",
    "    close_centrality = nx.closeness_centrality(nxG)\n",
    "    sortedDict1 = sorted(close_centrality.items(), key=lambda x:x[1])\n",
    "    converted_dict1 = dict(sortedDict1)\n",
    "    # print(converted_dict1)\n",
    "    #print(\"                           \")\n",
    "   # print(\"_______________Page Rank_____________________________\")\n",
    "    pr = nx.eigenvector_centrality(nxG)\n",
    "    sortedDict2 = sorted(pr.items(), key=lambda x:x[1])\n",
    "    converted_dict2 = dict(sortedDict2)\n",
    "    # print(converted_dict2)\n",
    "    #print(\"                           \")\n",
    "   # print(\"_______________Opinion Extremity_____________________________\")\n",
    "    def gap(op, n):\n",
    "        ones = np.ones((n, 1))\n",
    "        x = op - (np.dot(np.transpose(op),ones)/n) * ones\n",
    "        return abs(x)\n",
    "    gap = gap(s,n)\n",
    "    my_gap = {index: value for index, value in enumerate(gap)}\n",
    "    sorting_gap = sorted(my_gap.items(), key=lambda x:x[1], reverse=True)\n",
    "    sorted_gap = dict(sorting_gap)\n",
    "    # print(\"opinion - mean\")\n",
    "    # print(sorted_gap)\n",
    "    \n",
    "   # print(\"________________Shortest Path_____________________________\")\n",
    "    PathLen = shortest_pth(G, v1)\n",
    "    # creat a dict node:shortest length to v1(max selected node)\n",
    "    \n",
    "   #print(\"________________cluster coefficient____________________________\") \n",
    "    cc = local_clustering_coefficient(G)\n",
    "    \n",
    "#     PathLen = rescale(PathLen) # rescale the shortest path to the range (0,1) for regression\n",
    "#     converted_dict= rescale(converted_dict)\n",
    "#     converted_dict1 = rescale(converted_dict1)\n",
    "#     converted_dict2 = rescale(converted_dict2)\n",
    "#     sorted_gap = rescale(sorted_gap)\n",
    "#     cc = rescale(cc)\n",
    "    \n",
    "    # sorting all varibles based on the node index\n",
    "    scaled_MinPaths_sort = dict(sorted(PathLen.items(), key=lambda x:x[0]))\n",
    "    #print(\"scaled_paths_sort\",scaled_MinPaths_sort)\n",
    "    \n",
    "    scaled_deg_cent = dict(sorted(converted_dict.items(), key=lambda x:x[0]))\n",
    "    scaled_clo_cent = dict(sorted(converted_dict1.items(), key=lambda x:x[0]))\n",
    "    scaled_eigen_cent = dict(sorted(converted_dict2.items(), key=lambda x:x[0]))\n",
    "    scaled_op_extre = dict(sorted(sorted_gap.items(), key=lambda x:x[0]))\n",
    "    scaled_cc = dict(sorted(cc.items(), key=lambda x:x[0]))\n",
    "    \n",
    "    return (scaled_deg_cent, scaled_clo_cent, scaled_eigen_cent, scaled_MinPaths_sort, scaled_op_extre, scaled_cc)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "09e82411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the ground truth of Min's action - knowing Max chooses v1, what Min's action will be?\n",
    "def actual_rank(s, n, v1, max_opinion):\n",
    "\n",
    "    L = scipy.sparse.csgraph.laplacian(G, normed=False)  # Return the Laplacian matrix\n",
    "    A = np.linalg.inv(np.identity(n) + L)  # A = (I + L)^(-1)\\n  Stanford paper theory\n",
    "    op = copy.copy(s)\n",
    "    op[v1] = max_opinion\n",
    "    \n",
    "    all_1 = list(range(n))    # for all agent \n",
    "    C1 = [x for x in all_1 if x != v1]  # for the vertice that Maximizer has not touched\n",
    "    innat_por = obj_polarization(A, s, n) # Calculate the polarization after maximzer' action - not innate polarization\n",
    "    max_por = obj_polarization(A, op, n)\n",
    "    results = []\n",
    "    real_por1 = []\n",
    "    for v2 in C1:   \n",
    "        (changed_opinion, por) = derivate_s(op,n,v2,A)   # find the best new_op option  \n",
    "        por_1 = por - max_por     # append the change of the polarization\n",
    "        results.append((v2, por_1))\n",
    "        real_por1.append((v2,innat_por))\n",
    "#         print(\"innate_por \",real_por1)\n",
    "    results.append((v1,0)) # minimizer cannot choose v1, but we need all nodes for the dataframe\n",
    "    real_por1.append((v1,innat_por))\n",
    "\n",
    "    innate_por_dict = dict(real_por1)\n",
    "#     actual_por_dict = dict(sorted(actual_por.items(), key=lambda x:x[0]))  \n",
    "    \n",
    "    actual_Y = dict(results) # now we have - node:polarization\n",
    "    # most of v are in sequential order, but v1 might not be in order, so we need to sort it\n",
    "    actual_Y_dict = dict(sorted(actual_Y.items(), key=lambda x:x[0]))   #sort - list nodes in sequential of the node index\n",
    "    actual_Y_dict_scale = rescale(actual_Y_dict)\n",
    "   # dictionary -  node:polarization\n",
    "   # print(\"actual_Y_dict\",actual_Y_dict) \n",
    "\n",
    "    # create the rank of the Y values based on minimizer's choice \n",
    "    actual_Y_order = dict(sorted(actual_Y.items(), key=lambda x:x[1]))  #sort - list nodes in sequential of the polariz.\n",
    "    node_ranks= dict(zip(actual_Y_order.keys(), all_1)) # dictionary -  node:polarization rank(replace polarz. with rank)\n",
    "    actual_ranks = dict(sorted(node_ranks.items(), key=lambda x:x[0])) # sort - list node in sequential node index\n",
    "    \n",
    "    return (actual_Y_dict_scale, actual_ranks, innate_por_dict)  # return two dictionary, 1. sequential node: polarization, \n",
    "                                                                # 2. seq. node: pol rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "41b7603b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.0199012084611508, 2: 0.0199012084611508, 3: 0.0199012084611508, 4: 0.0199012084611508, 5: 0.0199012084611508, 6: 0.0199012084611508, 7: 0.0199012084611508, 8: 0.0199012084611508, 9: 0.0199012084611508, 10: 0.0199012084611508, 11: 0.0199012084611508, 12: 0.0199012084611508, 13: 0.0199012084611508, 14: 0.0199012084611508, 15: 0.0199012084611508, 16: 0.0199012084611508, 17: 0.0199012084611508, 18: 0.0199012084611508, 19: 0.0199012084611508, 20: 0.0199012084611508, 21: 0.0199012084611508, 22: 0.0199012084611508, 23: 0.0199012084611508, 24: 0.0199012084611508, 25: 0.0199012084611508, 26: 0.0199012084611508, 27: 0.0199012084611508, 28: 0.0199012084611508, 29: 0.0199012084611508, 1: 0.0199012084611508}\n"
     ]
    }
   ],
   "source": [
    "s = make_innat_opinions(n)\n",
    "G = make_random_network(n)\n",
    "nxG = nx.from_numpy_matrix(G) \n",
    "\n",
    "v1 = 1\n",
    "max_opinon=0\n",
    "\n",
    "a = actual_rank(s, n, v1, max_opinion)\n",
    "\n",
    "L = scipy.sparse.csgraph.laplacian(G, normed=False)  # Return the Laplacian matrix\n",
    "A = np.linalg.inv(np.identity(n) + L)  # A = (I + L)^(-1)\\n  Stanford paper theory\n",
    "op = copy.copy(s)\n",
    "op[v1] = max_opinion\n",
    "\n",
    "all_1 = list(range(n))    # for all agent \n",
    "C1 = [x for x in all_1 if x != v1]  # for the vertice that Maximizer has not touched\n",
    "innat_por = obj_polarization(A, s, n) # Calculate the polarization after maximzer' action - not innate polarization\n",
    "max_por = obj_polarization(A, op, n)\n",
    "results = []\n",
    "real_por1 = []\n",
    "for v2 in C1:   \n",
    "    (changed_opinion, por) = derivate_s(op,n,v2,A)   # find the best new_op option  \n",
    "    por_1 = por - max_por     # append the change of the polarization\n",
    "    results.append((v2, por_1))\n",
    "    real_por1.append((v2,innat_por))\n",
    "results.append((v1,0)) # minimizer cannot choose v1, but we need all nodes for the dataframe\n",
    "real_por1.append((v1,innat_por))\n",
    "\n",
    "innate_por_dict = dict(real_por1)\n",
    "#     actual_por_dict = dict(sorted(actual_por.items(), key=lambda x:x[0]))  \n",
    "\n",
    "actual_Y = dict(results) # now we have - node:polarization\n",
    "# most of v are in sequential order, but v1 might not be in order, so we need to sort it\n",
    "actual_Y_dict = dict(sorted(actual_Y.items(), key=lambda x:x[0]))   #sort - list nodes in sequential of the node index\n",
    "actual_Y_dict_scale = rescale(actual_Y_dict)\n",
    "# dictionary -  node:polarization\n",
    "# print(\"actual_Y_dict\",actual_Y_dict) \n",
    "\n",
    "# create the rank of the Y values based on minimizer's choice \n",
    "actual_Y_order = dict(sorted(actual_Y.items(), key=lambda x:x[1]))  #sort - list nodes in sequential of the polariz.\n",
    "node_ranks= dict(zip(actual_Y_order.keys(), all_1)) # dictionary -  node:polarization rank(replace polarz. with rank)\n",
    "actual_ranks = dict(sorted(node_ranks.items(), key=lambda x:x[0])) # sort - list node in sequential node index\n",
    "\n",
    "print(innate_por_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765bdc3f",
   "metadata": {},
   "source": [
    "# Creat Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d082fdf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.8271169432403425 changed to 1\n",
      "Min Action:    Agent28 's opinion 0.9818570498263892 changed to 0.38568203917047145\n",
      "Network reaches equilibrium Polarization: 0.026435826468651332\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent28 's opinion 0.6727456898053966 changed to 0\n",
      "Min Action:    Agent27 's opinion 0.11148210456842333 changed to 0.606635519330606\n",
      "Network reaches equilibrium Polarization: 0.014654617855643804\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.3329377219702512 changed to 0\n",
      "Min Action:    Agent25 's opinion 0.9098407479814604 changed to 0.39465692424743093\n",
      "Network reaches equilibrium Polarization: 0.03378731944590402\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent26 's opinion 0.6470613674816937 changed to 0\n",
      "Min Action:    Agent28 's opinion 0.011090595444409379 changed to 0.6327664777676734\n",
      "Network reaches equilibrium Polarization: 0.028263243955166918\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.03993694385668656 changed to 1\n",
      "Min Action:    Agent4 's opinion 0.0023702560990219723 changed to 0.7429914895239706\n",
      "Network reaches equilibrium Polarization: 0.027461800546191267\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.013703020141901057 changed to 1\n",
      "Min Action:    Agent27 's opinion 0.8918789066842939 changed to 0.2218538270033686\n",
      "Network reaches equilibrium Polarization: 0.031359621784663436\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent28 's opinion 0.7240519477661878 changed to 1\n",
      "Min Action:    Agent23 's opinion 0.01085341102772508 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.09869392430612148\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.6935566042486061 changed to 1\n",
      "Min Action:    Agent25 's opinion 0.9577741261520546 changed to 0.3841276491797354\n",
      "Network reaches equilibrium Polarization: 0.019169637030440334\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.50213960237172 changed to 0\n",
      "Min Action:    Agent25 's opinion 0.22913247671793757 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.07174169826035383\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.984333352012565 changed to 1\n",
      "Min Action:    Agent18 's opinion 0.1584519521414497 changed to 0.962681098098616\n",
      "Network reaches equilibrium Polarization: 0.025522145712206536\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.05059817451487014 changed to 0\n",
      "Min Action:    Agent8 's opinion 0.7999154639542767 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.030083610266674596\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.15715960038347743 changed to 0\n",
      "Min Action:    Agent4 's opinion 0.9743345949978193 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.09539430028797147\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.08327956155213045 changed to 0\n",
      "Min Action:    Agent2 's opinion 0.983515997095071 changed to 0\n",
      "Network reaches equilibrium Polarization: 0.07059300237453836\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.4983056208999782 changed to 0\n",
      "Min Action:    Agent23 's opinion 0.9902367530334133 changed to 0.3318585684031658\n",
      "Network reaches equilibrium Polarization: 0.026654915185755888\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent28 's opinion 0.6857076811306712 changed to 1\n",
      "Min Action:    Agent29 's opinion 0.9795347178008879 changed to 0.44551073280183123\n",
      "Network reaches equilibrium Polarization: 0.022925768845841694\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.2840597864890463 changed to 1\n",
      "Min Action:    Agent22 's opinion 0.0382809344445193 changed to 1\n",
      "Network reaches equilibrium Polarization: 0.2310837313447181\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-149-d50152ff2b9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m                        \u001b[1;34m'x3_clo'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclo_cent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                        \u001b[1;34m'x4_eigen'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0meigen_cent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m                        \u001b[1;34m'x5_path'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mMinPaths_sort\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m                        \u001b[1;34m'x6_cc'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m                        \u001b[1;34m'x7_po'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minnate_por_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-149-d50152ff2b9f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     36\u001b[0m                        \u001b[1;34m'x3_clo'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclo_cent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                        \u001b[1;34m'x4_eigen'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0meigen_cent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m                        \u001b[1;34m'x5_path'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mMinPaths_sort\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m                        \u001b[1;34m'x6_cc'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m                        \u001b[1;34m'x7_po'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minnate_por_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize an empty DataFrame to store your data\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Initialize empty lists to store data for training and testing\n",
    "train_data1 = []\n",
    "valid_data1 =[]\n",
    "test_data1 = []\n",
    "Game_result = []\n",
    "sets = 50\n",
    "for i in range(1, sets):  # Change the range if you want more iterations\n",
    "    # Your existing code here to generate data for each iteration\n",
    "    s = make_innat_opinions(n)\n",
    "    G = make_random_network(n)\n",
    "    (v1, v2, max_opinion, min_opinion, max_pol) = MaxMin_play(s, n, G)\n",
    "    Game_result.append((v2,max_pol))\n",
    "    (deg_cent, clo_cent, eigen_cent, MinPaths_sort,op_extre, cc) = metrics(G, v1)\n",
    "   # (converted_dict, converted_dict1, converted_dict2, sorted_gap, scaled_MinPaths_sort) = metrics(G, v1)\n",
    "    \n",
    "    # Calculate actual ranks and rescale polarization change\n",
    "    (actual_Y_dict, actual_ranks, innate_por_dict) = actual_rank(s, n, v1, max_opinion)\n",
    "    # rescale\n",
    "    scaled_actual_Y_dict = rescale(actual_Y_dict)\n",
    "    \n",
    "    keys = list(eigen_cent.keys())\n",
    "    # Assuming you have generated 'temp_df' as you did in your original code\n",
    "    temp_df = pd.DataFrame(({'keys': list(keys),\n",
    "                       'x1_d': [op_extre[x][0] for x in keys],\n",
    "                       'x2_deg':[deg_cent[x] for x in keys],\n",
    "                       'x3_clo':[clo_cent[x] for x in keys],\n",
    "                       'x4_eigen': [eigen_cent[x] for x in keys],\n",
    "                       'x5_path': [MinPaths_sort[x] for x in keys],\n",
    "                       'x6_cc': [cc[x] for x in keys],\n",
    "                       'x7_po':[innate_por_dict[x] for x in keys],\n",
    "                       'y_value': [scaled_actual_Y_dict[x] for x in keys],\n",
    "                        'ranks_y':[actual_ranks[x] for x in keys]}))\n",
    "\n",
    "    # Append the temporary DataFrame to the main DataFrame\n",
    "    df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "    # Append the data to either the training or testing list\n",
    "    if i <= 0.8*sets:  # Use first 80% for trainning, adjust as needed\n",
    "        train_data1.append(temp_df)\n",
    "    elif i> 0.8*sets and i <= 0.9*sets:\n",
    "        valid_data1.append(temp_df)\n",
    "    else:\n",
    "        test_data1.append(temp_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a7dc28d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    keys      x1_d    x2_deg    x3_clo  x4_eigen  x5_path     x6_cc     x7_po  \\\n",
      "0      0  0.409759  0.586207  0.707317  0.213151        3  0.602941  0.022199   \n",
      "1      1  0.091998  0.551724  0.690476  0.208540        3  0.700000  0.022199   \n",
      "2      2  0.049089  0.482759  0.659091  0.175780        3  0.615385  0.022199   \n",
      "3      3  0.086069  0.482759  0.644444  0.179630        3  0.648352  0.022199   \n",
      "4      4  0.241757  0.482759  0.659091  0.179451        3  0.626374  0.022199   \n",
      "5      5  0.382713  0.586207  0.707317  0.202908        2  0.551471  0.022199   \n",
      "6      6  0.405771  0.586207  0.707317  0.218452        3  0.676471  0.022199   \n",
      "7      7  0.189462  0.551724  0.690476  0.197418        3  0.583333  0.022199   \n",
      "8      8  0.396780  0.655172  0.743590  0.232277        3  0.573099  0.022199   \n",
      "9      9  0.087578  0.551724  0.690476  0.213541        3  0.750000  0.022199   \n",
      "10    10  0.187189  0.551724  0.690476  0.200341        3  0.566667  0.022199   \n",
      "11    11  0.162554  0.517241  0.659091  0.193938        4  0.657143  0.022199   \n",
      "12    12  0.092042  0.620690  0.725000  0.228067        3  0.633987  0.022199   \n",
      "13    13  0.367411  0.620690  0.725000  0.231304        3  0.660131  0.022199   \n",
      "14    14  0.058270  0.689655  0.763158  0.239030        3  0.547368  0.022199   \n",
      "15    15  0.329343  0.586207  0.707317  0.219707        3  0.654412  0.022199   \n",
      "16    16  0.335583  0.586207  0.707317  0.210081        3  0.588235  0.022199   \n",
      "17    17  0.016866  0.689655  0.763158  0.248116        3  0.600000  0.022199   \n",
      "18    18  0.288217  0.448276  0.630435  0.161893        4  0.589744  0.022199   \n",
      "19    19  0.054783  0.482759  0.644444  0.181155        4  0.670330  0.022199   \n",
      "20    20  0.202172  0.551724  0.690476  0.184611        3  0.525000  0.022199   \n",
      "21    21  0.436035  0.413793  0.630435  0.124618        3  0.409091  0.022199   \n",
      "22    22  0.250496  0.448276  0.644444  0.138496        3  0.461538  0.022199   \n",
      "23    23  0.392697  0.551724  0.690476  0.162406        3  0.450000  0.022199   \n",
      "24    24  0.009065  0.344828  0.604167  0.093811        3  0.422222  0.022199   \n",
      "25    25  0.327951  0.344828  0.604167  0.088045        3  0.577778  0.022199   \n",
      "26    26  0.523586  0.275862  0.580000  0.067265        3  0.678571  0.022199   \n",
      "27    27  0.306558  0.448276  0.644444  0.124468        2  0.384615  0.022199   \n",
      "28    28  0.454822  0.241379  0.557692  0.050845        2  0.380952  0.022199   \n",
      "29    29  0.300082  0.103448  0.500000  0.023976        1  0.333333  0.022199   \n",
      "\n",
      "     y_value  ranks_y  \n",
      "0   0.989553       25  \n",
      "1   0.829915       10  \n",
      "2   0.952459       19  \n",
      "3   0.926710       17  \n",
      "4   0.726142        5  \n",
      "5   0.985247       23  \n",
      "6   0.524708        2  \n",
      "7   0.799457        9  \n",
      "8   0.973424       21  \n",
      "9   0.864395       12  \n",
      "10  0.761393        6  \n",
      "11  0.762347        7  \n",
      "12  0.965324       20  \n",
      "13  0.705555        4  \n",
      "14  0.881197       14  \n",
      "15  0.978433       22  \n",
      "16  0.986244       24  \n",
      "17  0.864485       13  \n",
      "18  0.996315       27  \n",
      "19  0.935663       18  \n",
      "20  0.905704       15  \n",
      "21  0.180692        1  \n",
      "22  0.912781       16  \n",
      "23  0.997963       28  \n",
      "24  0.993417       26  \n",
      "25  0.844327       11  \n",
      "26  0.604119        3  \n",
      "27  0.769714        8  \n",
      "28  0.000000        0  \n",
      "29  1.000000       29  ,     keys      x1_d    x2_deg    x3_clo  x4_eigen  x5_path     x6_cc     x7_po  \\\n",
      "0      0  0.319935  0.517241  0.674419  0.193250        3  0.600000  0.011674   \n",
      "1      1  0.133610  0.482759  0.630435  0.184458        4  0.659341  0.011674   \n",
      "2      2  0.416431  0.413793  0.604167  0.162869        4  0.712121  0.011674   \n",
      "3      3  0.219088  0.448276  0.644444  0.167987        3  0.615385  0.011674   \n",
      "4      4  0.363660  0.551724  0.690476  0.205148        3  0.608333  0.011674   \n",
      "5      5  0.227295  0.482759  0.644444  0.187213        3  0.659341  0.011674   \n",
      "6      6  0.142826  0.551724  0.690476  0.210534        3  0.616667  0.011674   \n",
      "7      7  0.369963  0.655172  0.743590  0.236846        3  0.543860  0.011674   \n",
      "8      8  0.251288  0.551724  0.690476  0.205763        3  0.600000  0.011674   \n",
      "9      9  0.343407  0.551724  0.690476  0.209092        3  0.616667  0.011674   \n",
      "10    10  0.333782  0.724138  0.783784  0.266344        3  0.590476  0.011674   \n",
      "11    11  0.238266  0.655172  0.743590  0.242554        3  0.619883  0.011674   \n",
      "12    12  0.241253  0.482759  0.659091  0.176597        2  0.560440  0.011674   \n",
      "13    13  0.257074  0.448276  0.617021  0.173467        3  0.641026  0.011674   \n",
      "14    14  0.034302  0.586207  0.707317  0.221969        3  0.632353  0.011674   \n",
      "15    15  0.025212  0.655172  0.743590  0.234375        3  0.549708  0.011674   \n",
      "16    16  0.216631  0.517241  0.674419  0.191282        3  0.561905  0.011674   \n",
      "17    17  0.179219  0.586207  0.707317  0.220541        3  0.625000  0.011674   \n",
      "18    18  0.126411  0.517241  0.674419  0.172078        3  0.485714  0.011674   \n",
      "19    19  0.383140  0.551724  0.690476  0.201861        3  0.583333  0.011674   \n",
      "20    20  0.209109  0.517241  0.674419  0.179695        3  0.495238  0.011674   \n",
      "21    21  0.296070  0.482759  0.659091  0.153386        3  0.494505  0.011674   \n",
      "22    22  0.019096  0.482759  0.659091  0.168229        3  0.571429  0.011674   \n",
      "23    23  0.205374  0.413793  0.630435  0.136334        3  0.484848  0.011674   \n",
      "24    24  0.000183  0.448276  0.644444  0.140882        2  0.371795  0.011674   \n",
      "25    25  0.237597  0.517241  0.674419  0.154460        2  0.400000  0.011674   \n",
      "26    26  0.168806  0.275862  0.580000  0.083249        3  0.571429  0.011674   \n",
      "27    27  0.442749  0.241379  0.557692  0.050713        2  0.428571  0.011674   \n",
      "28    28  0.118515  0.172414  0.527273  0.037051        1  0.500000  0.011674   \n",
      "29    29  0.321902  0.206897  0.517857  0.046340        2  0.600000  0.011674   \n",
      "\n",
      "     y_value  ranks_y  \n",
      "0   0.983086       24  \n",
      "1   0.888105       12  \n",
      "2   0.974135       20  \n",
      "3   0.860016       10  \n",
      "4   0.620273        2  \n",
      "5   0.721675        6  \n",
      "6   0.952611       16  \n",
      "7   0.714183        5  \n",
      "8   0.615669        1  \n",
      "9   0.987287       25  \n",
      "10  0.972936       19  \n",
      "11  0.937510       14  \n",
      "12  0.980180       23  \n",
      "13  0.999542       27  \n",
      "14  0.838061        9  \n",
      "15  0.941885       15  \n",
      "16  0.702286        4  \n",
      "17  0.788446        7  \n",
      "18  0.908221       13  \n",
      "19  0.999650       28  \n",
      "20  0.641108        3  \n",
      "21  0.959177       18  \n",
      "22  0.958203       17  \n",
      "23  0.877526       11  \n",
      "24  0.974310       21  \n",
      "25  0.993651       26  \n",
      "26  0.831221        8  \n",
      "27  0.000000        0  \n",
      "28  1.000000       29  \n",
      "29  0.974341       22  ,     keys      x1_d    x2_deg    x3_clo  x4_eigen  x5_path     x6_cc    x7_po  \\\n",
      "0      0  0.170229  0.551724  0.690476  0.204898        3  0.633333  0.02117   \n",
      "1      1  0.387560  0.482759  0.659091  0.185770        3  0.670330  0.02117   \n",
      "2      2  0.370136  0.413793  0.630435  0.163802        3  0.727273  0.02117   \n",
      "3      3  0.458782  0.344828  0.604167  0.120989        3  0.577778  0.02117   \n",
      "4      4  0.266924  0.689655  0.763158  0.236870        2  0.531579  0.02117   \n",
      "5      5  0.246012  0.655172  0.743590  0.238620        3  0.602339  0.02117   \n",
      "6      6  0.235419  0.482759  0.659091  0.187335        3  0.725275  0.02117   \n",
      "7      7  0.409995  0.551724  0.690476  0.196231        3  0.566667  0.02117   \n",
      "8      8  0.312390  0.620690  0.725000  0.225855        3  0.594771  0.02117   \n",
      "9      9  0.391101  0.586207  0.707317  0.212465        2  0.602941  0.02117   \n",
      "10    10  0.269962  0.551724  0.690476  0.190997        3  0.533333  0.02117   \n",
      "11    11  0.329826  0.655172  0.743590  0.230185        2  0.561404  0.02117   \n",
      "12    12  0.281174  0.724138  0.783784  0.247501        3  0.523810  0.02117   \n",
      "13    13  0.221003  0.517241  0.674419  0.204145        3  0.742857  0.02117   \n",
      "14    14  0.242359  0.551724  0.690476  0.206904        3  0.658333  0.02117   \n",
      "15    15  0.085797  0.758621  0.805556  0.271201        3  0.597403  0.02117   \n",
      "16    16  0.256026  0.517241  0.674419  0.194090        3  0.638095  0.02117   \n",
      "17    17  0.196701  0.413793  0.617021  0.148947        3  0.575758  0.02117   \n",
      "18    18  0.010624  0.586207  0.707317  0.206886        3  0.536765  0.02117   \n",
      "19    19  0.409860  0.551724  0.690476  0.203764        3  0.616667  0.02117   \n",
      "20    20  0.300867  0.586207  0.707317  0.193928        3  0.507353  0.02117   \n",
      "21    21  0.071421  0.413793  0.617021  0.136429        4  0.515152  0.02117   \n",
      "22    22  0.432304  0.448276  0.630435  0.153370        4  0.564103  0.02117   \n",
      "23    23  0.058533  0.413793  0.630435  0.128035        3  0.393939  0.02117   \n",
      "24    24  0.023405  0.482759  0.659091  0.159030        3  0.494505  0.02117   \n",
      "25    25  0.373152  0.241379  0.557692  0.064128        4  0.476190  0.02117   \n",
      "26    26  0.376166  0.344828  0.604167  0.101563        3  0.422222  0.02117   \n",
      "27    27  0.195695  0.275862  0.580000  0.082061        3  0.500000  0.02117   \n",
      "28    28  0.299687  0.172414  0.527273  0.042922        4  0.300000  0.02117   \n",
      "29    29  0.203751  0.103448  0.491525  0.043280        1  1.000000  0.02117   \n",
      "\n",
      "     y_value  ranks_y  \n",
      "0   0.828163       18  \n",
      "1   0.983380       26  \n",
      "2   0.592486        9  \n",
      "3   0.696536       12  \n",
      "4   0.990263       27  \n",
      "5   0.654112       10  \n",
      "6   0.886873       20  \n",
      "7   0.889806       21  \n",
      "8   0.533528        7  \n",
      "9   0.492220        5  \n",
      "10  0.869883       19  \n",
      "11  0.814373       17  \n",
      "12  0.896543       22  \n",
      "13  0.969961       24  \n",
      "14  0.668789       11  \n",
      "15  0.712333       13  \n",
      "16  0.998182       28  \n",
      "17  0.499843        6  \n",
      "18  0.813652       16  \n",
      "19  0.980432       25  \n",
      "20  0.269205        2  \n",
      "21  0.712553       14  \n",
      "22  0.047651        1  \n",
      "23  0.801780       15  \n",
      "24  0.442473        4  \n",
      "25  0.000000        0  \n",
      "26  0.908928       23  \n",
      "27  0.338455        3  \n",
      "28  0.536778        8  \n",
      "29  1.000000       29  ,     keys      x1_d    x2_deg    x3_clo  x4_eigen  x5_path     x6_cc     x7_po  \\\n",
      "0      0  0.466235  0.379310  0.617021  0.158228        3  0.818182  0.036228   \n",
      "1      1  0.159872  0.517241  0.674419  0.197814        2  0.628571  0.036228   \n",
      "2      2  0.049909  0.517241  0.674419  0.197819        3  0.638095  0.036228   \n",
      "3      3  0.329486  0.551724  0.690476  0.209315        3  0.641667  0.036228   \n",
      "4      4  0.382234  0.482759  0.630435  0.186872        3  0.659341  0.036228   \n",
      "5      5  0.424412  0.620690  0.707317  0.225508        3  0.549020  0.036228   \n",
      "6      6  0.287533  0.689655  0.763158  0.256160        2  0.600000  0.036228   \n",
      "7      7  0.280723  0.551724  0.690476  0.211682        3  0.625000  0.036228   \n",
      "8      8  0.154528  0.586207  0.690476  0.213715        3  0.566176  0.036228   \n",
      "9      9  0.055392  0.620690  0.725000  0.231768        3  0.594771  0.036228   \n",
      "10    10  0.479793  0.517241  0.674419  0.191852        3  0.552381  0.036228   \n",
      "11    11  0.106119  0.517241  0.674419  0.190992        3  0.561905  0.036228   \n",
      "12    12  0.275058  0.551724  0.690476  0.204329        2  0.566667  0.036228   \n",
      "13    13  0.511320  0.586207  0.707317  0.218982        3  0.595588  0.036228   \n",
      "14    14  0.064952  0.689655  0.763158  0.241952        3  0.521053  0.036228   \n",
      "15    15  0.077861  0.413793  0.630435  0.158772        3  0.636364  0.036228   \n",
      "16    16  0.407307  0.517241  0.674419  0.191521        3  0.561905  0.036228   \n",
      "17    17  0.160016  0.689655  0.763158  0.242161        3  0.510526  0.036228   \n",
      "18    18  0.349925  0.551724  0.690476  0.191785        3  0.516667  0.036228   \n",
      "19    19  0.515945  0.413793  0.630435  0.157977        3  0.651515  0.036228   \n",
      "20    20  0.276807  0.413793  0.630435  0.168177        3  0.696970  0.036228   \n",
      "21    21  0.255626  0.551724  0.690476  0.179844        2  0.458333  0.036228   \n",
      "22    22  0.101823  0.413793  0.630435  0.123323        2  0.409091  0.036228   \n",
      "23    23  0.157765  0.379310  0.617021  0.129232        2  0.545455  0.036228   \n",
      "24    24  0.433531  0.482759  0.659091  0.158108        2  0.494505  0.036228   \n",
      "25    25  0.324677  0.448276  0.644444  0.133055        2  0.461538  0.036228   \n",
      "26    26  0.194759  0.379310  0.617021  0.099868        1  0.400000  0.036228   \n",
      "27    27  0.429635  0.275862  0.580000  0.075986        2  0.535714  0.036228   \n",
      "28    28  0.441211  0.137931  0.517857  0.036000        2  0.500000  0.036228   \n",
      "29    29  0.365928  0.103448  0.508772  0.034859        2  0.333333  0.036228   \n",
      "\n",
      "     y_value  ranks_y  \n",
      "0   0.654913        6  \n",
      "1   0.947313       19  \n",
      "2   0.862518       14  \n",
      "3   0.968850       23  \n",
      "4   0.979828       24  \n",
      "5   0.990326       25  \n",
      "6   0.951373       21  \n",
      "7   0.950171       20  \n",
      "8   0.771729        9  \n",
      "9   0.824903       11  \n",
      "10  0.627396        4  \n",
      "11  0.889035       15  \n",
      "12  0.736709        8  \n",
      "13  0.648220        5  \n",
      "14  0.960402       22  \n",
      "15  0.861415       13  \n",
      "16  0.777799       10  \n",
      "17  0.938090       17  \n",
      "18  0.999708       28  \n",
      "19  0.617101        3  \n",
      "20  0.688951        7  \n",
      "21  0.946880       18  \n",
      "22  0.997665       26  \n",
      "23  0.999553       27  \n",
      "24  0.935428       16  \n",
      "25  0.837844       12  \n",
      "26  1.000000       29  \n",
      "27  0.545866        2  \n",
      "28  0.000000        0  \n",
      "29  0.271571        1  ,     keys      x1_d    x2_deg    x3_clo  x4_eigen  x5_path     x6_cc     x7_po  \\\n",
      "0      0  0.008730  0.517241  0.674419  0.175915        3  0.685714  0.011832   \n",
      "1      1  0.205542  0.620690  0.725000  0.207488        3  0.647059  0.011832   \n",
      "2      2  0.074701  0.517241  0.674419  0.169274        3  0.609524  0.011832   \n",
      "3      3  0.035076  0.586207  0.707317  0.191564        3  0.588235  0.011832   \n",
      "4      4  0.368206  0.517241  0.659091  0.174720        4  0.647619  0.011832   \n",
      "5      5  0.431494  0.586207  0.707317  0.202348        3  0.698529  0.011832   \n",
      "6      6  0.206639  0.586207  0.707317  0.189820        3  0.595588  0.011832   \n",
      "7      7  0.028745  0.758621  0.805556  0.235614        2  0.554113  0.011832   \n",
      "8      8  0.155920  0.620690  0.725000  0.213150        3  0.679739  0.011832   \n",
      "9      9  0.006988  0.551724  0.690476  0.186559        3  0.691667  0.011832   \n",
      "10    10  0.402136  0.689655  0.763158  0.232682        3  0.657895  0.011832   \n",
      "11    11  0.237627  0.724138  0.783784  0.235707        3  0.609524  0.011832   \n",
      "12    12  0.090529  0.586207  0.707317  0.190419        3  0.595588  0.011832   \n",
      "13    13  0.320211  0.448276  0.644444  0.159076        3  0.717949  0.011832   \n",
      "14    14  0.248041  0.689655  0.763158  0.224514        3  0.610526  0.011832   \n",
      "15    15  0.197694  0.448276  0.644444  0.152182        3  0.589744  0.011832   \n",
      "16    16  0.012847  0.517241  0.674419  0.166703        3  0.600000  0.011832   \n",
      "17    17  0.166308  0.724138  0.783784  0.225474        3  0.552381  0.011832   \n",
      "18    18  0.022311  0.620690  0.725000  0.200451        2  0.614379  0.011832   \n",
      "19    19  0.262147  0.655172  0.743590  0.211353        3  0.596491  0.011832   \n",
      "20    20  0.204895  0.551724  0.690476  0.180009        3  0.625000  0.011832   \n",
      "21    21  0.226359  0.620690  0.725000  0.186855        3  0.509804  0.011832   \n",
      "22    22  0.168041  0.620690  0.725000  0.192279        2  0.568627  0.011832   \n",
      "23    23  0.275212  0.482759  0.659091  0.152663        3  0.560440  0.011832   \n",
      "24    24  0.325237  0.655172  0.743590  0.215135        3  0.625731  0.011832   \n",
      "25    25  0.270894  0.413793  0.630435  0.125339        3  0.515152  0.011832   \n",
      "26    26  0.109643  0.310345  0.591837  0.094674        3  0.583333  0.011832   \n",
      "27    27  0.112568  0.241379  0.568627  0.071929        3  0.523810  0.011832   \n",
      "28    28  0.113006  0.241379  0.557692  0.063116        4  0.428571  0.011832   \n",
      "29    29  0.330639  0.103448  0.508772  0.037148        1  1.000000  0.011832   \n",
      "\n",
      "     y_value  ranks_y  \n",
      "0   0.802687       19  \n",
      "1   0.465737        8  \n",
      "2   0.421203        5  \n",
      "3   0.725506       15  \n",
      "4   0.000000        0  \n",
      "5   0.995464       27  \n",
      "6   0.852803       20  \n",
      "7   0.881331       21  \n",
      "8   0.700535       14  \n",
      "9   0.735713       17  \n",
      "10  0.969640       23  \n",
      "11  0.405576        4  \n",
      "12  0.676555       13  \n",
      "13  0.990243       26  \n",
      "14  0.626611       12  \n",
      "15  0.461250        7  \n",
      "16  0.762688       18  \n",
      "17  0.188693        3  \n",
      "18  0.728459       16  \n",
      "19  0.920096       22  \n",
      "20  0.496381        9  \n",
      "21  0.170092        2  \n",
      "22  0.577614       10  \n",
      "23  0.973901       24  \n",
      "24  0.983122       25  \n",
      "25  0.999785       28  \n",
      "26  0.596342       11  \n",
      "27  0.442998        6  \n",
      "28  0.151397        1  \n",
      "29  1.000000       29  ,     keys      x1_d    x2_deg    x3_clo  x4_eigen  x5_path     x6_cc     x7_po  \\\n",
      "0      0  0.412723  0.482759  0.644444  0.180652        4  0.659341  0.025308   \n",
      "1      1  0.107953  0.448276  0.617021  0.175782        4  0.679487  0.025308   \n",
      "2      2  0.191523  0.551724  0.674419  0.217120        4  0.733333  0.025308   \n",
      "3      3  0.478413  0.586207  0.690476  0.230676        4  0.727941  0.025308   \n",
      "4      4  0.039461  0.448276  0.617021  0.179658        4  0.743590  0.025308   \n",
      "5      5  0.067101  0.448276  0.630435  0.165115        4  0.589744  0.025308   \n",
      "6      6  0.090798  0.586207  0.707317  0.218079        3  0.617647  0.025308   \n",
      "7      7  0.278503  0.482759  0.644444  0.185576        4  0.714286  0.025308   \n",
      "8      8  0.187169  0.551724  0.674419  0.216739        4  0.725000  0.025308   \n",
      "9      9  0.047402  0.517241  0.659091  0.210273        4  0.752381  0.025308   \n",
      "10    10  0.213799  0.655172  0.743590  0.240024        3  0.596491  0.025308   \n",
      "11    11  0.036819  0.655172  0.743590  0.247352        3  0.643275  0.025308   \n",
      "12    12  0.427569  0.586207  0.707317  0.215004        3  0.595588  0.025308   \n",
      "13    13  0.076940  0.517241  0.674419  0.202408        3  0.685714  0.025308   \n",
      "14    14  0.166801  0.655172  0.743590  0.237286        3  0.561404  0.025308   \n",
      "15    15  0.150728  0.482759  0.659091  0.179528        3  0.582418  0.025308   \n",
      "16    16  0.257700  0.758621  0.805556  0.270001        3  0.567100  0.025308   \n",
      "17    17  0.370643  0.344828  0.591837  0.115849        4  0.555556  0.025308   \n",
      "18    18  0.439863  0.758621  0.805556  0.263871        3  0.541126  0.025308   \n",
      "19    19  0.314704  0.413793  0.630435  0.140959        3  0.560606  0.025308   \n",
      "20    20  0.145164  0.586207  0.707317  0.207330        3  0.588235  0.025308   \n",
      "21    21  0.351900  0.413793  0.630435  0.141932        2  0.560606  0.025308   \n",
      "22    22  0.205418  0.482759  0.659091  0.158910        3  0.494505  0.025308   \n",
      "23    23  0.365492  0.379310  0.617021  0.126218        3  0.581818  0.025308   \n",
      "24    24  0.011796  0.344828  0.604167  0.099342        3  0.355556  0.025308   \n",
      "25    25  0.408626  0.344828  0.604167  0.087290        2  0.377778  0.025308   \n",
      "26    26  0.081834  0.275862  0.580000  0.073517        3  0.428571  0.025308   \n",
      "27    27  0.446281  0.241379  0.557692  0.056786        2  0.333333  0.025308   \n",
      "28    28  0.353126  0.172414  0.527273  0.047636        4  0.400000  0.025308   \n",
      "29    29  0.431895  0.103448  0.439394  0.018457        1  0.666667  0.025308   \n",
      "\n",
      "     y_value  ranks_y  \n",
      "0   0.550093        4  \n",
      "1   0.962167       20  \n",
      "2   0.714300        7  \n",
      "3   0.992305       26  \n",
      "4   0.923363       15  \n",
      "5   0.883470       10  \n",
      "6   0.890538       11  \n",
      "7   0.892373       12  \n",
      "8   0.933869       17  \n",
      "9   0.938610       18  \n",
      "10  0.989780       25  \n",
      "11  0.910256       13  \n",
      "12  0.996137       28  \n",
      "13  0.996081       27  \n",
      "14  0.785107        8  \n",
      "15  0.973728       22  \n",
      "16  0.666590        6  \n",
      "17  0.924035       16  \n",
      "18  0.521509        2  \n",
      "19  0.620677        5  \n",
      "20  0.921189       14  \n",
      "21  0.529576        3  \n",
      "22  0.966526       21  \n",
      "23  0.984650       23  \n",
      "24  0.945226       19  \n",
      "25  0.987987       24  \n",
      "26  0.821326        9  \n",
      "27  0.000000        0  \n",
      "28  0.135317        1  \n",
      "29  1.000000       29  ,     keys      x1_d    x2_deg    x3_clo  x4_eigen  x5_path     x6_cc    x7_po  \\\n",
      "0      0  0.020565  0.551724  0.690476  0.207382        2  0.566667  0.05305   \n",
      "1      1  0.241111  0.448276  0.644444  0.170787        3  0.602564  0.05305   \n",
      "2      2  0.012412  0.448276  0.617021  0.177249        3  0.641026  0.05305   \n",
      "3      3  0.307151  0.551724  0.674419  0.216868        3  0.616667  0.05305   \n",
      "4      4  0.188292  0.482759  0.644444  0.197129        3  0.681319  0.05305   \n",
      "5      5  0.374663  0.586207  0.707317  0.227826        3  0.595588  0.05305   \n",
      "6      6  0.212027  0.482759  0.644444  0.194656        3  0.703297  0.05305   \n",
      "7      7  0.486907  0.517241  0.674419  0.198757        3  0.571429  0.05305   \n",
      "8      8  0.388971  0.655172  0.743590  0.245266        3  0.573099  0.05305   \n",
      "9      9  0.313625  0.379310  0.604167  0.144428        4  0.545455  0.05305   \n",
      "10    10  0.378552  0.620690  0.725000  0.242040        3  0.607843  0.05305   \n",
      "11    11  0.289406  0.586207  0.707317  0.211166        3  0.514706  0.05305   \n",
      "12    12  0.185427  0.586207  0.707317  0.220678        3  0.529412  0.05305   \n",
      "13    13  0.346073  0.517241  0.659091  0.197552        4  0.590476  0.05305   \n",
      "14    14  0.044556  0.586207  0.690476  0.222249        4  0.566176  0.05305   \n",
      "15    15  0.265001  0.551724  0.674419  0.219585        4  0.625000  0.05305   \n",
      "16    16  0.323588  0.517241  0.674419  0.204583        3  0.619048  0.05305   \n",
      "17    17  0.389782  0.482759  0.644444  0.177892        4  0.549451  0.05305   \n",
      "18    18  0.118373  0.448276  0.644444  0.168526        3  0.589744  0.05305   \n",
      "19    19  0.140868  0.482759  0.644444  0.171859        4  0.483516  0.05305   \n",
      "20    20  0.191806  0.724138  0.783784  0.261414        3  0.519048  0.05305   \n",
      "21    21  0.065156  0.413793  0.617021  0.158802        4  0.545455  0.05305   \n",
      "22    22  0.370859  0.413793  0.617021  0.147700        4  0.469697  0.05305   \n",
      "23    23  0.421363  0.379310  0.604167  0.118486        4  0.418182  0.05305   \n",
      "24    24  0.394745  0.448276  0.644444  0.145181        3  0.487179  0.05305   \n",
      "25    25  0.379003  0.413793  0.617021  0.144688        4  0.500000  0.05305   \n",
      "26    26  0.046186  0.241379  0.557692  0.071960        4  0.333333  0.05305   \n",
      "27    27  0.030816  0.206897  0.517857  0.051128        4  0.400000  0.05305   \n",
      "28    28  0.291835  0.034483  0.414286  0.013891        1  0.000000  0.05305   \n",
      "29    29  0.526401  0.103448  0.500000  0.029081        4  0.333333  0.05305   \n",
      "\n",
      "     y_value  ranks_y  \n",
      "0   0.828522       20  \n",
      "1   0.482083       12  \n",
      "2   0.597814       15  \n",
      "3   0.834258       21  \n",
      "4   0.545482       14  \n",
      "5   0.329220        7  \n",
      "6   0.802079       19  \n",
      "7   0.953138       27  \n",
      "8   0.267811        4  \n",
      "9   0.330011        8  \n",
      "10  0.870946       25  \n",
      "11  0.918068       26  \n",
      "12  0.753998       18  \n",
      "13  0.835283       22  \n",
      "14  0.531054       13  \n",
      "15  0.313971        5  \n",
      "16  0.854649       23  \n",
      "17  0.193895        3  \n",
      "18  0.447881       10  \n",
      "19  0.676080       16  \n",
      "20  0.373220        9  \n",
      "21  0.481109       11  \n",
      "22  0.868362       24  \n",
      "23  0.000000        0  \n",
      "24  0.325190        6  \n",
      "25  0.180269        2  \n",
      "26  0.725382       17  \n",
      "27  0.991990       28  \n",
      "28  1.000000       29  \n",
      "29  0.094136        1  ,     keys      x1_d    x2_deg    x3_clo  x4_eigen  x5_path     x6_cc     x7_po  \\\n",
      "0      0  0.136216  0.517241  0.674419  0.185431        3  0.609524  0.013593   \n",
      "1      1  0.117039  0.551724  0.690476  0.207590        3  0.708333  0.013593   \n",
      "2      2  0.046695  0.620690  0.725000  0.217257        3  0.562092  0.013593   \n",
      "3      3  0.105196  0.517241  0.674419  0.188131        3  0.609524  0.013593   \n",
      "4      4  0.316014  0.586207  0.707317  0.214913        3  0.654412  0.013593   \n",
      "5      5  0.361610  0.517241  0.674419  0.191222        3  0.676190  0.013593   \n",
      "6      6  0.099417  0.655172  0.743590  0.239925        3  0.649123  0.013593   \n",
      "7      7  0.013545  0.551724  0.690476  0.198527        3  0.625000  0.013593   \n",
      "8      8  0.078303  0.551724  0.690476  0.207604        3  0.666667  0.013593   \n",
      "9      9  0.086864  0.655172  0.743590  0.234011        2  0.614035  0.013593   \n",
      "10    10  0.072302  0.620690  0.725000  0.211618        2  0.535948  0.013593   \n",
      "11    11  0.057478  0.689655  0.763158  0.240635        3  0.573684  0.013593   \n",
      "12    12  0.311378  0.551724  0.674419  0.208075        3  0.683333  0.013593   \n",
      "13    13  0.280617  0.586207  0.707317  0.219951        3  0.683824  0.013593   \n",
      "14    14  0.270142  0.517241  0.674419  0.195034        3  0.666667  0.013593   \n",
      "15    15  0.382960  0.413793  0.630435  0.151653        3  0.606061  0.013593   \n",
      "16    16  0.050016  0.689655  0.763158  0.241835        3  0.584211  0.013593   \n",
      "17    17  0.554351  0.586207  0.707317  0.203967        3  0.558824  0.013593   \n",
      "18    18  0.130934  0.448276  0.644444  0.146234        3  0.474359  0.013593   \n",
      "19    19  0.375911  0.586207  0.707317  0.184824        2  0.463235  0.013593   \n",
      "20    20  0.166188  0.517241  0.674419  0.175851        3  0.533333  0.013593   \n",
      "21    21  0.481802  0.655172  0.743590  0.199486        3  0.491228  0.013593   \n",
      "22    22  0.366333  0.448276  0.644444  0.142106        3  0.500000  0.013593   \n",
      "23    23  0.056301  0.448276  0.644444  0.144656        3  0.525641  0.013593   \n",
      "24    24  0.010125  0.448276  0.644444  0.124299        3  0.423077  0.013593   \n",
      "25    25  0.397301  0.310345  0.591837  0.084080        2  0.388889  0.013593   \n",
      "26    26  0.405857  0.275862  0.580000  0.077746        3  0.642857  0.013593   \n",
      "27    27  0.319325  0.206897  0.547170  0.053254        3  0.666667  0.013593   \n",
      "28    28  0.285364  0.241379  0.557692  0.077769        4  0.523810  0.013593   \n",
      "29    29  0.133084  0.137931  0.527273  0.044963        1  0.500000  0.013593   \n",
      "\n",
      "     y_value  ranks_y  \n",
      "0   0.598159        7  \n",
      "1   0.773764       12  \n",
      "2   0.953168       22  \n",
      "3   0.709554        9  \n",
      "4   0.271182        3  \n",
      "5   0.478747        4  \n",
      "6   0.728477       11  \n",
      "7   0.874518       17  \n",
      "8   0.813174       13  \n",
      "9   0.972387       23  \n",
      "10  0.999177       28  \n",
      "11  0.893547       18  \n",
      "12  0.497516        5  \n",
      "13  0.950758       21  \n",
      "14  0.900815       19  \n",
      "15  0.126559        2  \n",
      "16  0.714304       10  \n",
      "17  0.033788        1  \n",
      "18  0.992592       26  \n",
      "19  0.638265        8  \n",
      "20  0.972501       24  \n",
      "21  0.860465       15  \n",
      "22  0.836382       14  \n",
      "23  0.981782       25  \n",
      "24  0.993492       27  \n",
      "25  0.000000        0  \n",
      "26  0.537031        6  \n",
      "27  0.860746       16  \n",
      "28  0.907579       20  \n",
      "29  1.000000       29  ,     keys      x1_d    x2_deg    x3_clo  x4_eigen  x5_path     x6_cc     x7_po  \\\n",
      "0      0  0.219320  0.551724  0.674419  0.218779        4  0.691667  0.013286   \n",
      "1      1  0.123501  0.517241  0.659091  0.202242        4  0.628571  0.013286   \n",
      "2      2  0.008820  0.517241  0.659091  0.207231        4  0.657143  0.013286   \n",
      "3      3  0.219545  0.517241  0.659091  0.205525        4  0.685714  0.013286   \n",
      "4      4  0.327369  0.517241  0.659091  0.205614        4  0.647619  0.013286   \n",
      "5      5  0.127195  0.517241  0.659091  0.209159        4  0.714286  0.013286   \n",
      "6      6  0.307654  0.551724  0.659091  0.211697        4  0.591667  0.013286   \n",
      "7      7  0.135519  0.379310  0.591837  0.157189        4  0.781818  0.013286   \n",
      "8      8  0.232977  0.517241  0.659091  0.205433        4  0.638095  0.013286   \n",
      "9      9  0.430361  0.620690  0.725000  0.232425        3  0.581699  0.013286   \n",
      "10    10  0.410812  0.586207  0.690476  0.207046        4  0.500000  0.013286   \n",
      "11    11  0.388914  0.620690  0.725000  0.233769        3  0.568627  0.013286   \n",
      "12    12  0.209323  0.620690  0.707317  0.221786        4  0.516340  0.013286   \n",
      "13    13  0.195425  0.724138  0.763158  0.258963        4  0.509524  0.013286   \n",
      "14    14  0.472474  0.448276  0.630435  0.173195        4  0.602564  0.013286   \n",
      "15    15  0.081789  0.482759  0.644444  0.190036        4  0.637363  0.013286   \n",
      "16    16  0.327499  0.655172  0.725000  0.238915        4  0.549708  0.013286   \n",
      "17    17  0.095276  0.551724  0.690476  0.189331        3  0.525000  0.013286   \n",
      "18    18  0.432645  0.482759  0.644444  0.178446        4  0.571429  0.013286   \n",
      "19    19  0.042461  0.551724  0.674419  0.195935        4  0.508333  0.013286   \n",
      "20    20  0.225076  0.517241  0.674419  0.182636        3  0.533333  0.013286   \n",
      "21    21  0.249746  0.448276  0.630435  0.160494        4  0.525641  0.013286   \n",
      "22    22  0.035900  0.379310  0.617021  0.132385        3  0.509091  0.013286   \n",
      "23    23  0.343562  0.413793  0.617021  0.143557        3  0.454545  0.013286   \n",
      "24    24  0.221686  0.275862  0.568627  0.082221        3  0.535714  0.013286   \n",
      "25    25  0.272790  0.275862  0.568627  0.079731        2  0.321429  0.013286   \n",
      "26    26  0.255522  0.310345  0.580000  0.094605        4  0.444444  0.013286   \n",
      "27    27  0.252324  0.310345  0.580000  0.103386        4  0.583333  0.013286   \n",
      "28    28  0.242728  0.103448  0.483333  0.034732        5  1.000000  0.013286   \n",
      "29    29  0.000217  0.034483  0.367089  0.005290        1  0.000000  0.013286   \n",
      "\n",
      "     y_value  ranks_y  \n",
      "0   0.809311       18  \n",
      "1   0.731407       14  \n",
      "2   0.670116       12  \n",
      "3   0.507364        8  \n",
      "4   0.870993       23  \n",
      "5   0.534632        9  \n",
      "6   0.422401        4  \n",
      "7   0.766499       16  \n",
      "8   0.444598        5  \n",
      "9   0.397320        2  \n",
      "10  0.472931        6  \n",
      "11  0.943374       26  \n",
      "12  0.858631       21  \n",
      "13  0.785187       17  \n",
      "14  0.982948       28  \n",
      "15  0.743511       15  \n",
      "16  0.401850        3  \n",
      "17  0.677730       13  \n",
      "18  0.310616        1  \n",
      "19  0.608370       11  \n",
      "20  0.865005       22  \n",
      "21  0.852731       20  \n",
      "22  0.895364       24  \n",
      "23  0.573237       10  \n",
      "24  0.836416       19  \n",
      "25  0.000000        0  \n",
      "26  0.972458       27  \n",
      "27  0.490692        7  \n",
      "28  0.899875       25  \n",
      "29  1.000000       29  ,     keys      x1_d    x2_deg    x3_clo  x4_eigen  x5_path     x6_cc     x7_po  \\\n",
      "0      0  0.183359  0.551724  0.690476  0.199467        3  0.666667  0.027085   \n",
      "1      1  0.222947  0.620690  0.725000  0.224850        3  0.679739  0.027085   \n",
      "2      2  0.222916  0.551724  0.690476  0.184566        3  0.558333  0.027085   \n",
      "3      3  0.249151  0.517241  0.644444  0.179550        4  0.619048  0.027085   \n",
      "4      4  0.451096  0.689655  0.763158  0.237496        3  0.605263  0.027085   \n",
      "5      5  0.084124  0.655172  0.743590  0.224648        3  0.596491  0.027085   \n",
      "6      6  0.146148  0.620690  0.725000  0.219433        3  0.653595  0.027085   \n",
      "7      7  0.254348  0.482759  0.659091  0.183266        3  0.758242  0.027085   \n",
      "8      8  0.256860  0.620690  0.725000  0.216713        3  0.607843  0.027085   \n",
      "9      9  0.039351  0.448276  0.644444  0.154130        3  0.564103  0.027085   \n",
      "10    10  0.138697  0.482759  0.659091  0.170240        3  0.648352  0.027085   \n",
      "11    11  0.426205  0.551724  0.690476  0.183458        3  0.550000  0.027085   \n",
      "12    12  0.267746  0.620690  0.725000  0.221047        3  0.660131  0.027085   \n",
      "13    13  0.096600  0.655172  0.743590  0.219640        3  0.573099  0.027085   \n",
      "14    14  0.485465  0.758621  0.805556  0.254211        2  0.571429  0.027085   \n",
      "15    15  0.294272  0.448276  0.644444  0.151378        3  0.589744  0.027085   \n",
      "16    16  0.295645  0.620690  0.725000  0.222121        3  0.660131  0.027085   \n",
      "17    17  0.223282  0.586207  0.707317  0.203533        3  0.625000  0.027085   \n",
      "18    18  0.303239  0.517241  0.674419  0.182735        3  0.619048  0.027085   \n",
      "19    19  0.032080  0.586207  0.707317  0.197530        3  0.558824  0.027085   \n",
      "20    20  0.072171  0.586207  0.707317  0.198512        3  0.566176  0.027085   \n",
      "21    21  0.195958  0.551724  0.690476  0.182182        3  0.525000  0.027085   \n",
      "22    22  0.438837  0.620690  0.725000  0.194551        2  0.496732  0.027085   \n",
      "23    23  0.280502  0.413793  0.630435  0.144810        3  0.606061  0.027085   \n",
      "24    24  0.325461  0.241379  0.557692  0.074355        3  0.523810  0.027085   \n",
      "25    25  0.412064  0.344828  0.604167  0.100543        3  0.466667  0.027085   \n",
      "26    26  0.527304  0.413793  0.630435  0.115734        3  0.393939  0.027085   \n",
      "27    27  0.093820  0.310345  0.591837  0.088702        3  0.333333  0.027085   \n",
      "28    28  0.160240  0.275862  0.580000  0.065173        2  0.321429  0.027085   \n",
      "29    29  0.522642  0.103448  0.517857  0.031685        1  0.333333  0.027085   \n",
      "\n",
      "     y_value  ranks_y  \n",
      "0   0.876817       19  \n",
      "1   0.864156       18  \n",
      "2   0.446485        8  \n",
      "3   0.164386        2  \n",
      "4   0.951157       26  \n",
      "5   0.703156       14  \n",
      "6   0.440504        7  \n",
      "7   0.349077        5  \n",
      "8   0.366665        6  \n",
      "9   0.712339       15  \n",
      "10  0.891379       21  \n",
      "11  0.259300        3  \n",
      "12  0.074373        1  \n",
      "13  0.659327       12  \n",
      "14  0.835136       17  \n",
      "15  0.530087       10  \n",
      "16  0.882474       20  \n",
      "17  0.554413       11  \n",
      "18  0.000000        0  \n",
      "19  0.939183       24  \n",
      "20  0.904810       22  \n",
      "21  0.664197       13  \n",
      "22  0.998457       28  \n",
      "23  0.935008       23  \n",
      "24  0.458379        9  \n",
      "25  0.270457        4  \n",
      "26  0.816270       16  \n",
      "27  0.957106       27  \n",
      "28  0.942029       25  \n",
      "29  1.000000       29  ,     keys      x1_d    x2_deg    x3_clo  x4_eigen  x5_path     x6_cc     x7_po  \\\n",
      "0      0  0.352254  0.551724  0.674419  0.203502        3  0.633333  0.029121   \n",
      "1      1  0.197705  0.551724  0.674419  0.205408        4  0.625000  0.029121   \n",
      "2      2  0.093499  0.448276  0.604167  0.169210        4  0.666667  0.029121   \n",
      "3      3  0.310553  0.413793  0.630435  0.165184        3  0.757576  0.029121   \n",
      "4      4  0.037666  0.551724  0.690476  0.207131        3  0.658333  0.029121   \n",
      "5      5  0.042436  0.620690  0.725000  0.232366        3  0.647059  0.029121   \n",
      "6      6  0.313781  0.517241  0.674419  0.191497        3  0.628571  0.029121   \n",
      "7      7  0.109483  0.620690  0.725000  0.220681        3  0.581699  0.029121   \n",
      "8      8  0.156124  0.620690  0.725000  0.230433        3  0.633987  0.029121   \n",
      "9      9  0.342861  0.517241  0.674419  0.184416        3  0.561905  0.029121   \n",
      "10    10  0.223889  0.655172  0.743590  0.236069        3  0.578947  0.029121   \n",
      "11    11  0.490462  0.517241  0.674419  0.188325        3  0.580952  0.029121   \n",
      "12    12  0.383210  0.551724  0.690476  0.206876        3  0.641667  0.029121   \n",
      "13    13  0.259197  0.620690  0.725000  0.225260        3  0.601307  0.029121   \n",
      "14    14  0.174988  0.724138  0.783784  0.236470        3  0.476190  0.029121   \n",
      "15    15  0.203018  0.758621  0.805556  0.258071        2  0.515152  0.029121   \n",
      "16    16  0.175871  0.551724  0.690476  0.197237        3  0.583333  0.029121   \n",
      "17    17  0.206639  0.586207  0.707317  0.209165        3  0.544118  0.029121   \n",
      "18    18  0.239273  0.551724  0.690476  0.206235        3  0.625000  0.029121   \n",
      "19    19  0.551193  0.517241  0.674419  0.180118        3  0.580952  0.029121   \n",
      "20    20  0.580366  0.379310  0.617021  0.129113        3  0.454545  0.029121   \n",
      "21    21  0.151728  0.448276  0.644444  0.168228        3  0.628205  0.029121   \n",
      "22    22  0.271176  0.448276  0.644444  0.153907        3  0.500000  0.029121   \n",
      "23    23  0.290140  0.379310  0.617021  0.133116        3  0.527273  0.029121   \n",
      "24    24  0.078646  0.344828  0.604167  0.104196        3  0.444444  0.029121   \n",
      "25    25  0.143422  0.344828  0.591837  0.136215        3  0.711111  0.029121   \n",
      "26    26  0.194020  0.206897  0.537037  0.051394        3  0.333333  0.029121   \n",
      "27    27  0.310708  0.241379  0.557692  0.053002        2  0.238095  0.029121   \n",
      "28    28  0.343394  0.275862  0.568627  0.066286        2  0.357143  0.029121   \n",
      "29    29  0.593193  0.103448  0.508772  0.024170        1  0.333333  0.029121   \n",
      "\n",
      "     y_value  ranks_y  \n",
      "0   0.079126        2  \n",
      "1   0.083813        3  \n",
      "2   0.860851       17  \n",
      "3   0.948187       24  \n",
      "4   0.380473        8  \n",
      "5   0.716437       15  \n",
      "6   0.129412        5  \n",
      "7   0.248165        6  \n",
      "8   0.000000        0  \n",
      "9   0.069696        1  \n",
      "10  0.556671       11  \n",
      "11  0.996641       28  \n",
      "12  0.909169       20  \n",
      "13  0.119275        4  \n",
      "14  0.534481       10  \n",
      "15  0.993304       27  \n",
      "16  0.446631        9  \n",
      "17  0.827285       16  \n",
      "18  0.893268       18  \n",
      "19  0.896518       19  \n",
      "20  0.640043       14  \n",
      "21  0.937150       23  \n",
      "22  0.575566       12  \n",
      "23  0.330840        7  \n",
      "24  0.933905       22  \n",
      "25  0.626236       13  \n",
      "26  0.914087       21  \n",
      "27  0.967612       25  \n",
      "28  0.981777       26  \n",
      "29  1.000000       29  ,     keys      x1_d    x2_deg    x3_clo  x4_eigen  x5_path     x6_cc     x7_po  \\\n",
      "0      0  0.171091  0.482759  0.644444  0.174404        4  0.681319  0.063818   \n",
      "1      1  0.052726  0.517241  0.659091  0.186905        4  0.704762  0.063818   \n",
      "2      2  0.331684  0.620690  0.725000  0.220362        3  0.686275  0.063818   \n",
      "3      3  0.035634  0.586207  0.690476  0.209278        4  0.654412  0.063818   \n",
      "4      4  0.353802  0.620690  0.707317  0.227919        4  0.725490  0.063818   \n",
      "5      5  0.017402  0.586207  0.690476  0.211361        4  0.676471  0.063818   \n",
      "6      6  0.475576  0.620690  0.725000  0.214553        3  0.614379  0.063818   \n",
      "7      7  0.102549  0.586207  0.690476  0.203818        4  0.625000  0.063818   \n",
      "8      8  0.023848  0.551724  0.690476  0.194408        3  0.666667  0.063818   \n",
      "9      9  0.135234  0.482759  0.644444  0.173719        4  0.670330  0.063818   \n",
      "10    10  0.431415  0.517241  0.659091  0.193525        4  0.771429  0.063818   \n",
      "11    11  0.074836  0.862069  0.852941  0.284502        4  0.566667  0.063818   \n",
      "12    12  0.036694  0.448276  0.630435  0.166177        4  0.705128  0.063818   \n",
      "13    13  0.291416  0.517241  0.659091  0.192177        4  0.742857  0.063818   \n",
      "14    14  0.275961  0.517241  0.659091  0.187643        4  0.666667  0.063818   \n",
      "15    15  0.423276  0.827586  0.828571  0.268677        4  0.536232  0.063818   \n",
      "16    16  0.037155  0.551724  0.674419  0.193739        4  0.641667  0.063818   \n",
      "17    17  0.334266  0.586207  0.707317  0.193761        3  0.522059  0.063818   \n",
      "18    18  0.277037  0.655172  0.743590  0.213460        3  0.526316  0.063818   \n",
      "19    19  0.305196  0.413793  0.617021  0.147540        4  0.681818  0.063818   \n",
      "20    20  0.325274  0.586207  0.690476  0.186774        4  0.544118  0.063818   \n",
      "21    21  0.062051  0.586207  0.690476  0.190361        4  0.544118  0.063818   \n",
      "22    22  0.166296  0.448276  0.630435  0.144168        4  0.628205  0.063818   \n",
      "23    23  0.250187  0.344828  0.591837  0.109841        4  0.666667  0.063818   \n",
      "24    24  0.080162  0.413793  0.630435  0.122192        3  0.530303  0.063818   \n",
      "25    25  0.155191  0.310345  0.580000  0.103641        4  0.583333  0.063818   \n",
      "26    26  0.108149  0.413793  0.630435  0.114180        3  0.469697  0.063818   \n",
      "27    27  0.306107  0.310345  0.591837  0.084033        2  0.361111  0.063818   \n",
      "28    28  0.614445  0.310345  0.591837  0.087218        3  0.555556  0.063818   \n",
      "29    29  0.463373  0.034483  0.376623  0.005172        1  0.000000  0.063818   \n",
      "\n",
      "     y_value  ranks_y  \n",
      "0   0.300329        7  \n",
      "1   0.504806       16  \n",
      "2   0.161169        5  \n",
      "3   0.337891       10  \n",
      "4   0.000000        0  \n",
      "5   0.377944       13  \n",
      "6   0.896032       26  \n",
      "7   0.317031        8  \n",
      "8   0.542364       18  \n",
      "9   0.349424       11  \n",
      "10  0.843713       24  \n",
      "11  0.275478        6  \n",
      "12  0.463766       14  \n",
      "13  0.072248        1  \n",
      "14  0.145700        3  \n",
      "15  0.824404       22  \n",
      "16  0.325085        9  \n",
      "17  0.116023        2  \n",
      "18  0.763779       21  \n",
      "19  0.151954        4  \n",
      "20  0.761092       20  \n",
      "21  0.367576       12  \n",
      "22  0.485974       15  \n",
      "23  0.538256       17  \n",
      "24  0.896716       27  \n",
      "25  0.825093       23  \n",
      "26  0.684362       19  \n",
      "27  0.855947       25  \n",
      "28  0.955478       28  \n",
      "29  1.000000       29  ,     keys      x1_d    x2_deg    x3_clo  x4_eigen  x5_path     x6_cc     x7_po  \\\n",
      "0      0  0.129770  0.517241  0.659091  0.196091        4  0.638095  0.059464   \n",
      "1      1  0.101046  0.586207  0.707317  0.216173        3  0.602941  0.059464   \n",
      "2      2  0.468855  0.517241  0.674419  0.192399        3  0.571429  0.059464   \n",
      "3      3  0.222238  0.551724  0.674419  0.206417        4  0.600000  0.059464   \n",
      "4      4  0.013261  0.517241  0.659091  0.194593        4  0.647619  0.059464   \n",
      "5      5  0.495740  0.586207  0.707317  0.222212        3  0.654412  0.059464   \n",
      "6      6  0.133029  0.379310  0.591837  0.152685        4  0.818182  0.059464   \n",
      "7      7  0.098161  0.551724  0.659091  0.210092        4  0.641667  0.059464   \n",
      "8      8  0.173165  0.586207  0.674419  0.221948        4  0.654412  0.059464   \n",
      "9      9  0.221641  0.620690  0.725000  0.229067        3  0.594771  0.059464   \n",
      "10    10  0.428032  0.586207  0.674419  0.228347        4  0.698529  0.059464   \n",
      "11    11  0.008703  0.689655  0.763158  0.242788        3  0.531579  0.059464   \n",
      "12    12  0.289196  0.586207  0.690476  0.215265        3  0.573529  0.059464   \n",
      "13    13  0.106701  0.551724  0.674419  0.205818        4  0.616667  0.059464   \n",
      "14    14  0.290211  0.482759  0.630435  0.186618        4  0.615385  0.059464   \n",
      "15    15  0.008252  0.517241  0.674419  0.188010        3  0.571429  0.059464   \n",
      "16    16  0.228189  0.620690  0.707317  0.226411        4  0.581699  0.059464   \n",
      "17    17  0.059939  0.517241  0.659091  0.171584        3  0.514286  0.059464   \n",
      "18    18  0.414624  0.586207  0.690476  0.197139        4  0.507353  0.059464   \n",
      "19    19  0.054734  0.413793  0.630435  0.138466        3  0.545455  0.059464   \n",
      "20    20  0.130086  0.517241  0.674419  0.163296        2  0.438095  0.059464   \n",
      "21    21  0.306069  0.482759  0.659091  0.169722        3  0.516484  0.059464   \n",
      "22    22  0.253712  0.551724  0.690476  0.191758        3  0.541667  0.059464   \n",
      "23    23  0.369114  0.448276  0.644444  0.146201        3  0.487179  0.059464   \n",
      "24    24  0.001155  0.448276  0.644444  0.148217        3  0.525641  0.059464   \n",
      "25    25  0.002071  0.448276  0.630435  0.151866        4  0.512821  0.059464   \n",
      "26    26  0.116922  0.310345  0.580000  0.094326        4  0.388889  0.059464   \n",
      "27    27  0.097419  0.172414  0.500000  0.038009        3  0.200000  0.059464   \n",
      "28    28  0.190095  0.103448  0.500000  0.030965        4  0.333333  0.059464   \n",
      "29    29  0.431382  0.034483  0.408451  0.010580        1  0.000000  0.059464   \n",
      "\n",
      "     y_value  ranks_y  \n",
      "0   0.380347        7  \n",
      "1   0.502209       12  \n",
      "2   0.000000        0  \n",
      "3   0.752226       21  \n",
      "4   0.543311       14  \n",
      "5   0.986916       28  \n",
      "6   0.415423       10  \n",
      "7   0.400307        9  \n",
      "8   0.321174        5  \n",
      "9   0.342823        6  \n",
      "10  0.927318       26  \n",
      "11  0.589368       17  \n",
      "12  0.841028       22  \n",
      "13  0.395993        8  \n",
      "14  0.844024       23  \n",
      "15  0.622219       18  \n",
      "16  0.239921        2  \n",
      "17  0.667873       20  \n",
      "18  0.070295        1  \n",
      "19  0.662003       19  \n",
      "20  0.519402       13  \n",
      "21  0.864049       24  \n",
      "22  0.315386        4  \n",
      "23  0.306912        3  \n",
      "24  0.574429       16  \n",
      "25  0.460313       11  \n",
      "26  0.555013       15  \n",
      "27  0.911230       25  \n",
      "28  0.975572       27  \n",
      "29  1.000000       29  ,     keys      x1_d    x2_deg    x3_clo  x4_eigen  x5_path     x6_cc     x7_po  \\\n",
      "0      0  0.410634  0.413793  0.630435  0.158100        3  0.772727  0.009518   \n",
      "1      1  0.104825  0.551724  0.690476  0.201534        3  0.683333  0.009518   \n",
      "2      2  0.019275  0.517241  0.674419  0.186607        3  0.647619  0.009518   \n",
      "3      3  0.066091  0.586207  0.707317  0.215050        3  0.676471  0.009518   \n",
      "4      4  0.012905  0.517241  0.659091  0.188570        4  0.685714  0.009518   \n",
      "5      5  0.125774  0.551724  0.690476  0.207988        3  0.716667  0.009518   \n",
      "6      6  0.016814  0.620690  0.725000  0.214617        3  0.575163  0.009518   \n",
      "7      7  0.045011  0.586207  0.707317  0.221149        3  0.705882  0.009518   \n",
      "8      8  0.144988  0.758621  0.805556  0.256018        3  0.558442  0.009518   \n",
      "9      9  0.217697  0.620690  0.725000  0.229316        3  0.692810  0.009518   \n",
      "10    10  0.187720  0.551724  0.690476  0.199869        3  0.675000  0.009518   \n",
      "11    11  0.125125  0.482759  0.659091  0.181794        3  0.703297  0.009518   \n",
      "12    12  0.312077  0.379310  0.604167  0.138097        4  0.654545  0.009518   \n",
      "13    13  0.350551  0.758621  0.805556  0.251202        3  0.541126  0.009518   \n",
      "14    14  0.396855  0.413793  0.630435  0.153218        3  0.681818  0.009518   \n",
      "15    15  0.391903  0.724138  0.783784  0.251838        3  0.604762  0.009518   \n",
      "16    16  0.404774  0.724138  0.783784  0.243890        2  0.552381  0.009518   \n",
      "17    17  0.163171  0.586207  0.707317  0.202394        3  0.588235  0.009518   \n",
      "18    18  0.288612  0.620690  0.725000  0.220235        3  0.620915  0.009518   \n",
      "19    19  0.338018  0.551724  0.690476  0.169833        3  0.483333  0.009518   \n",
      "20    20  0.323677  0.551724  0.690476  0.191567        3  0.608333  0.009518   \n",
      "21    21  0.056886  0.413793  0.630435  0.142078        3  0.621212  0.009518   \n",
      "22    22  0.251910  0.517241  0.674419  0.178785        3  0.571429  0.009518   \n",
      "23    23  0.410470  0.275862  0.568627  0.094815        4  0.571429  0.009518   \n",
      "24    24  0.322626  0.448276  0.644444  0.152014        3  0.602564  0.009518   \n",
      "25    25  0.062103  0.206897  0.557692  0.048857        3  0.333333  0.009518   \n",
      "26    26  0.055890  0.344828  0.604167  0.099359        2  0.444444  0.009518   \n",
      "27    27  0.094166  0.275862  0.580000  0.076603        3  0.357143  0.009518   \n",
      "28    28  0.037959  0.172414  0.547170  0.043473        2  0.200000  0.009518   \n",
      "29    29  0.081461  0.103448  0.500000  0.024064        1  0.000000  0.009518   \n",
      "\n",
      "     y_value  ranks_y  \n",
      "0   0.979445       26  \n",
      "1   0.796067       12  \n",
      "2   0.887475       15  \n",
      "3   0.848769       13  \n",
      "4   0.902956       16  \n",
      "5   0.938251       21  \n",
      "6   0.744856        9  \n",
      "7   0.775817       10  \n",
      "8   0.917880       18  \n",
      "9   0.935173       20  \n",
      "10  0.999999       28  \n",
      "11  0.970771       24  \n",
      "12  0.967435       23  \n",
      "13  0.385492        3  \n",
      "14  0.293807        2  \n",
      "15  0.225455        1  \n",
      "16  0.976780       25  \n",
      "17  0.652247        7  \n",
      "18  0.925015       19  \n",
      "19  0.463845        5  \n",
      "20  0.887145       14  \n",
      "21  0.691806        8  \n",
      "22  0.913194       17  \n",
      "23  0.000000        0  \n",
      "24  0.533661        6  \n",
      "25  0.995920       27  \n",
      "26  0.778352       11  \n",
      "27  0.954632       22  \n",
      "28  0.401296        4  \n",
      "29  1.000000       29  ,     keys      x1_d    x2_deg    x3_clo  x4_eigen  x5_path     x6_cc     x7_po  \\\n",
      "0      0  0.349216  0.482759  0.659091  0.167302        3  0.736264  0.027518   \n",
      "1      1  0.320127  0.413793  0.630435  0.142840        3  0.818182  0.027518   \n",
      "2      2  0.191086  0.586207  0.707317  0.189237        3  0.610294  0.027518   \n",
      "3      3  0.396404  0.517241  0.674419  0.168204        3  0.638095  0.027518   \n",
      "4      4  0.146730  0.655172  0.743590  0.217563        3  0.625731  0.027518   \n",
      "5      5  0.475621  0.758621  0.805556  0.252669        3  0.645022  0.027518   \n",
      "6      6  0.116378  0.551724  0.690476  0.181284        3  0.641667  0.027518   \n",
      "7      7  0.484381  0.620690  0.725000  0.204040        2  0.633987  0.027518   \n",
      "8      8  0.233127  0.586207  0.707317  0.189694        3  0.625000  0.027518   \n",
      "9      9  0.459409  0.724138  0.783784  0.243276        3  0.657143  0.027518   \n",
      "10    10  0.398695  0.586207  0.707317  0.191291        2  0.610294  0.027518   \n",
      "11    11  0.259456  0.655172  0.743590  0.216110        3  0.619883  0.027518   \n",
      "12    12  0.023797  0.758621  0.805556  0.246967        3  0.597403  0.027518   \n",
      "13    13  0.280639  0.586207  0.707317  0.193994        3  0.647059  0.027518   \n",
      "14    14  0.230715  0.586207  0.707317  0.201914        3  0.713235  0.027518   \n",
      "15    15  0.163980  0.586207  0.707317  0.191390        3  0.595588  0.027518   \n",
      "16    16  0.444634  0.655172  0.743590  0.208806        3  0.578947  0.027518   \n",
      "17    17  0.067404  0.551724  0.690476  0.189887        3  0.658333  0.027518   \n",
      "18    18  0.181665  0.620690  0.725000  0.206492        3  0.620915  0.027518   \n",
      "19    19  0.364208  0.551724  0.690476  0.187262        3  0.650000  0.027518   \n",
      "20    20  0.262635  0.517241  0.674419  0.178546        3  0.695238  0.027518   \n",
      "21    21  0.471227  0.551724  0.690476  0.178540        2  0.641667  0.027518   \n",
      "22    22  0.048053  0.551724  0.690476  0.178309        3  0.625000  0.027518   \n",
      "23    23  0.239888  0.551724  0.674419  0.179575        3  0.625000  0.027518   \n",
      "24    24  0.417625  0.517241  0.674419  0.153237        2  0.533333  0.027518   \n",
      "25    25  0.311474  0.448276  0.644444  0.136419        3  0.589744  0.027518   \n",
      "26    26  0.128848  0.379310  0.604167  0.123007        3  0.618182  0.027518   \n",
      "27    27  0.390571  0.172414  0.547170  0.043111        3  0.300000  0.027518   \n",
      "28    28  0.183613  0.137931  0.527273  0.043239        1  0.500000  0.027518   \n",
      "29    29  0.477440  0.137931  0.508772  0.035100        4  0.500000  0.027518   \n",
      "\n",
      "     y_value  ranks_y  \n",
      "0   0.792851        8  \n",
      "1   0.997138       27  \n",
      "2   0.973709       21  \n",
      "3   0.935259       19  \n",
      "4   0.920225       15  \n",
      "5   0.630609        2  \n",
      "6   0.833868       11  \n",
      "7   0.867221       13  \n",
      "8   0.993969       24  \n",
      "9   0.990956       23  \n",
      "10  0.999915       28  \n",
      "11  0.933369       18  \n",
      "12  0.833092       10  \n",
      "13  0.714222        5  \n",
      "14  0.758640        7  \n",
      "15  0.977584       22  \n",
      "16  0.994415       25  \n",
      "17  0.874949       14  \n",
      "18  0.925301       17  \n",
      "19  0.678415        3  \n",
      "20  0.712079        4  \n",
      "21  0.996515       26  \n",
      "22  0.816582        9  \n",
      "23  0.726930        6  \n",
      "24  0.968541       20  \n",
      "25  0.857373       12  \n",
      "26  0.924318       16  \n",
      "27  0.362278        1  \n",
      "28  1.000000       29  \n",
      "29  0.000000        0  ]\n"
     ]
    }
   ],
   "source": [
    "print(train_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0686a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_excel(r'C:/Users/xzhan/OneDrive/Misinfo Paper/One Node - Final/NE Prediction/Network_datasets.xlsx', index=False)\n",
    "# Concatenate the training and testing dataframes\n",
    "train_df = pd.concat(train_data1, ignore_index=True)\n",
    "# test_df = pd.concat(test_data, ignore_index=True)\n",
    "# valid_df = pd.concat(valid_data, ignore_index=True)\n",
    "#Split the data into features (X) and target (Y)\n",
    "X_train = train_df[['x1_d', 'x2_deg', 'x3_clo', 'x4_eigen','x5_path','x6_cc','x7_po','y_value']].values\n",
    "Y_train = train_df['y_value'].values\n",
    "Y_ranks = train_df['ranks_y'].values\n",
    "\n",
    "# X_test = test_df[['x1_d', 'x2_deg', 'x3_clo', 'x4_eigen','x5_path','x6_cc','x7_po','y_value']].values\n",
    "# Y_test = test_df['y_value'].values\n",
    "# Y_test_ranks = test_df['ranks_y'].values\n",
    "\n",
    "# X_valid = valid_df[['x1_d', 'x2_deg', 'x3_clo', 'x4_eigen','x5_path','x6_cc','x7_po','y_value']].values\n",
    "# Y_valid = valid_df['y_value'].values\n",
    "# Y_vaid_ranks = valid_df['ranks_y'].values\n",
    "\n",
    "\n",
    "# # # #########################################################\n",
    "X_train = train_df[['x1_d', 'x4_eigen','x5_path','x6_cc','y_value']].values\n",
    "# Y_train = train_df['y_value'].values\n",
    "# Y_ranks = train_df['ranks_y'].values\n",
    "\n",
    "# X_test = test_df[['x11', 'x22', 'x33']].values\n",
    "# Y_test = test_df['y_value'].values\n",
    "# X_valid = valid_df[['x11', 'x22', 'x33']].values\n",
    "# Y_valid = valid_df['y_value'].values\n",
    "\n",
    "\n",
    "# ######################################################\n",
    "# X_train = train_df[['x11', 'x22']].values\n",
    "# Y_train = train_df['y_value'].values\n",
    "# X_test = test_df[['x11', 'x22']].values\n",
    "# Y_test = test_df['y_value'].values\n",
    "# X_valid = valid_df[['x11', 'x22']].values\n",
    "# Y_valid = valid_df['y_value'].values\n",
    "\n",
    "########################################################\n",
    "# X_train = train_df[['x22']].values\n",
    "# Y_train = train_df['y_value'].values\n",
    "# X_test = test_df[['x22']].values\n",
    "# Y_test = test_df['y_value'].values\n",
    "# X_valid = valid_df[['x22']].values\n",
    "# Y_valid = valid_df['y_value'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53082279",
   "metadata": {},
   "source": [
    "# A. Linear Regression Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "438eef2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 9.337e+29\n",
      "Date:                Fri, 10 Nov 2023   Prob (F-statistic):               0.00\n",
      "Time:                        17:32:11   Log-Likelihood:                 14551.\n",
      "No. Observations:                 450   AIC:                        -2.908e+04\n",
      "Df Residuals:                     441   BIC:                        -2.905e+04\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        2.22e-16   4.41e-15      0.050      0.960   -8.45e-15    8.89e-15\n",
      "x1         -1.041e-15   7.47e-16     -1.394      0.164   -2.51e-15    4.27e-16\n",
      "x2          4.663e-15   6.64e-15      0.702      0.483    -8.4e-15    1.77e-14\n",
      "x3         -3.109e-15   9.79e-15     -0.318      0.751   -2.23e-14    1.61e-14\n",
      "x4         -3.553e-15   9.48e-15     -0.375      0.708   -2.22e-14    1.51e-14\n",
      "x5         -6.245e-16   1.87e-16     -3.340      0.001   -9.92e-16   -2.57e-16\n",
      "x6          7.216e-16   1.15e-15      0.630      0.529   -1.53e-15    2.97e-15\n",
      "x7         -3.553e-15   6.61e-15     -0.537      0.591   -1.66e-14    9.45e-15\n",
      "x8             1.0000   3.99e-16    2.5e+15      0.000       1.000       1.000\n",
      "==============================================================================\n",
      "Omnibus:                       29.527   Durbin-Watson:                   0.067\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               37.607\n",
      "Skew:                           0.549   Prob(JB):                     6.82e-09\n",
      "Kurtosis:                       3.895   Cond. No.                         455.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "coefficients: [ 2.220e-16 -1.041e-15  4.663e-15 -3.109e-15 -3.553e-15 -6.245e-16\n",
      "  7.216e-16 -3.553e-15  1.000e+00]\n",
      "standard_errors: [4.410e-15 7.467e-16 6.645e-15 9.790e-15 9.483e-15 1.870e-16 1.145e-15\n",
      " 6.614e-15 3.995e-16]\n",
      "Mean Squared Error: 4.797440293540003e-30\n",
      "P value:[9.599e-01 1.640e-01 4.832e-01 7.510e-01 7.081e-01 9.082e-04 5.290e-01\n",
      " 5.915e-01 0.000e+00]\n",
      "F-test:9.336910408714186e+29\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# add a constant term to the dataframe\n",
    "X_train_OLS = sm.add_constant(X_train)\n",
    "# fit the linear regression model\n",
    "model_OLS = sm.OLS(Y_train,X_train_OLS).fit()\n",
    "#model = sm.OLS(df['y_rank'], df[['const', 'x1','x2','x3']]).fit()\n",
    "# print the model summary\n",
    "print(model_OLS.summary())\n",
    "\n",
    "############## Model Evaluation#################\n",
    "coefficients = model_OLS.params\n",
    "standard_errors = model_OLS.bse\n",
    "print(\"coefficients:\",coefficients)\n",
    "print(\"standard_errors:\",standard_errors)\n",
    "r_squared = model_OLS.rsquared\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "predictions_ols = model_OLS.predict(X_train_OLS)\n",
    "mse_ols = mean_squared_error(Y_train, predictions_ols)\n",
    "print(f\"Mean Squared Error: {mse_ols}\")\n",
    "residuals_ols = model_OLS.resid\n",
    "p_values_ols = model_OLS.pvalues\n",
    "print(f\"P value:{p_values_ols}\")\n",
    "f_statistic = model_OLS.fvalue\n",
    "print(f\"F-test:{f_statistic}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2d31dee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.0790\n",
      "Mean Absolute Error (MAE): 0.2290\n",
      "P value:[1.293e-265 7.795e-021 9.463e-005 4.979e-013 2.620e-014]\n",
      "F-test:46.77953472334489\n",
      "[834 812 837]\n"
     ]
    }
   ],
   "source": [
    "#### pred_Y = model.predict(df[['const', 'x11','x22','x33']])\n",
    "# add a constant term to the dataframe\n",
    "X_test_OLS = sm.add_constant(X_test)\n",
    "predictions_test_ols = model_OLS.predict(X_test_OLS)\n",
    "#print(predictions_test_ols)\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "mse = mean_squared_error(Y_test, predictions_test_ols)\n",
    "mae = mean_absolute_error(Y_test, predictions_test_ols)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "residuals_ols = model_OLS.resid\n",
    "p_values_ols = model_OLS.pvalues\n",
    "print(f\"P value:{p_values_ols}\")\n",
    "f_statistic = model_OLS.fvalue\n",
    "print(f\"F-test:{f_statistic}\")\n",
    "\n",
    "\n",
    "# pred_index = np.argmin(pred_Y)\n",
    "# Find k nodes index with smallest polarization - use to predict minimizer's choice\n",
    "k = 3\n",
    "print(predictions_ols.argsort()[:k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7840f5ba",
   "metadata": {},
   "source": [
    "# B. Neural Network Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1cfc265d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "75/75 - 0s - loss: 42.5968 - mae: 5.9613\n",
      "Epoch 2/50\n",
      "75/75 - 0s - loss: 12.0865 - mae: 2.8943\n",
      "Epoch 3/50\n",
      "75/75 - 0s - loss: 9.3134 - mae: 2.4982\n",
      "Epoch 4/50\n",
      "75/75 - 0s - loss: 8.7329 - mae: 2.4159\n",
      "Epoch 5/50\n",
      "75/75 - 0s - loss: 8.3596 - mae: 2.3544\n",
      "Epoch 6/50\n",
      "75/75 - 0s - loss: 8.0048 - mae: 2.2871\n",
      "Epoch 7/50\n",
      "75/75 - 0s - loss: 7.7561 - mae: 2.2638\n",
      "Epoch 8/50\n",
      "75/75 - 0s - loss: 7.5553 - mae: 2.2283\n",
      "Epoch 9/50\n",
      "75/75 - 0s - loss: 7.3919 - mae: 2.1965\n",
      "Epoch 10/50\n",
      "75/75 - 0s - loss: 7.2790 - mae: 2.1854\n",
      "Epoch 11/50\n",
      "75/75 - 0s - loss: 7.1517 - mae: 2.1687\n",
      "Epoch 12/50\n",
      "75/75 - 0s - loss: 7.0626 - mae: 2.1476\n",
      "Epoch 13/50\n",
      "75/75 - 0s - loss: 6.9957 - mae: 2.1354\n",
      "Epoch 14/50\n",
      "75/75 - 0s - loss: 6.9360 - mae: 2.1223\n",
      "Epoch 15/50\n",
      "75/75 - 0s - loss: 6.9007 - mae: 2.1206\n",
      "Epoch 16/50\n",
      "75/75 - 0s - loss: 6.8565 - mae: 2.1112\n",
      "Epoch 17/50\n",
      "75/75 - 0s - loss: 6.8305 - mae: 2.1077\n",
      "Epoch 18/50\n",
      "75/75 - 0s - loss: 6.7885 - mae: 2.0966\n",
      "Epoch 19/50\n",
      "75/75 - 0s - loss: 6.7497 - mae: 2.0889\n",
      "Epoch 20/50\n",
      "75/75 - 0s - loss: 6.7505 - mae: 2.0969\n",
      "Epoch 21/50\n",
      "75/75 - 0s - loss: 6.7655 - mae: 2.0946\n",
      "Epoch 22/50\n",
      "75/75 - 0s - loss: 6.7371 - mae: 2.0843\n",
      "Epoch 23/50\n",
      "75/75 - 0s - loss: 6.6597 - mae: 2.0781\n",
      "Epoch 24/50\n",
      "75/75 - 0s - loss: 6.6832 - mae: 2.0782\n",
      "Epoch 25/50\n",
      "75/75 - 0s - loss: 6.6448 - mae: 2.0697\n",
      "Epoch 26/50\n",
      "75/75 - 0s - loss: 6.6193 - mae: 2.0606\n",
      "Epoch 27/50\n",
      "75/75 - 0s - loss: 6.5816 - mae: 2.0538\n",
      "Epoch 28/50\n",
      "75/75 - 0s - loss: 6.5967 - mae: 2.0724\n",
      "Epoch 29/50\n",
      "75/75 - 0s - loss: 6.5792 - mae: 2.0506\n",
      "Epoch 30/50\n",
      "75/75 - 0s - loss: 6.5956 - mae: 2.0604\n",
      "Epoch 31/50\n",
      "75/75 - 0s - loss: 6.5224 - mae: 2.0473\n",
      "Epoch 32/50\n",
      "75/75 - 0s - loss: 6.5033 - mae: 2.0435\n",
      "Epoch 33/50\n",
      "75/75 - 0s - loss: 6.5252 - mae: 2.0486\n",
      "Epoch 34/50\n",
      "75/75 - 0s - loss: 6.4864 - mae: 2.0434\n",
      "Epoch 35/50\n",
      "75/75 - 0s - loss: 6.5227 - mae: 2.0496\n",
      "Epoch 36/50\n",
      "75/75 - 0s - loss: 6.4829 - mae: 2.0411\n",
      "Epoch 37/50\n",
      "75/75 - 0s - loss: 6.4831 - mae: 2.0371\n",
      "Epoch 38/50\n",
      "75/75 - 0s - loss: 6.4475 - mae: 2.0375\n",
      "Epoch 39/50\n",
      "75/75 - 0s - loss: 6.4402 - mae: 2.0327\n",
      "Epoch 40/50\n",
      "75/75 - 0s - loss: 6.4411 - mae: 2.0271\n",
      "Epoch 41/50\n",
      "75/75 - 0s - loss: 6.4410 - mae: 2.0387\n",
      "Epoch 42/50\n",
      "75/75 - 0s - loss: 6.4317 - mae: 2.0310\n",
      "Epoch 43/50\n",
      "75/75 - 0s - loss: 6.3712 - mae: 2.0182\n",
      "Epoch 44/50\n",
      "75/75 - 0s - loss: 6.3746 - mae: 2.0217\n",
      "Epoch 45/50\n",
      "75/75 - 0s - loss: 6.4497 - mae: 2.0259\n",
      "Epoch 46/50\n",
      "75/75 - 0s - loss: 6.3779 - mae: 2.0186\n",
      "Epoch 47/50\n",
      "75/75 - 0s - loss: 6.3609 - mae: 2.0230\n",
      "Epoch 48/50\n",
      "75/75 - 0s - loss: 6.3350 - mae: 2.0169\n",
      "Epoch 49/50\n",
      "75/75 - 0s - loss: 6.3596 - mae: 2.0146\n",
      "Epoch 50/50\n",
      "75/75 - 0s - loss: 6.3358 - mae: 2.0176\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standardize the features (important for neural networks)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "# Define a simple neural network model\n",
    "model_NN = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1)  # Output layer with a single neuron (for regression)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_NN.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model_NN.fit(X_train, Y_train, epochs=50, batch_size=32, verbose=2)\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44b3e920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 4)\n",
      "(28, 0.04187373571282055)\n",
      "[(16, -0.0151415095), (10, -0.015009886), (5, -0.014558872), (4, -0.011456942), (8, -0.011417782), (19, -0.011154255), (1, -0.010690497), (3, -0.009535773), (22, -0.008449068), (24, -0.008164829), (13, -0.008027699), (18, -0.0075722393), (20, -0.0070563536), (26, -0.006835861), (9, -0.0066093635), (0, -0.006463727), (25, -0.0061844494), (23, -0.004704898), (17, -0.0032228364), (21, -0.0027107021), (29, -0.0012028946), (14, -0.00038064294), (15, 0.0008013414), (12, 0.0011436099), (7, 0.001608269), (2, 0.0020497625), (28, 0.0020708197), (11, 0.0037495808), (27, 0.0077538732), (6, 0.012119165)]\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "# Use the trained model to make predictions on the test data\n",
    "predictions = model_NN.predict(X_test)\n",
    "# # Print the predictions\n",
    "# for i, pred in enumerate(predictions):\n",
    "#     print(f\"Prediction for sample {i+1}: {pred[0]}\")\n",
    "\n",
    "x = 2\n",
    "index = int(sets*0.9+1+x)\n",
    "\n",
    "print(Game_result[index])\n",
    "\n",
    "predictions_1net = predictions[x*n:(x+1)*n]\n",
    "indexed_dict = {}\n",
    "for index, item in enumerate(predictions_1net):\n",
    "    indexed_dict[index] = item[0]\n",
    "\n",
    "print(sorted(indexed_dict.items(), key=lambda x:x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e434ca9",
   "metadata": {},
   "source": [
    "### NN Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6fdcc70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 Weights:\n",
      "(4, 64)\n",
      "Layer 1 Weights:\n",
      "(64,)\n",
      "Layer 2 Weights:\n",
      "(64, 32)\n",
      "Layer 3 Weights:\n",
      "(32,)\n",
      "Layer 4 Weights:\n",
      "(32, 1)\n",
      "Layer 5 Weights:\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "# Get the weights and biases of the neural network\n",
    "weights = model_NN.get_weights()\n",
    "\n",
    "# Print the weights and biases\n",
    "for layer_num, layer_weights in enumerate(weights):\n",
    "    print(f\"Layer {layer_num} Weights:\")\n",
    "    print(layer_weights.shape)\n",
    "   \n",
    "# Evaluate the model on the test data\n",
    "loss, mae = model_NN.evaluate(X_test, Y_test)\n",
    "# # Print the Mean Absolute Error\n",
    "# print(f\"Mean Absolute Error on Test Data: {mae}\")\n",
    "# Use the trained model to make predictions on the test data\n",
    "predictions = model_NN.predict(X_test)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE) manually\n",
    "mae = np.mean(np.abs(predictions - Y_test))\n",
    "print(f\"Mean Absolute Error on Test Data: {mae}\")\n",
    "print(f\"Mean Absolute Error percentage on Test Data: {mae/np.mean(Y_test)}\")\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(Y_test, predictions)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "# Calculate R-squared score\n",
    "r2 = r2_score(Y_test, predictions)\n",
    "print(f\"R-squared (R^2) Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05a8c2a",
   "metadata": {},
   "source": [
    "## C. Decision Tree Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "193febc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 416  256  573 ...  556 1974 2242]\n",
      "[13  8 19 ... 18 65 74]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a label encoder to map the unique values to integers\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the original target variable into integers\n",
    "encoded_y = label_encoder.fit_transform()\n",
    "print(encoded_y)\n",
    "# Split the encoded values into batches (30 unique values in each batch)\n",
    "batch_size = n\n",
    "batched_y = np.floor(encoded_y / batch_size).astype(int)\n",
    "print(batched_y)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, batched_y)  # Train the model\n",
    "\n",
    "# Decode the predicted values\n",
    "predicted_batched_y = decision_tree.predict(X_test)\n",
    "predicted_y = predicted_batched_y * batch_size  # Decode the batched predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442dcd7e",
   "metadata": {},
   "source": [
    "## Sample eg - unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "72ba9559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.6226527909046995 changed to 1\n",
      "Min Action:    Agent26 's opinion 0.000984043874843299 changed to 0.5547007727634141\n",
      "Network reaches equilibrium Polarization: 0.016080010549744186\n",
      "_________________\n",
      "True\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.6226527909046995 changed to 1\n",
      "Min Action:    Agent26 's opinion 0.000984043874843299 changed to 0.5547007727634141\n",
      "Network reaches equilibrium Polarization: 0.016080010549744186\n",
      "{0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0, 6: 0.5, 7: 1.0, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.5, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0, 20: 1.0, 21: 1.0, 22: 0.5, 23: 1.0, 24: 0.5, 25: 0.5, 26: 1.0, 27: 1.0, 28: 1.0, 29: 0.0}\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.3541732845321627 changed to 0\n",
      "Min Action:    Agent28 's opinion 0.9453848410127564 changed to 0.4667759539039294\n",
      "Network reaches equilibrium Polarization: 0.031239528658814436\n",
      "_________________\n",
      "True\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent29 's opinion 0.3541732845321627 changed to 0\n",
      "Min Action:    Agent28 's opinion 0.9453848410127564 changed to 0.4667759539039294\n",
      "Network reaches equilibrium Polarization: 0.031239528658814436\n",
      "{0: 1.0, 1: 0.6666666666666667, 2: 0.6666666666666667, 3: 0.3333333333333333, 4: 0.6666666666666667, 5: 0.6666666666666667, 6: 0.6666666666666667, 7: 0.6666666666666667, 8: 0.6666666666666667, 9: 0.6666666666666667, 10: 0.6666666666666667, 11: 0.6666666666666667, 12: 0.6666666666666667, 13: 0.6666666666666667, 14: 0.6666666666666667, 15: 0.6666666666666667, 16: 0.3333333333333333, 17: 0.6666666666666667, 18: 0.6666666666666667, 19: 0.6666666666666667, 20: 0.6666666666666667, 21: 0.6666666666666667, 22: 0.6666666666666667, 23: 0.6666666666666667, 24: 0.6666666666666667, 25: 0.6666666666666667, 26: 0.6666666666666667, 27: 0.3333333333333333, 28: 1.0, 29: 0.0}\n",
      "Actual Value: 0.00756561708792502\n",
      "Predicted Value: 0.0010581613\n",
      "Difference: 0.00650745582922751\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assume you have the necessary functions defined: make_innat_opinions, make_random_network, network_data,\n",
    "# MaxMin_play, metrics, actual_rank, and rescale\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Define the number of iterations\n",
    "num_iterations = 50  # Change this number if needed\n",
    "\n",
    "# Initialize lists to store actual and predicted values\n",
    "actual_values = []\n",
    "predicted_values = []\n",
    "\n",
    "# Create a neural network model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(3,)),  # Three features (x11, x22, x33)\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1)  # Output layer with a single neuron (for regression)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Loop through iterations\n",
    "for i in range(2):\n",
    "    s = make_innat_opinions(n)\n",
    "    G = make_random_network(n)\n",
    "    (temp_df, actual_Y_dict) = network_data(s, G, n)\n",
    "    (v1, v2, max_opinion, min_opinion, max_pol) = MaxMin_play(s, n, G)\n",
    "    (converted_dict, converted_dict1, converted_dict2, sorted_gap, scaled_MinPaths_sort) = metrics(G, v1)\n",
    "\n",
    "    # Calculate actual ranks and rescale polarization change\n",
    "    (actual_Y_dict, actual_ranks) = actual_rank(s, n, v1, max_opinion)\n",
    "    # rescaled_dict = rescale(actual_Y_dict)\n",
    "\n",
    "    # Create a temporary DataFrame for the current iteration's data\n",
    "    temp_df = pd.DataFrame({\n",
    "        'x11': [sorted_gap[x] for x in converted_dict2.keys()],\n",
    "        'x22': [converted_dict2[x] for x in converted_dict2.keys()],\n",
    "        'x33': [scaled_MinPaths_sort[x] for x in converted_dict2.keys()],\n",
    "        'y_value': [actual_Y_dict[x] for x in converted_dict2.keys()]\n",
    "    })\n",
    "    print(scaled_MinPaths_sort)\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    temp_df[['x11', 'x22', 'x33']] = scaler.fit_transform(temp_df[['x11', 'x22', 'x33']])\n",
    "\n",
    "    # Concatenate the temporary DataFrame to the main DataFrame\n",
    "    df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "    # Extract features (x11, x22, x33) and target (y_value)\n",
    "    X = temp_df[['x11', 'x22', 'x33']].values\n",
    "    y = temp_df['y_value'].values\n",
    "\n",
    "    # Train the neural network for each iteration\n",
    "    model.fit(X, y, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    # Predict the target values\n",
    "    predictions = model.predict(X)\n",
    "\n",
    "    # Append actual and predicted values to their respective lists\n",
    "    actual_values.extend(y)\n",
    "    predicted_values.extend(predictions.flatten())\n",
    "\n",
    "# Calculate the difference between actual and predicted values\n",
    "differences = np.abs(np.array(actual_values) - np.array(predicted_values))\n",
    "\n",
    "# Print the first predicted value and its actual value\n",
    "print(\"Actual Value:\", actual_values[0])\n",
    "print(\"Predicted Value:\", predicted_values[0])\n",
    "print(\"Difference:\", differences[0])\n",
    "print(f\"Predicted y_value for the test network: {predictions[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "39b0693f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent28 's opinion 0.6023554375757443 changed to 0\n",
      "Min Action:    Agent25 's opinion 0.9562842372875656 changed to 0.6065065580033292\n",
      "Network reaches equilibrium Polarization: 0.016077623621038515\n",
      "_________________\n",
      "True\n",
      "                                \n",
      "Maximizer finds its target agent:\n",
      "Max Action:    Agent28 's opinion 0.6023554375757443 changed to 0\n",
      "Min Action:    Agent25 's opinion 0.9562842372875656 changed to 0.6065065580033292\n",
      "Network reaches equilibrium Polarization: 0.016077623621038515\n"
     ]
    }
   ],
   "source": [
    "# create testing data\n",
    "df1 = pd.DataFrame()\n",
    "for i in range(1):  # Change the range if you want more iterations\n",
    "    s = make_innat_opinions(n)\n",
    "    G = make_random_network(n)\n",
    "    (temp_df, actual_Y_dict) = network_data(s, G, n)\n",
    "    (v1, v2, max_opinion, min_opinion, max_pol) = MaxMin_play(s, n, G)\n",
    "    (converted_dict, converted_dict1, converted_dict2, sorted_gap, scaled_MinPaths_sort) = metrics(G, v1)\n",
    "\n",
    "    # Calculate actual ranks and rescale polarization change\n",
    "    (actual_Y_dict, actual_ranks) = actual_rank(s, n, v1, max_opinion)\n",
    "    #rescaled_dict = rescale(actual_Y_dict)\n",
    "\n",
    "    # Create a temporary DataFrame for the current iteration's data\n",
    "    temp_df = pd.DataFrame({'keys': list(converted_dict2.keys()),\n",
    "                            'x11': [sorted_gap[x] for x in converted_dict2.keys()],\n",
    "                            'x22': [converted_dict2[x] for x in converted_dict2.keys()],\n",
    "                            'x33': [scaled_MinPaths_sort[x] for x in converted_dict2.keys()],\n",
    "                            'y_value': [actual_Y_dict[x] for x in converted_dict2.keys()]})\n",
    "\n",
    "    # Concatenate the temporary DataFrame to the main DataFrame\n",
    "    df1 = pd.concat([df1, temp_df], ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3aa2e7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df:     const  keys       x11       x22       x33   y_value\n",
      "0     1.0     0  0.698243  0.624098  0.666667  0.003389\n",
      "1     1.0     1  0.790401  0.692491  0.333333  0.003894\n",
      "2     1.0     2  0.522414  0.737438  0.666667  0.004365\n",
      "3     1.0     3  0.634123  0.660801  0.666667  0.003371\n",
      "4     1.0     4  0.742036  0.679378  0.666667  0.003375\n",
      "5     1.0     5  0.527894  0.677503  0.666667  0.003841\n",
      "6     1.0     6  0.861896  1.000000  0.333333  0.004143\n",
      "7     1.0     7  0.860905  0.903703  0.333333  0.004139\n",
      "8     1.0     8  1.000000  0.865950  0.666667  0.003112\n",
      "9     1.0     9  0.974292  0.852483  0.666667  0.003963\n",
      "10    1.0    10  0.206775  0.980180  0.666667  0.004342\n",
      "11    1.0    11  0.010986  0.883571  0.666667  0.004332\n",
      "12    1.0    12  0.762645  0.893460  0.666667  0.003564\n",
      "13    1.0    13  0.070004  0.835888  0.666667  0.004325\n",
      "14    1.0    14  0.092986  0.739548  0.666667  0.004349\n",
      "15    1.0    15  0.914326  0.749338  0.666667  0.003293\n",
      "16    1.0    16  0.000000  0.732002  0.666667  0.004241\n",
      "17    1.0    17  0.092116  0.674298  0.333333  0.004294\n",
      "18    1.0    18  0.604845  0.670243  0.333333  0.003198\n",
      "19    1.0    19  0.454999  0.683604  0.666667  0.004023\n",
      "20    1.0    20  0.839966  0.582417  0.666667  0.003970\n",
      "21    1.0    21  0.440871  0.777961  0.666667  0.004073\n",
      "22    1.0    22  0.150946  0.620826  0.666667  0.004353\n",
      "23    1.0    23  0.759306  0.443111  0.666667  0.003255\n",
      "24    1.0    24  0.708678  0.492357  0.666667  0.003565\n",
      "25    1.0    25  0.953766  0.266214  1.000000  0.003092\n",
      "26    1.0    26  0.191835  0.221273  0.666667  0.004243\n",
      "27    1.0    27  0.180224  0.126644  0.666667  0.003938\n",
      "28    1.0    28  0.233307  0.095255  0.000000  0.000000\n",
      "29    1.0    29  0.387357  0.000000  0.333333  0.004217\n",
      "predictions [(28, 0.008754212898974073), (29, 0.011951224710081311), (1, 0.01678428339222567), (18, 0.016830494185308607), (27, 0.017269292354793946), (17, 0.017460057849816024), (26, 0.01798046207250216), (7, 0.018319585410549937), (23, 0.019017032793617883), (6, 0.019055929802209038), (24, 0.01945328944834245), (20, 0.019989770566901485), (0, 0.020474422607340084), (3, 0.02083036431763774), (4, 0.020846673246607855), (5, 0.021082281084870185), (22, 0.021088227593618492), (15, 0.021181360141095687), (19, 0.02121409346165484), (25, 0.021541608836999196), (2, 0.021547696023404846), (9, 0.02190131039172312), (21, 0.021953235249769103), (8, 0.021974441086428546), (14, 0.02206513235725116), (16, 0.022115876774919767), (12, 0.022462191391619726), (13, 0.02282979058275598), (11, 0.023263870762474482), (10, 0.02377521230639021)]\n",
      "actual values [(28, 0), (25, 0.0030919865442198893), (8, 0.0031122031843165247), (18, 0.0031981204992056304), (23, 0.003254984968395963), (15, 0.0032932904390964544), (3, 0.003370577133469964), (4, 0.0033749070443898146), (0, 0.0033889576254761064), (12, 0.0035639902267741823), (24, 0.0035645974403405965), (5, 0.003841192083629201), (1, 0.0038935400818983674), (27, 0.003938006039578834), (9, 0.003962697978074501), (20, 0.003970499889970301), (19, 0.004023116457642906), (21, 0.0040733187759542724), (7, 0.004139436362001623), (6, 0.004143015034158523), (29, 0.004217195349386863), (16, 0.004241011523816004), (26, 0.004242634914863066), (17, 0.004294223541400424), (13, 0.004325430979800586), (11, 0.004332151934007138), (10, 0.004342186075297079), (14, 0.004349023610798773), (22, 0.004353080930025819), (2, 0.004364953373075589)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xzhan\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    }
   ],
   "source": [
    "#  Creat testing\n",
    "# (df, actual_Y_dict_test) = creat_data(n, 1)\n",
    "# print(\"DataFrame\", df)\n",
    "# print(\"Actual_Y_dict\", actual_Y_dict_test)\n",
    "# # actual_min = np.argmax(df[\"y_value\"])\n",
    "# # print('Min s', actual_min)\n",
    "\n",
    "test_df = sm.add_constant(df1)\n",
    "print('test_df:',test_df)\n",
    "# Use the trained model to make predictions on the new data\n",
    "predictions = model.predict(test_df[['const', 'x11', 'x22', 'x33']])\n",
    "sorted_predictions = sorted(predictions.items(), key=lambda x:x[1])\n",
    "# # Print or use the predictions as needed\n",
    "print(\"predictions\", sorted_predictions)\n",
    "\n",
    "sorted_actual_Y_dict = sorted(actual_Y_dict.items(), key=lambda x:x[1])\n",
    "print(\"actual values\", sorted_actual_Y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d185115d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(29, 0), (25, 0.00040657091805073806), (2, 0.001773838572260926), (21, 0.0018749557517400706), (23, 0.0020531171860036293), (14, 0.002202128022298043), (10, 0.0025835762471996884), (18, 0.00271894002204999), (26, 0.0027535264735846846), (13, 0.002784035032888668), (6, 0.0028127358484876692), (17, 0.0028547120575342956), (4, 0.0028582587959319686), (22, 0.0028805401654238283), (3, 0.0029748191274902927), (24, 0.0029885525392130477), (8, 0.0030030718505019566), (1, 0.003013648350633027), (0, 0.003039554731715355), (19, 0.0030516378590010884), (15, 0.003088247734453285), (20, 0.0031010346312026794), (12, 0.003127983331037691), (7, 0.003205938458982392), (11, 0.0032301317374829747), (27, 0.0032369515651250423), (16, 0.003254671460723748), (9, 0.0032604258732439814), (28, 0.0032693800563578027), (5, 0.0032778666281935258)]\n"
     ]
    }
   ],
   "source": [
    "a = sorted(actual_Y_dict_test.items(), key=lambda x:x[1])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "104a1a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    539\n",
      "1    209\n",
      "2    389\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find k nodes index with smallest polarization - use to predict minimizer's choice\n",
    "k = 3\n",
    "print(pred_Y.argsort()[:k])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
