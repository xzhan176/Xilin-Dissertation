{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95e3904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e3f6f3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In the context of graph neural networks (GNNs), the input data typically consists of three parts:\n",
    "\n",
    "The graph structure: This is typically represented as an adjacency matrix or an edge list. The adjacency matrix is a square matrix where the (i,j)-th entry is 1 if there is an edge from node i to node j, and 0 otherwise. An edge list is simply a list of tuples (i,j) representing the edges in the graph.\n",
    "\n",
    "Node features: These are the properties of each node in the graph that the model uses to learn representations. Node features can include things like text embeddings, image features, or numerical attributes. In the case of the Cora dataset, each node is represented by a 1433-dimensional binary vector indicating the presence or absence of certain keywords in a document.\n",
    "\n",
    "Node labels: These are the ground truth labels for each node that the model tries to predict. In the case of the Cora dataset, each node is assigned one of seven possible labels indicating the topic of the corresponding document.\n",
    "The data for the Cora dataset looks like this:\n",
    "\n",
    "css\n",
    "Copy code\n",
    "Data(edge_index=[2, 10556], x=[2708, 1433], y=[2708])\n",
    "Here, edge_index is the edge list representing the graph structure, x is the node feature matrix, and y is the node label vector.\n",
    "\n",
    "In more detail, edge_index is a 2D tensor of shape (2, E) where E is the number of edges in the graph. \n",
    "The first row of edge_index contains the indices of the source nodes of each edge, while the second row contains the indices of the target nodes. \n",
    "Each row of x represents the feature vector for a node, and y is a 1D tensor of length N where N is the number of nodes in the graph. \n",
    "The i-th entry of y contains the label for the i-th node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab8e7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graphical Convelution Network model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)  # define the first GCN layer\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim) # define the second GCN layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        # Pass the node features and adjacency matrix through the first layer\n",
    "        x, edge_index = data.x, data.edge_index  # read each variable\n",
    "        x = F.relu(self.conv1(x, edge_index)) # apply the ReLU activation function on first layer\n",
    "        # Pass the output of the first layer through the second layer\n",
    "        x = self.conv2(x, edge_index)  \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b54eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "adjacency_matrix = [[0, 1, 1, 0], [1, 0, 1, 1], [1, 1, 0, 1], [0, 1, 1, 0]]\n",
    "num_nodes = len(adjacency_matrix)\n",
    "edge_index = torch.tensor([[i, j] for i in range(num_nodes) for j in range(num_nodes) if adjacency_matrix[i][j] == 1],\n",
    "                          dtype=torch.long).t()\n",
    "node_features = torch.randn((num_nodes, 16))\n",
    "node_labels = torch.tensor([0, 1, 1, 0], dtype=torch.long)\n",
    "\n",
    "data = Data(x=node_features, edge_index=edge_index, y=node_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d4b4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "# Create a torch geometric data object\n",
    "# data = Data(x=torch.tensor(node_props, dtype=torch.float),\n",
    "#             edge_index=torch.tensor(adj_matrix.nonzero(), dtype=torch.long),\n",
    "#             y=torch.tensor(labels, dtype=torch.long))\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data, val_data = torch.utils.data.random_split(data, [int(0.8*len(data)), len(data)-int(0.8*len(data))])\n",
    "\n",
    "# Create data loaders for batch processing\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7363fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(input_dim=node_props.shape[1], hidden_dim=64, output_dim=2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(model, loader, optimizer, criterion, device):\n",
    "    model.train()   # set the model in training mode\n",
    "    total_loss, total_correct = 0, 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()  # zero the gradients\n",
    "        output = model(data)  # forward pass\n",
    "        loss = criterion(output, data.y)  # compute the loss on labeled nodes only\n",
    "        loss.backward()  # backward pass\n",
    "        optimizer.step()  # update the parameters\n",
    "        total_loss += loss.item()\n",
    "        total_correct += (output.argmax(dim=1) == data.y).sum().item()\n",
    "    return total_loss/len(loader.dataset), total_correct/len(loader.dataset)\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval() # set the model in evaluation mode\n",
    "    total_loss, total_correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)  # forward pass\n",
    "            loss = criterion(output, data.y) \n",
    "            total_loss += loss.item()\n",
    "            total_correct += (output.argmax(dim=1) == data.y).sum().item() # compute the number of correct predictions\n",
    "    return total_loss/len    # compute the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088016a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(200):\n",
    "    train() # train the model for one epoch\n",
    "    test() # evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5784bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
